{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d8f9656-434b-47d4-89e5-50b79d09e669",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Initializing layer with input size: 810000\n",
      "INFO:__main__:Initializing layer with input size: 810000\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'train_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 208\u001b[0m\n\u001b[0;32m    205\u001b[0m model2\u001b[38;5;241m.\u001b[39minitialize_layer()\n\u001b[0;32m    207\u001b[0m \u001b[38;5;66;03m# Train the models\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m dual_model_training(model1, model2, \u001b[43mtrain_loader\u001b[49m, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-3\u001b[39m)\n\u001b[0;32m    209\u001b[0m \u001b[38;5;66;03m# Adaptive Reward Based Model\u001b[39;00m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mAdaptiveRewardBasedModel\u001b[39;00m(nn\u001b[38;5;241m.\u001b[39mModule):\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_loader' is not defined"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import json\n",
    "import logging\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from dataclasses import dataclass\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Data Class for Grid Pairs\n",
    "@dataclass\n",
    "class GridPair:\n",
    "    task_id: str\n",
    "    input_grid: list\n",
    "    output_grid: list\n",
    "\n",
    "# Load ARC Data\n",
    "def load_arc_data():\n",
    "    file_paths = {\n",
    "        \"arc-agi_training-challenges\": \"arc-agi_training_challenges.json\",\n",
    "        \"arc-agi_evaluation-challenges\": \"arc-agi_evaluation_challenges.json\"\n",
    "    }\n",
    "    arc_data = {}\n",
    "    for key, path in file_paths.items():\n",
    "        try:\n",
    "            with open(path, 'r') as f:\n",
    "                arc_data[key] = json.load(f)\n",
    "                logger.info(f\"Loaded {key} from {path}.\")\n",
    "        except (FileNotFoundError, json.JSONDecodeError) as e:\n",
    "            logger.error(f\"Error loading {path}: {e}\")\n",
    "            arc_data[key] = {}\n",
    "    return arc_data\n",
    "\n",
    "# Custom Collate Function for Dynamic Padding\n",
    "def collate_fn(batch):\n",
    "    \"\"\"Dynamically pad grids to match the largest grid size in the batch.\"\"\"\n",
    "    max_size = max(\n",
    "        max(len(pair[0]), len(pair[1]))\n",
    "        for pair in batch\n",
    "    )\n",
    "\n",
    "    padded_inputs, padded_outputs = [], []\n",
    "\n",
    "    for input_grid, output_grid in batch:\n",
    "        # Convert to tensors\n",
    "        input_tensor = torch.tensor(input_grid, dtype=torch.float32)\n",
    "        output_tensor = torch.tensor(output_grid, dtype=torch.float32)\n",
    "\n",
    "        # Pad input and output grids\n",
    "        padded_input = torch.full((max_size, max_size), -1, dtype=torch.float32)\n",
    "        padded_output = torch.full((max_size, max_size), -1, dtype=torch.float32)\n",
    "\n",
    "        padded_input[:input_tensor.size(0), :input_tensor.size(1)] = input_tensor\n",
    "        padded_output[:output_tensor.size(0), :output_tensor.size(1)] = output_tensor\n",
    "\n",
    "        padded_inputs.append(padded_input)\n",
    "        padded_outputs.append(padded_output)\n",
    "\n",
    "    return torch.stack(padded_inputs), torch.stack(padded_outputs)\n",
    "\n",
    "# PyTorch Dataset Class\n",
    "class AugmentedARCDataset(Dataset):\n",
    "    def __init__(self, grid_pairs, augment=True):\n",
    "        self.grid_pairs = grid_pairs\n",
    "        self.augment = augment\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.grid_pairs)\n",
    "\n",
    "    # In AugmentedARCDataset class\n",
    "    def __getitem__(self, idx):\n",
    "        pair = self.grid_pairs[idx]\n",
    "        input_grid = torch.tensor(pair.input_grid, dtype=torch.float32)\n",
    "        output_grid = torch.tensor(pair.output_grid, dtype=torch.float32)\n",
    "        \n",
    "        # Flatten the output grid if necessary\n",
    "        target = output_grid.flatten()  # Adjust this based on how you want to shape your targets\n",
    "    \n",
    "        return input_grid, target  # Ensure targets are in the correct shape\n",
    "def pad_and_flatten(inputs, target_size):\n",
    "    # Pad to the target size\n",
    "    padded = torch.full((inputs.size(0), target_size), -1, dtype=torch.float32)  # -1 or another value as padding\n",
    "    for i in range(inputs.size(0)):\n",
    "        padded[i, :inputs[i].numel()] = inputs[i].flatten()  # Flatten and fill the padded tensor\n",
    "    return padded\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import logging\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Adaptive Reward-Based Model\n",
    "class AdaptiveRewardBasedModel(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super().__init__()\n",
    "        self.dynamic_layer = nn.Linear(input_size, num_classes)\n",
    "        self.input_size = input_size  # Store the input size\n",
    "\n",
    "    def initialize_layer(self):\n",
    "        logger.info(f\"Initializing layer with input size: {self.input_size}\")\n",
    "        self.dynamic_layer = nn.Linear(self.input_size, 10)  # Adjust output size as needed\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.dynamic_layer is None:\n",
    "            raise ValueError(\"Dynamic layer has not been initialized.\")\n",
    "        logger.info(f\"Forward pass with input shape: {x.shape}\")\n",
    "        return self.dynamic_layer(x)\n",
    "        \n",
    "    def get_params(self):\n",
    "        return self.dynamic_layer.parameters()\n",
    "\n",
    "# Train the models\n",
    "def dual_model_training(model1, model2, train_loader, epochs, lr):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer1 = optim.AdamW(model1.parameters(), lr=lr)\n",
    "    optimizer2 = optim.AdamW(model2.parameters(), lr=lr)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for inputs, targets in train_loader:\n",
    "            # Pad and flatten inputs\n",
    "            padded_inputs = pad_and_flatten(inputs, 810000)  # Match input size\n",
    "\n",
    "            # Flatten and convert targets to Long type\n",
    "            targets = targets.view(-1)  # Ensure targets are 1D\n",
    "            logger.info(f\"Flattened targets shape: {targets.shape}\")\n",
    "\n",
    "            # Check for any out-of-bounds indices in targets\n",
    "            if targets.dim() > 1:\n",
    "                targets = targets.view(-1)\n",
    "                logger.warning(f\"Reshaped targets to shape: {targets.shape}\")\n",
    "\n",
    "            # Replace out-of-bound values\n",
    "            invalid_indices = targets < 0\n",
    "            if invalid_indices.any():\n",
    "                logger.warning(\"Found invalid target indices. Setting them to 0.\")\n",
    "                targets[invalid_indices] = 0  # Map invalid targets to a valid class\n",
    "\n",
    "            # Ensure targets are of Long type\n",
    "            if targets.dtype != torch.long:\n",
    "                targets = targets.long()\n",
    "\n",
    "            optimizer1.zero_grad()\n",
    "            optimizer2.zero_grad()\n",
    "\n",
    "            # Forward pass for both models\n",
    "            outputs1 = model1(padded_inputs)\n",
    "            outputs2 = model2(padded_inputs)\n",
    "\n",
    "            # Log output shapes\n",
    "            logger.info(f\"Outputs1 shape: {outputs1.shape}, Targets shape: {targets.shape}\")\n",
    "\n",
    "            # Check if outputs and targets are compatible for loss computation\n",
    "            if outputs1.size(0) != targets.size(0):\n",
    "                # Handle size mismatch by truncating targets or repeating\n",
    "                if targets.size(0) < outputs1.size(0):\n",
    "                    targets = targets.repeat((outputs1.size(0) // targets.size(0) + 1))[:outputs1.size(0)]\n",
    "                    logger.warning(f\"Resized targets to shape: {targets.shape}\")\n",
    "                else:\n",
    "                    targets = targets[:outputs1.size(0)]\n",
    "                    logger.warning(f\"Truncated targets to shape: {targets.shape}\")\n",
    "\n",
    "            # Ensure outputs and targets are compatible for loss computation\n",
    "            if outputs1.size(0) != targets.size(0):\n",
    "                raise ValueError(f\"Output batch size {outputs1.size(0)} does not match target batch size {targets.size(0)}.\")\n",
    "\n",
    "            # Compute loss for model1\n",
    "            loss1 = criterion(outputs1, targets)\n",
    "            loss1.backward()  # Backpropagation for model1\n",
    "            optimizer1.step()  # Update model1 parameters\n",
    "\n",
    "            # Repeat the above checks and computations for model2\n",
    "            # Check for size compatibility again\n",
    "            if outputs2.size(0) != targets.size(0):\n",
    "                if targets.size(0) < outputs2.size(0):\n",
    "                    targets = targets.repeat((outputs2.size(0) // targets.size(0) + 1))[:outputs2.size(0)]\n",
    "                    logger.warning(f\"Resized targets for model2 to shape: {targets.shape}\")\n",
    "                else:\n",
    "                    targets = targets[:outputs2.size(0)]\n",
    "                    logger.warning(f\"Truncated targets for model2 to shape: {targets.shape}\")\n",
    "\n",
    "            # Compute loss for model2\n",
    "            loss2 = criterion(outputs2, targets)\n",
    "            loss2.backward()  # Backpropagation for model2\n",
    "            optimizer2.step()  # Update model2 parameters\n",
    "\n",
    "    logger.info(f\"Completed {epochs} epochs.\")\n",
    "\n",
    "\n",
    "# Main execution\n",
    "input_size = 810000  # Set the input size appropriately\n",
    "num_classes = 10  # Set this to your actual number of classes\n",
    "model1 = AdaptiveRewardBasedModel(input_size, num_classes)\n",
    "model2 = AdaptiveRewardBasedModel(input_size, num_classes)\n",
    "\n",
    "# Initialize the layers if necessary\n",
    "model1.initialize_layer()\n",
    "model2.initialize_layer()\n",
    "\n",
    "# Train the models\n",
    "dual_model_training(model1, model2, train_loader, epochs=10, lr=1e-3)\n",
    "# Adaptive Reward Based Model\n",
    "class AdaptiveRewardBasedModel(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(AdaptiveRewardBasedModel, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.num_classes = num_classes\n",
    "        self.dynamic_layer = nn.Linear(input_size, num_classes)\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "    def forward(self, x):\n",
    "        logger.info(f\"Forward pass with input shape: {x.shape}\")\n",
    "        x = self.flatten(x)\n",
    "        return self.dynamic_layer(x)\n",
    "\n",
    "def dual_model_training(model1, model2, train_loader, epochs, lr):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer1 = optim.AdamW(model1.parameters(), lr=lr)\n",
    "    optimizer2 = optim.AdamW(model2.parameters(), lr=lr)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        logger.info(f\"Starting epoch {epoch + 1}/{epochs}\")\n",
    "        for inputs, targets in train_loader:\n",
    "            logger.info(f\"Input shape: {inputs.shape}, Targets shape: {targets.shape}\")\n",
    "\n",
    "            # Check and adjust input shape\n",
    "            if inputs.size(1) != model1.input_size:\n",
    "                logger.warning(f\"Resizing input from {inputs.shape} to match expected size {model1.input_size}.\")\n",
    "                inputs = inputs.view(inputs.size(0), -1)  # Flatten to a single dimension\n",
    "\n",
    "            # Handle targets\n",
    "            targets = targets.view(-1).long()  # Flatten targets to a 1D array and convert to long\n",
    "\n",
    "            # Check for invalid target indices\n",
    "            if (targets < 0).any() or (targets >= model1.num_classes).any():\n",
    "                logger.warning(f\"Found invalid target indices. Adjusting them.\")\n",
    "                targets = targets.clamp(0, model1.num_classes - 1)\n",
    "\n",
    "            # Forward pass for both models\n",
    "            outputs1 = model1(inputs)\n",
    "            outputs2 = model2(inputs)\n",
    "\n",
    "            logger.info(f\"Outputs1 shape: {outputs1.shape}, Targets shape: {targets.shape}\")\n",
    "\n",
    "            # Ensure outputs and targets are compatible for loss computation\n",
    "            if outputs1.size(0) != targets.size(0):\n",
    "                logger.warning(f\"Adjusting targets size from {targets.shape} to {outputs1.size(0)}\")\n",
    "                targets = targets[:outputs1.size(0)]  # Adjust targets size\n",
    "\n",
    "            # Compute loss for model1\n",
    "            loss1 = criterion(outputs1, targets)\n",
    "            loss1.backward()  # Backpropagation for model1\n",
    "            optimizer1.step()  # Update model1 parameters\n",
    "\n",
    "            # Repeat for model2\n",
    "            optimizer2.zero_grad()\n",
    "            if outputs2.size(0) != targets.size(0):\n",
    "                logger.warning(f\"Adjusting targets size from {targets.shape} to {outputs2.size(0)}\")\n",
    "                targets = targets[:outputs2.size(0)]  # Adjust targets size\n",
    "            loss2 = criterion(outputs2, targets)\n",
    "            loss2.backward()  # Backpropagation for model2\n",
    "            optimizer2.step()  # Update model2 parameters\n",
    "\n",
    "        logger.info(f\"Completed epoch {epoch + 1}/{epochs}\")\n",
    "\n",
    "# Example instantiation and training call\n",
    "input_size = 810000  # Set according to your requirements\n",
    "num_classes = 10  # Adjust based on your dataset\n",
    "\n",
    "# Assuming train_loader is defined and populated correctly\n",
    "model1 = AdaptiveRewardBasedModel(input_size, num_classes)\n",
    "model2 = AdaptiveRewardBasedModel(input_size, num_classes)\n",
    "\n",
    "# Start training\n",
    "dual_model_training(model1, model2, train_loader, epochs=10, lr=1e-3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34afd7b-8e4d-4fc3-9474-f90966d74ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import json\n",
    "import logging\n",
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from dataclasses import dataclass\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Data Class for Grid Pairs\n",
    "@dataclass\n",
    "class GridPair:\n",
    "    task_id: str\n",
    "    input_grid: list\n",
    "    output_grid: list\n",
    "\n",
    "# Load ARC Data\n",
    "def load_arc_data():\n",
    "    file_paths = {\n",
    "        \"arc-agi_training-challenges\": \"arc-agi_training_challenges.json\",\n",
    "        \"arc-agi_evaluation-challenges\": \"arc-agi_evaluation_challenges.json\"\n",
    "    }\n",
    "    arc_data = {}\n",
    "    for key, path in file_paths.items():\n",
    "        try:\n",
    "            with open(path, 'r') as f:\n",
    "                arc_data[key] = json.load(f)\n",
    "                logger.info(f\"Loaded {key} from {path}.\")\n",
    "        except (FileNotFoundError, json.JSONDecodeError) as e:\n",
    "            logger.error(f\"Error loading {path}: {e}\")\n",
    "            arc_data[key] = {}\n",
    "    return arc_data\n",
    "\n",
    "# Flatten and Reshape Grid Data\n",
    "def flatten_and_reshape(task_data):\n",
    "    flattened_pairs = []\n",
    "    for task_id, task_content in task_data.items():\n",
    "        logger.info(f\"Parsing task {task_id}...\")\n",
    "        train_pairs = task_content.get('train', [])\n",
    "        for pair in train_pairs:\n",
    "            input_grid = extract_and_reshape_grid(pair.get(\"input\"))\n",
    "            output_grid = extract_and_reshape_grid(pair.get(\"output\"))\n",
    "            if input_grid and output_grid:\n",
    "                flattened_pairs.append(GridPair(task_id, input_grid, output_grid))\n",
    "    return flattened_pairs\n",
    "\n",
    "# Extract and Reshape Grid\n",
    "def extract_and_reshape_grid(grid):\n",
    "    try:\n",
    "        flat_list = [item for sublist in grid for item in sublist] if isinstance(grid, list) else [grid]\n",
    "        return reshape_to_square_grid(flat_list)\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error processing grid: {e}\")\n",
    "        return None\n",
    "\n",
    "# Reshape to Square Grid\n",
    "def reshape_to_square_grid(flat_list):\n",
    "    size = math.ceil(math.sqrt(len(flat_list)))\n",
    "    padded_list = np.pad(flat_list, (0, size * size - len(flat_list)), constant_values=-1)\n",
    "    return padded_list.reshape(size, size).tolist()\n",
    "\n",
    "# Data Augmentation Functions\n",
    "def augment_grid(grid, noise_prob=0.2, dead_square_prob=0.1):\n",
    "    \"\"\"Applies augmentation to the grid by adding noise and dead squares.\"\"\"\n",
    "    augmented_grid = np.array(grid).copy()\n",
    "\n",
    "    for i in range(augmented_grid.shape[0]):\n",
    "        for j in range(augmented_grid.shape[1]):\n",
    "            if random.random() < noise_prob:\n",
    "                augmented_grid[i, j] = random.randint(0, 10)  # Add noise\n",
    "            if random.random() < dead_square_prob:\n",
    "                augmented_grid[i, j] = -1  # Dead square\n",
    "    return augmented_grid.tolist()\n",
    "\n",
    "def rotate_grid(grid):\n",
    "    \"\"\"Randomly rotates the grid.\"\"\"\n",
    "    rotations = random.choice([0, 1, 2, 3])\n",
    "    return np.rot90(grid, rotations).tolist()\n",
    "\n",
    "def flip_grid(grid):\n",
    "    \"\"\"Randomly flips the grid.\"\"\"\n",
    "    if random.random() > 0.5:\n",
    "        return np.flipud(grid).tolist()  # Vertical flip\n",
    "    else:\n",
    "        return np.fliplr(grid).tolist()  # Horizontal flip\n",
    "\n",
    "# Custom Collate Function for Dynamic Padding\n",
    "def collate_fn(batch):\n",
    "    \"\"\"Dynamically pad grids to match the largest grid size in the batch.\"\"\"\n",
    "    # Convert all grids to tensors and find the largest grid size\n",
    "    batch = [(torch.tensor(x[0], dtype=torch.float32), \n",
    "              torch.tensor(x[1], dtype=torch.float32)) for x in batch]\n",
    "\n",
    "    max_size = max(max(grid.shape[0], grid.shape[1]) for pair in batch for grid in pair)\n",
    "\n",
    "    padded_inputs, padded_outputs = [], []\n",
    "\n",
    "    # Pad each input and output grid to the max size\n",
    "    for input_grid, output_grid in batch:\n",
    "        input_padded = torch.full((max_size, max_size), -1, dtype=torch.float32)\n",
    "        output_padded = torch.full((max_size, max_size), -1, dtype=torch.float32)\n",
    "\n",
    "        # Copy the original grids into the padded tensors\n",
    "        input_padded[:input_grid.shape[0], :input_grid.shape[1]] = input_grid\n",
    "        output_padded[:output_grid.shape[0], :output_grid.shape[1]] = output_grid\n",
    "\n",
    "        padded_inputs.append(input_padded)\n",
    "        padded_outputs.append(output_padded)\n",
    "\n",
    "    # Stack the padded grids into a batch tensor\n",
    "    return torch.stack(padded_inputs), torch.stack(padded_outputs)\n",
    "\n",
    "# PyTorch Dataset Class\n",
    "class AugmentedARCDataset(Dataset):\n",
    "    def __init__(self, grid_pairs, augment=True):\n",
    "        self.grid_pairs = grid_pairs\n",
    "        self.augment = augment\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.grid_pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        pair = self.grid_pairs[idx]\n",
    "        input_grid = torch.tensor(pair.input_grid, dtype=torch.float32)\n",
    "        output_grid = torch.tensor(pair.output_grid, dtype=torch.float32)\n",
    "\n",
    "        if self.augment:\n",
    "            input_grid = augment_grid(input_grid)\n",
    "            input_grid = rotate_grid(input_grid)\n",
    "            input_grid = flip_grid(input_grid)\n",
    "\n",
    "        return input_grid, output_grid\n",
    "\n",
    "class RewardBasedModel(nn.Module):\n",
    "    def __init__(self, input_size, output_size=10):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear = nn.Linear(input_size, output_size)  # Input size matches flattened grid size\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)  # Flatten the input dynamically\n",
    "        return self.linear(x)\n",
    "\n",
    "\n",
    "    def earn_points(self, correct_predictions):\n",
    "        \"\"\"Earn points for correct predictions.\"\"\"\n",
    "        self.bank += correct_predictions\n",
    "\n",
    "    def spend_points(self, points):\n",
    "        \"\"\"Spend points from the bank.\"\"\"\n",
    "        if points > self.bank:\n",
    "            raise ValueError(\"Not enough points!\")\n",
    "        self.bank -= points\n",
    "\n",
    "    def select_variable_squares(self):\n",
    "        \"\"\"Select random variable squares for perturbation.\"\"\"\n",
    "        num_squares = random.randint(1, self.grid_size // 2)\n",
    "        return random.sample([(i, j) for i in range(self.grid_size) for j in range(self.grid_size)], num_squares)\n",
    "\n",
    "# Loss Function with Variable Squares\n",
    "def loss_with_variable_squares(predictions, targets, variable_squares, criterion):\n",
    "    mask = torch.ones_like(predictions, dtype=torch.bool)\n",
    "    for (i, j) in variable_squares:\n",
    "        mask[:, i, j] = False\n",
    "    return criterion(predictions[mask], targets[mask])\n",
    "\n",
    "def dual_model_training(model1, model2, train_loader, epochs, lr):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer1 = optim.AdamW(model1.parameters(), lr=lr)\n",
    "    optimizer2 = optim.AdamW(model2.parameters(), lr=lr)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for inputs, targets in train_loader:\n",
    "            # Pad and flatten inputs\n",
    "            padded_inputs = pad_and_flatten(inputs, 810000)  # Match input size\n",
    "\n",
    "            # Flatten and convert targets to Long type\n",
    "            targets = targets.view(-1)  # Ensure targets are 1D\n",
    "            logger.info(f\"Flattened targets shape: {targets.shape}\")\n",
    "\n",
    "            # Check for any out-of-bounds indices in targets\n",
    "            if targets.dim() > 1:\n",
    "                targets = targets.view(-1)\n",
    "                logger.warning(f\"Reshaped targets to shape: {targets.shape}\")\n",
    "\n",
    "            # Replace out-of-bound values\n",
    "            invalid_indices = targets < 0\n",
    "            if invalid_indices.any():\n",
    "                logger.warning(\"Found invalid target indices. Setting them to 0.\")\n",
    "                targets[invalid_indices] = 0  # Map invalid targets to a valid class\n",
    "\n",
    "            # Ensure targets are of Long type\n",
    "            if targets.dtype != torch.long:\n",
    "                targets = targets.long()\n",
    "\n",
    "            optimizer1.zero_grad()\n",
    "            optimizer2.zero_grad()\n",
    "\n",
    "            # Forward pass for both models\n",
    "            outputs1 = model1(padded_inputs)\n",
    "            outputs2 = model2(padded_inputs)\n",
    "\n",
    "            # Log output shapes\n",
    "            logger.info(f\"Outputs1 shape: {outputs1.shape}, Targets shape: {targets.shape}\")\n",
    "\n",
    "            # Check if outputs and targets are compatible for loss computation\n",
    "            if outputs1.size(0) != targets.size(0):\n",
    "                # Handle size mismatch by truncating targets or repeating\n",
    "                if targets.size(0) < outputs1.size(0):\n",
    "                    targets = targets.repeat((outputs1.size(0) // targets.size(0) + 1))[:outputs1.size(0)]\n",
    "                    logger.warning(f\"Resized targets to shape: {targets.shape}\")\n",
    "                else:\n",
    "                    targets = targets[:outputs1.size(0)]\n",
    "                    logger.warning(f\"Truncated targets to shape: {targets.shape}\")\n",
    "\n",
    "            # Ensure outputs and targets are compatible for loss computation\n",
    "            if outputs1.size(0) != targets.size(0):\n",
    "                raise ValueError(f\"Output batch size {outputs1.size(0)} does not match target batch size {targets.size(0)}.\")\n",
    "\n",
    "            # Compute loss for model1\n",
    "            loss1 = criterion(outputs1, targets)\n",
    "            loss1.backward()  # Backpropagation for model1\n",
    "            optimizer1.step()  # Update model1 parameters\n",
    "\n",
    "            # Repeat the above checks and computations for model2\n",
    "            # Check for size compatibility again\n",
    "            if outputs2.size(0) != targets.size(0):\n",
    "                if targets.size(0) < outputs2.size(0):\n",
    "                    targets = targets.repeat((outputs2.size(0) // targets.size(0) + 1))[:outputs2.size(0)]\n",
    "                    logger.warning(f\"Resized targets for model2 to shape: {targets.shape}\")\n",
    "                else:\n",
    "                    targets = targets[:outputs2.size(0)]\n",
    "                    logger.warning(f\"Truncated targets for model2 to shape: {targets.shape}\")\n",
    "\n",
    "            # Compute loss for model2\n",
    "            loss2 = criterion(outputs2, targets)\n",
    "            loss2.backward()  # Backpropagation for model2\n",
    "            optimizer2.step()  # Update model2 parameters\n",
    "\n",
    "    logger.info(f\"Completed {epochs} epochs.\")\n",
    "\n",
    "# Main Workflow\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "arc_data = load_arc_data()\n",
    "train_grid_pairs = flatten_and_reshape(arc_data[\"arc-agi_training-challenges\"])\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    AugmentedARCDataset(train_grid_pairs, augment=True), \n",
    "    batch_size=32, \n",
    "    shuffle=True, \n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "base_model = nn.Sequential(nn.Flatten(), nn.Linear(9, 10))\n",
    "# Assuming your grids are padded to 29x29\n",
    "grid_size = 29  # Adjust based on your actual input size\n",
    "\n",
    "# Initialize the models with the appropriate grid size\n",
    "model1 = RewardBasedModel(input_size=input_size, output_size=10).to(device)\n",
    "model2 = RewardBasedModel(input_size=input_size, output_size=10).to(device)\n",
    "\n",
    "\n",
    "dual_model_training(model1, model2, train_loader, epochs=10, lr=1e-3)\n",
    "# Initialize models with the correct input size\n",
    "model1 = RewardBasedModel(input_size=input_size, output_size=10).to(device)\n",
    "model2 = RewardBasedModel(input_size=input_size, output_size=10).to(device)\n",
    "\n",
    "# Train the models using dual training\n",
    "dual_model_training(model1, model2, train_loader, epochs=10, lr=1e-)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c36d6115-d28c-468c-b7ff-65fd97ef5fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# models/cnn_grid_mapper.py\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class CNNGridMapper(nn.Module):\n",
    "    def __init__(self, num_classes=11):\n",
    "        \"\"\"\n",
    "        Initializes the CNN model.\n",
    "\n",
    "        Args:\n",
    "            num_classes (int, optional): Number of classes per grid cell. Defaults to 11.\n",
    "        \"\"\"\n",
    "        super(CNNGridMapper, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1),  # Input channels=1\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),  # 10x10 -> 5x5\n",
    "            nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)  # 5x5 -> 2x2\n",
    "        )\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(32, 16, kernel_size=2, stride=2),  # 2x2 -> 4x4\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(16, num_classes, kernel_size=3, stride=1, padding=1),  # 4x4 -> 4x4\n",
    "            # Optionally, add another upsampling layer to reach 9x9\n",
    "            nn.Upsample(size=(9, 9), mode='bilinear', align_corners=True)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Reshape input to (batch_size, 1, 10, 10)\n",
    "        x = x.view(-1, 1, 10, 10)\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        # Flatten output to (batch_size, 81)\n",
    "        x = x.view(-1, 81)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a95bbfb-f252-48fa-9ce4-b2653a49887d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import logging\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "99668d4a-e3e7-4d71-9f8b-d97f2d64f08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_grid_pairs(challenges, solutions):\n",
    "    \"\"\"\n",
    "    Extracts pairs of input and output grids from two datasets: challenges and solutions.\n",
    "\n",
    "    Args:\n",
    "        challenges (list of dict): A list of dictionaries containing input grids.\n",
    "        solutions (list of dict): A list of dictionaries containing output grids.\n",
    "\n",
    "    Returns:\n",
    "        list of tuple: A list of (input_grid, output_grid) pairs.\n",
    "    \"\"\"\n",
    "    if len(challenges) != len(solutions):\n",
    "        raise ValueError(\"The number of challenges and solutions must be equal.\")\n",
    "\n",
    "    grid_pairs = []\n",
    "\n",
    "    for challenge, solution in zip(challenges, solutions):\n",
    "        try:\n",
    "            # Ensure each dictionary contains 'input' and 'output' keys\n",
    "            input_grid = challenge.get('input')\n",
    "            output_grid = solution.get('output')\n",
    "\n",
    "            if input_grid is not None and output_grid is not None:\n",
    "                grid_pairs.append((input_grid, output_grid))\n",
    "            else:\n",
    "                print(f\"Invalid grid pair: {challenge}, {solution}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error extracting grid pair: {e}\")\n",
    "\n",
    "    return grid_pairs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f7732657-814b-492c-ae7a-75302ac07167",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_arc_model(model_type='mlp', num_epochs=50, learning_rate=0.001, device='cpu'):\n",
    "    \"\"\"\n",
    "    Trains the specified model type on the ARC dataset.\n",
    "\n",
    "    Args:\n",
    "        model_type (str, optional): Type of model ('mlp' or 'cnn'). Defaults to 'mlp'.\n",
    "        num_epochs (int, optional): Number of training epochs. Defaults to 50.\n",
    "        learning_rate (float, optional): Learning rate for the optimizer. Defaults to 0.001.\n",
    "        device (str, optional): Device to train on ('cpu' or 'cuda'). Defaults to 'cpu'.\n",
    "\n",
    "    Returns:\n",
    "        nn.Module: Trained model.\n",
    "    \"\"\"\n",
    "    # Load data\n",
    "    arc_data = load_arc_data()\n",
    "    unique_id = \"007bbfb7\"  # Replace with your actual unique ID if different\n",
    "\n",
    "    train_challenges = arc_data.get(\"arc-agi_training-challenges\", [])\n",
    "    train_solutions = arc_data.get(\"arc-agi_training-solutions\", [])\n",
    "    eval_challenges = arc_data.get(\"arc-agi_evaluation-challenges\", [])\n",
    "    eval_solutions = arc_data.get(\"arc-agi_evaluation-solutions\", [])\n",
    "\n",
    "    logger.info(f\"Number of training challenges: {len(train_challenges)}\")\n",
    "    logger.info(f\"Number of training solutions: {len(train_solutions)}\")\n",
    "    logger.info(f\"Number of evaluation challenges: {len(eval_challenges)}\")\n",
    "    logger.info(f\"Number of evaluation solutions: {len(eval_solutions)}\")\n",
    "\n",
    "    # Extract grid pairs\n",
    "    train_grid_pairs = extract_grid_pairs(train_challenges, train_solutions)\n",
    "    eval_grid_pairs = extract_grid_pairs(eval_challenges, eval_solutions)\n",
    "    logger.info(f\"Number of training grid pairs: {len(train_grid_pairs)}\")\n",
    "    logger.info(f\"Number of evaluation grid pairs: {len(eval_grid_pairs)}\")\n",
    "\n",
    "    # Create DataLoaders\n",
    "    batch_size = 32\n",
    "    train_loader, test_loader = create_data_loaders(\n",
    "        train_grid_pairs,\n",
    "        eval_grid_pairs,\n",
    "        batch_size=batch_size,\n",
    "        flatten=True,\n",
    "        max_size=10,\n",
    "        padding_value=-1\n",
    "    )\n",
    "\n",
    "    logger.info(f\"Training DataLoader size: {len(train_loader)} batches\")\n",
    "    logger.info(f\"Testing DataLoader size: {len(test_loader)} batches\")\n",
    "\n",
    "    # Initialize the model\n",
    "    if model_type.lower() == 'mlp':\n",
    "        input_size = 10 * 10  # 100\n",
    "        output_size = 9 * 9  # 81\n",
    "        model = MLPGridMapper(input_size=input_size, hidden_sizes=[256, 128], output_size=output_size)\n",
    "    elif model_type.lower() == 'cnn':\n",
    "        model = CNNGridMapper(num_classes=11)  # Adjust num_classes as per your dataset\n",
    "    else:\n",
    "        logger.error(\"Invalid model type specified. Choose 'mlp' or 'cnn'.\")\n",
    "        return None\n",
    "\n",
    "    # Define the loss function and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Train the model\n",
    "    model.to(device)\n",
    "    logger.info(f\"Starting training on {device}...\")\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for batch in train_loader:\n",
    "            inputs = batch['input_grid'].to(device)\n",
    "            targets = batch['output_grid'].to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "            # Calculate accuracy\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            _, actual = torch.max(targets, 1)\n",
    "            total += targets.size(0)\n",
    "            correct += (predicted == actual).sum().item()\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        epoch_acc = correct / total\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in test_loader:\n",
    "                inputs = batch['input_grid'].to(device)\n",
    "                targets = batch['output_grid'].to(device)\n",
    "\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                _, actual = torch.max(targets, 1)\n",
    "                val_total += targets.size(0)\n",
    "                val_correct += (predicted == actual).sum().item()\n",
    "\n",
    "        avg_val_loss = val_loss / len(test_loader.dataset)\n",
    "        val_acc = val_correct / val_total\n",
    "\n",
    "        logger.info(f\"Epoch {epoch}/{num_epochs} - \"\n",
    "                    f\"Train Loss: {epoch_loss:.4f}, Train Acc: {epoch_acc:.4f} - \"\n",
    "                    f\"Val Loss: {avg_val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "    logger.info(\"Training complete.\")\n",
    "\n",
    "    # Save the trained model\n",
    "    model_filename = f\"{model_type}_grid_mapper.pth\"\n",
    "    torch.save(model.state_dict(), model_filename)\n",
    "    logger.info(f\"Model saved to {model_filename}\")\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3cb9b1b2-7326-4cb2-931a-ccb50bb1c736",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MLPGridMapper(nn.Module):\n",
    "    \"\"\"\n",
    "    A Multi-Layer Perceptron (MLP) model to map input grids to output grids.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_size=100, hidden_sizes=[256, 128], output_size=81):\n",
    "        super(MLPGridMapper, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_sizes[0])\n",
    "        self.fc2 = nn.Linear(hidden_sizes[0], hidden_sizes[1])\n",
    "        self.fc3 = nn.Linear(hidden_sizes[1], output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return self.fc3(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b7bfa07a-5e7c-425b-ade6-33eb56f98b94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 1.0346\n",
      "Epoch 2/10, Loss: 1.0190\n",
      "Epoch 3/10, Loss: 1.0055\n",
      "Epoch 4/10, Loss: 0.9929\n",
      "Epoch 5/10, Loss: 0.9807\n",
      "Epoch 6/10, Loss: 0.9684\n",
      "Epoch 7/10, Loss: 0.9561\n",
      "Epoch 8/10, Loss: 0.9435\n",
      "Epoch 9/10, Loss: 0.9309\n",
      "Epoch 10/10, Loss: 0.9181\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model, loss function, and optimizer\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = MLPGridMapper(input_size=100, hidden_sizes=[256, 128], output_size=81).to(device)\n",
    "criterion = nn.MSELoss()  # Example loss function\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Example data (random) - replace with actual grid data\n",
    "X_train = torch.randn(100, 100).to(device)  # 100 samples, each with 100 features\n",
    "y_train = torch.randn(100, 81).to(device)   # 100 samples, each with 81 outputs\n",
    "\n",
    "# Training loop\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    output = model(X_train)\n",
    "    loss = criterion(output, y_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    print(f\"Epoch {epoch + 1}/{epochs}, Loss: {loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a59ba9aa-0711-4370-b566-4a8163d0e43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model's state dictionary\n",
    "torch.save(model.state_dict(), 'mlp_grid_mapper.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "736cf9b7-61c4-40ff-bb4c-71d9c8b6ecb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model again\n",
    "model = MLPGridMapper(input_size=100, hidden_sizes=[256, 128], output_size=81).to(device)\n",
    "\n",
    "# Load the model with weights_only=True\n",
    "model.load_state_dict(\n",
    "    torch.load('mlp_grid_mapper.pth', map_location=device, weights_only=True)\n",
    ")\n",
    "\n",
    "print(\"Model loaded successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d2060ed4-4421-4e2e-b9ef-50da74c75e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Example test data (random data)\n",
    "X_test = torch.randn(20, 100)  # 20 samples, each with 100 features\n",
    "y_test = torch.randint(0, 81, (20, 81))  # 20 samples, each with 81 possible outputs\n",
    "\n",
    "# Create a TensorDataset and DataLoader for the test data\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "test_loader = DataLoader(test_dataset, batch_size=4, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "440c8e11-973e-4e4c-8deb-b7d0d1192485",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader, device='cpu'):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in test_loader:\n",
    "            inputs = inputs.to(device)\n",
    "\n",
    "            # Convert targets to class indices if they are one-hot encoded\n",
    "            if targets.dtype != torch.long:\n",
    "                targets = torch.argmax(targets, dim=1)\n",
    "\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            total_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += targets.size(0)\n",
    "            correct += (predicted == targets).sum().item()\n",
    "\n",
    "    avg_loss = total_loss / len(test_loader.dataset)\n",
    "    accuracy = correct / total\n",
    "\n",
    "    print(f\"Test Loss: {avg_loss:.4f}, Test Accuracy: {accuracy:.4f}\")\n",
    "    return avg_loss, accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3fc15810-5cbb-4ee4-9d58-7fc232f93750",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA88AAAHqCAYAAAA6dXxvAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/H5lhTAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA8SklEQVR4nO3dd5gV5d0//vdSFhYWpAiIFRR7jRiNnRjFiBpLUCyJwcSERzEajSWWROwl+hVji0l4Yn9URH3UmCgajTFG1AjGgiUWxE5HqrCc3x/8dh/XBWaXAAfN63Vd57p2Z+6Z+cxx5cz73HPfU1EqlUoBAAAAFqtZuQsAAACAlZ3wDAAAAAWEZwAAACggPAMAAEAB4RkAAAAKCM8AAABQQHgGAACAAsIzAAAAFBCeAQAAoIDwDCuBIUOGpKKiolFtKyoqMmTIkEa1ffrpp1NZWZlx48b9G9Wt3A455JAcfPDB5S4DgKXQo0ePDBw4sNxlrHQ+/7489thjqaioyGOPPbbMjtGU6wlgIeGZsrj++utTUVGRZ599ttylJElmzZqVIUOGNPlD6eOPP87PfvazbL755qmurk7r1q3Tq1evHHnkkXniiSeWT7FNcMYZZ+TQQw/NOuusU7fs6aefzjHHHJPevXunZcuWhaF92LBh2XjjjdO6deusv/76ufLKK5e6nuVx7FNPPTUjRozI888/v9R1AbBsvfHGGxk0aFDWXXfdtG7dOu3bt8+OO+6YK664IrNnzy53eUtUe41S+2rdunU22GCDHHvssfnoo4/KXV6TPPDAAwIyLEPCM2RheD777LObFJ6ffvrpbLrpphk6dGh69+6diy++OFdddVUGDBiQp59+OjvvvHMef/zxRu3rzDPPXOYXE2PGjMnDDz+c//qv/6q3/IEHHsjvfve7VFRUZN11113iPq677rocddRR2XTTTXPllVdm++23z3HHHZeLL754qWpaHsf+yle+km222SaXXXbZUtUEwLL1hz/8IZtvvnnuuOOO7Lvvvrnyyitz4YUXZu21187JJ5+c448/vtwlNso555yTm266KVdddVV22GGHXHvttdl+++0za9asFV7LLrvsktmzZ2eXXXZp0nYPPPBAzj777EWumz17ds4888xlUR785yhBGfz+978vJSk988wz5S6lVCqVShMmTCglKZ111lmNaj958uRS9+7dS6uttlpp7NixDdYvWLCgdOutt5aefvrpJe5nxowZTa61sXUed9xxpbXXXru0YMGCess//PDD0qxZs0qlUqk0ePDg0uL+GZg1a1apc+fOpb333rve8sMPP7zUtm3b0uTJk5tc+/I69qWXXlpq27Zt6ZNPPmlyTQAsO2+++Wapurq6tNFGG5Xef//9Butff/310tChQ+t+X2eddUrf+973VmCFxRZ3jXLiiSeWkpRuvfXWxW67NJ/ri7Ks3pclfdYCTafnmZXGwIEDU11dnffeey/7779/qqur06VLl5x00kmpqampa/f222+noqIil156aS6//PKss846qaqqyq677poXX3yx3j779OmTPn36LPJYPXr0qNtfly5dkiRnn3123W1aS7rN6de//nU++OCDDB06NBtttFGD9RUVFTn00EPz1a9+tW5Z7bjml19+OYcddlg6duyYnXbaqd66z5o7d25OOOGEdOnSJe3atcu3vvWtvPvuu0t8Dz/rnnvuyW677dZgv926dUtVVVXh9o8++mgmTZqUY445pt7ywYMHZ+bMmfnDH/6QJBk7dmyqqqpyxBFH1Gv3xBNPpHnz5jn11FOX27Fr7bHHHpk5c2ZGjhxZuG8Alp9LLrkkM2bMyLBhw9K9e/cG63v16rXEnufJkyfnpJNOqhsO1b59++y1116LHJpz5ZVXZtNNN02bNm3SsWPHbLPNNrn11lvr1n/yySf5yU9+kh49eqRVq1bp2rVr9thjjzz33HNLdW677bZbkuStt95K8n/XLW+88Ub69euXdu3a5fDDD0+SLFiwIEOHDs2mm26a1q1bp1u3bhk0aFCmTJlSb5+lUinnnXde1lxzzbRp0yZf//rX89JLLzU49uLGPI8aNSr9+vVLx44d07Zt22yxxRa54oor6uq7+uqrk6Tebei1FnWtM3r06Oy1115p3759qqur841vfCNPPfVUvTa1t7X/7W9/y4knnpguXbqkbdu2OeCAAzJhwoQmvqvwxdKi3AXAZ9XU1GTPPffMdtttl0svvTQPP/xwLrvssqy33no5+uij67W98cYb88knn2Tw4MGZM2dOrrjiiuy222554YUX0q1bt0Yfs0uXLrn22mtz9NFH54ADDsiBBx6YJNliiy0Wu819992XqqqqurZNcdBBB2X99dfPBRdckFKptNh2Rx11VG6++eYcdthh2WGHHfLnP/85e++9d6OO8d577+Wdd97J1ltv3eT6ao0ePTpJss0229Rb3rt37zRr1iyjR4/Od77znWy88cY599xzc/LJJ6d///751re+lZkzZ2bgwIHZaKONcs455yy3Y9faZJNNUlVVlb/97W854IADmnw8AJaN++67L+uuu2522GGHpdr+zTffzD333JODDjooPXv2zEcffZTrrrsuu+66a15++eWsvvrqSZLf/va3Oe6449K/f/8cf/zxmTNnTv75z39m1KhROeyww5Ik//Vf/5U777wzxx57bDbZZJNMmjQpTzzxRMaOHbtUn49vvPFGkqRz5851y+bPn58999wzO+20Uy699NK0adMmSTJo0KBcf/31OfLII3PcccflrbfeylVXXZXRo0fnb3/7W1q2bJkk+cUvfpHzzjsv/fr1S79+/fLcc8+lb9+++fTTTwvrGTlyZPbZZ5907949xx9/fFZbbbWMHTs2999/f44//vgMGjQo77//fkaOHJmbbrqpcH8vvfRSdt5557Rv3z6nnHJKWrZsmeuuuy59+vTJX/7yl2y33Xb12v/4xz9Ox44dc9ZZZ+Xtt9/O0KFDc+yxx+b2229v9HsKXzjl7vrmP9Oibon63ve+V0pSOuecc+q1/cpXvlLq3bt33e9vvfVWKUmpqqqq9O6779YtHzVqVClJ6YQTTqhbtuuuu5Z23XXXBsf/3ve+V1pnnXXqfm/qbdsdO3YsbbXVVg2WT58+vTRhwoS612dv3zrrrLNKSUqHHnpog+1q19UaM2ZMKUnpmGOOqdfusMMOa1SdDz/8cClJ6b777ltiuyXdzjV48OBS8+bNF7muS5cupUMOOaTu95qamtJOO+1U6tatW2nixImlwYMHl1q0aLHE2/KX1bFrbbDBBqW99tprsccDYPmaNm1aKUlpv/32a/Q2n789ec6cOaWampp6bd56661Sq1at6l0f7LfffqVNN910ifteZZVVSoMHD250LbVqr1Eefvjh0oQJE0rjx48v3XbbbaXOnTvXu/aovW752c9+Vm/7v/71r6UkpVtuuaXe8j/96U/1ln/88celysrK0t57711viNXpp59eSlLvfXn00UdLSUqPPvpoqVQqlebPn1/q2bNnaZ111ilNmTKl3nE+u68lfdZ+/npi//33L1VWVpbeeOONumXvv/9+qV27dqVddtmlwfuz++671zvWCSecUGrevHlp6tSpizwefBm4bZuVzucnuNp5553z5ptvNmi3//77Z4011qj7fdttt812222XBx54YLnXOH369FRXVzdY/t3vfjddunSpe332luVanz+/Rak9h+OOO67e8p/85CeNqm/SpElJko4dOzaq/aLMnj07lZWVi1zXunXrehOcNWvWLNdff31mzJiRvfbaK9dcc01OO+20Bj3Hy+PYtTp27JiJEycu1fEA+PdNnz49SdKuXbul3kerVq3SrNnCy9OamppMmjQp1dXV2XDDDevdbt2hQ4e8++67eeaZZxa7rw4dOmTUqFF5//33l6qW3XffPV26dMlaa62VQw45JNXV1bn77rvrXXskaXBn3PDhw7PKKqtkjz32yMSJE+tevXv3TnV1dR599NEkycMPP5xPP/00P/7xj+vdTt2Yz/rRo0fnrbfeyk9+8pN06NCh3rrGPvrys2pqavLQQw9l//33rzehZ/fu3XPYYYfliSeeqPvvW+tHP/pRvWPtvPPOqamp+VI/HhOEZ1YqrVu3rht/XKtjx44Nxgglyfrrr99g2QYbbJC33357eZVXp127dpkxY0aD5eecc05Gjhy5xLG3PXv2LNz/uHHj0qxZs6y33nr1lm+44YZNqrO0hNvCi1RVVS32trE5c+Y0GLu83nrrZciQIXnmmWey6aab5uc///kKO3ay8FyX5oIBgGWjffv2SRaONV5aCxYsyOWXX571118/rVq1yqqrrpouXbrkn//8Z6ZNm1bX7tRTT011dXW23XbbrL/++hk8eHD+9re/1dvXJZdckhdffDFrrbVWtt122wwZMmSRX8YvztVXX52RI0fm0Ucfzcsvv5w333wze+65Z702LVq0yJprrllv2euvv55p06ala9eu9b5Q79KlS2bMmJGPP/44SepC5uevZ7p06VL45XftLeSbbbZZo89nSSZMmJBZs2Yt8jpj4403zoIFCzJ+/Ph6y9dee+16v9fWvKhrNviyMOaZlUrz5s2X6f4qKioWGSA/OwHZ0thoo43y/PPPZ968eXXjlpIlj5Ou1ZgJs/5dteOx/p0PsO7du6empiYff/xxunbtWrf8008/zaRJk+rGnX3WQw89lCR5//33M2nSpKy22mor7NhTpkxZ5BcqAKwY7du3z+qrr95g8s6muOCCC/Lzn/883//+93PuueemU6dOadasWX7yk59kwYIFde023njjvPrqq7n//vvzpz/9KSNGjMg111yTX/ziF3WPZjr44IOz88475+67785DDz2UX/7yl7n44otz1113Za+99iqsZdttty28g+qzPeW1FixYkK5du+aWW25Z5Daf7yT4olrcNdu/88U9rOz0PPOF9frrrzdY9tprr9XNop0s/BZ06tSpDdp9/paipvZY7rPPPpk9e3buvvvuJm3XWOuss04WLFhQ981yrVdffbVR29fOAF47I+jS2GqrrZIkzz77bL3lzz77bBYsWFC3vtavf/3rjBw5Mueff34+/fTTDBo0aIUde/78+Rk/fnw23njjpT4mAP++ffbZJ2+88Ub+/ve/L9X2d955Z77+9a9n2LBhOeSQQ9K3b9/svvvui/wsb9u2bQYMGJDf//73eeedd7L33nvn/PPPz5w5c+radO/ePcccc0zuueeevPXWW+ncuXPOP//8pT29RllvvfUyadKk7Ljjjtl9990bvLbccsskCz/rk4bXMxMmTCj88rv2zrSiLyoae33TpUuXtGnTZpHXGa+88kqaNWuWtdZaq1H7gi8z4ZkvrHvuuSfvvfde3e9PP/10Ro0aVe/b5PXWWy+vvPJKvUcnPP/88w1u7aqdHXNRH86LcvTRR6dbt2454YQT8tprrzVY/+9+61p7Dr/61a/qLR86dGijtl9jjTWy1lprNQifTbHbbrulU6dOufbaa+stv/baa9OmTZt6M3+/9dZbOfnkk/Ptb387p59+ei699NLce++9ufHGG5f7sZPk5Zdfzpw5c5Z6dlcAlo1TTjklbdu2zVFHHZWPPvqowfo33nij7lFKi9K8efMGn6HDhw+v93mf/N/cHrUqKyuzySabpFQqZd68eampqal3m3eSdO3aNauvvnrmzp3b1NNqkoMPPjg1NTU599xzG6ybP39+3bXG7rvvnpYtW+bKK6+sd86N+azfeuut07NnzwwdOrTBtctn99W2bdskxdc3zZs3T9++ffO///u/9Ya/ffTRR7n11luz00471d2WD//J3LbNF1avXr2y00475eijj87cuXMzdOjQdO7cOaecckpdm+9///v5f//v/2XPPffMD37wg3z88cf59a9/nU033bTexBdVVVXZZJNNcvvtt2eDDTZIp06dstlmmy12LFGnTp1y9913Z999982WW26ZQw45JF/96lfTsmXLjB8/PsOHD0/ScDxQY2211VY59NBDc80112TatGnZYYcd8sgjj+Rf//pXo/ex33775e67724wFnjcuHF1j6yoDdfnnXdekoXfgn/3u99NsvA9OffcczN48OAcdNBB2XPPPfPXv/41N998c84///x06tQpycIP6e9///upqqqqC7uDBg3KiBEjcvzxx2f33Xevu816WR+71siRI9OmTZvssccejX5/AFj21ltvvdx6660ZMGBANt544xxxxBHZbLPN8umnn+bJJ5/M8OHDM3DgwMVuv88+++Scc87JkUcemR122CEvvPBCbrnllnqTWCVJ3759s9pqq2XHHXdMt27dMnbs2Fx11VXZe++9065du0ydOjVrrrlm+vfvny233DLV1dV5+OGH88wzz+Syyy5bru/BrrvumkGDBuXCCy/MmDFj0rdv37Rs2TKvv/56hg8fniuuuCL9+/dPly5dctJJJ+XCCy/MPvvsk379+mX06NH54x//mFVXXXWJx2jWrFmuvfba7Lvvvtlqq61y5JFHpnv37nnllVfy0ksv5cEHH0yy8BGPycIJSPfcc880b948hxxyyCL3ed5552XkyJHZaaedcswxx6RFixa57rrrMnfu3FxyySXL9k2CL6oyzfLNf7jFPaqqbdu2Ddp+/jFOtY+q+uUvf1m67LLLSmuttVapVatWpZ133rn0/PPPN9j+5ptvLq277rqlysrK0lZbbVV68MEHGzyqqlQqlZ588slS7969S5WVlY1+bNUHH3xQOvnkk0ubbLJJqaqqqtSqVavSuuuuWzriiCNKjz/++CLPY8KECYXnWCqVSrNnzy4dd9xxpc6dO5fatm1b2nfffUvjx49vdG3PPfdcKUnpr3/9a73ltY+7WNRrUY/1+s1vflPacMMNS5WVlaX11luvdPnll9d7NMUVV1xRSlIaMWJEve3eeeedUvv27Uv9+vVbbseutd1225W+853vFL4nAKwYr732WumHP/xhqUePHqXKyspSu3btSjvuuGPpyiuvLM2ZM6eu3aIeVfXTn/601L1791JVVVVpxx13LP39739v8OjJ6667rrTLLruUOnfuXGrVqlVpvfXWK5188smladOmlUqlUmnu3Lmlk08+ubTllluW2rVrV2rbtm1pyy23LF1zzTWFtS/qGmVRFnfdUus3v/lNqXfv3qWqqqpSu3btSptvvnnplFNOKb3//vt1bWpqakpnn3123fn26dOn9OKLLzZ4Xz7/qKpaTzzxRGmPPfaoO8ctttiidOWVV9atnz9/funHP/5xqUuXLqWKiop61xqLup547rnnSnvuuWepurq61KZNm9LXv/710pNPPtmo92dxNcKXSUWpZFQ/Xyxvv/12evbsmV/+8pc56aSTyl3OSu0b3/hGVl999bre3i+jMWPGZOutt85zzz3XYCw0AAAsK8Y8w5fYBRdckNtvv/1L/czFiy66KP379xecAQBYrox5hi+x7bbbbrHPS/6yuO2228pdAgAA/wH0PAMAAEABY54BAACggJ5nAAAAKCA8AwAAQAHhGQAAAAo0erbtTU+9fHnWsVzM3HRuuUtoki/i6PPmEyvLXULTVXzx3uhuT5e7gqb7cN8v1v9/nR9uXe4SmmzegVPKXUKTzRzbsdwlNNm/Tjmx3CUAACsBPc8AAABQQHgGAACAAsIzAAAAFBCeAQAAoIDwDAAAAAWEZwAAACggPAMAAEAB4RkAAAAKCM8AAABQQHgGAACAAsIzAAAAFBCeAQAAoIDwDAAAAAWEZwAAACggPAMAAEAB4RkAAAAKCM8AAABQQHgGAACAAsIzAAAAFBCeAQAAoIDwDAAAAAWEZwAAACggPAMAAEAB4RkAAAAKCM8AAABQQHgGAACAAsIzAAAAFBCeAQAAoIDwDAAAAAWEZwAAACggPAMAAEAB4RkAAAAKCM8AAABQQHgGAACAAsIzAAAAFBCeAQAAoIDwDAAAAAWEZwAAACggPAMAAEAB4RkAAAAKCM8AAABQQHgGAACAAsIzAAAAFBCeAQAAoECLxjZc679fWZ51LBfjj9yo3CU0SfV7C8pdQpO1f2tmuUtoss6XjS93CU32+ktfrL/lJGk9tqrcJTTJnFXLXUHTffp8x3KX0HTrzyp3BQAAS0XPMwAAABQQngEAAKCA8AwAAAAFhGcAAAAoIDwDAABAAeEZAAAACgjPAAAAUEB4BgAAgALCMwAAABQQngEAAKCA8AwAAAAFhGcAAAAoIDwDAABAAeEZAAAACgjPAAAAUEB4BgAAgALCMwAAABQQngEAAKCA8AwAAAAFhGcAAAAoIDwDAABAAeEZAAAACgjPAAAAUEB4BgAAgALCMwAAABQQngEAAKCA8AwAAAAFhGcAAAAoIDwDAABAAeEZAAAACgjPAAAAUEB4BgAAgALCMwAAABQQngEAAKCA8AwAAAAFhGcAAAAoIDwDAABAAeEZAAAACgjPAAAAUEB4BgAAgALCMwAAABQQngEAAKCA8AwAAAAFhGcAAAAo0KKxDed8pefyrGO5+PSrM8pdQpOUPmhT7hKa7MOfzSt3CU02cXKXcpfQZFO3LJW7hCYrdZpb7hKapEXl/HKX0GSrPNi23CU0WWn8F+/fuQwodwEAwMpAzzMAAAAUEJ4BAACggPAMAAAABYRnAAAAKCA8AwAAQAHhGQAAAAoIzwAAAFBAeAYAAIACwjMAAAAUEJ4BAACggPAMAAAABYRnAAAAKCA8AwAAQAHhGQAAAAoIzwAAAFBAeAYAAIACwjMAAAAUEJ4BAACggPAMAAAABYRnAAAAKCA8AwAAQAHhGQAAAAoIzwAAAFBAeAYAAIACwjMAAAAUEJ4BAACggPAMAAAABYRnAAAAKCA8AwAAQAHhGQAAAAoIzwAAAFBAeAYAAIACwjMAAAAUEJ4BAACggPAMAAAABYRnAAAAKCA8AwAAQAHhGQAAAAoIzwAAAFBAeAYAAIACwjMAAAAUEJ4BAACggPAMAAAABVo0tuHM1SuXZx3LRfs/fbFqrpxZU+4SmqzTGQvKXUKTjT1+lXKX0GT77fxsuUtosv99Zutyl9AkpQ9albuEJuv8z+nlLqHJJm7VvtwlAAAsFT3PAAAAUEB4BgAAgALCMwAAABQQngEAAKCA8AwAAAAFhGcAAAAoIDwDAABAAeEZAAAACgjPAAAAUEB4BgAAgALCMwAAABQQngEAAKCA8AwAAAAFhGcAAAAoIDwDAABAAeEZAAAACgjPAAAAUEB4BgAAgALCMwAAABQQngEAAKCA8AwAAAAFhGcAAAAoIDwDAABAAeEZAAAACgjPAAAAUEB4BgAAgALCMwAAABQQngEAAKCA8AwAAAAFhGcAAAAoIDwDAABAAeEZAAAACgjPAAAAUEB4BgAAgALCMwAAABQQngEAAKCA8AwAAAAFhGcAAAAoIDwDAABAAeEZAAAACgjPAAAAUEB4BgAAgALCMwAAABQQngEAAKBARalUKjWm4U/HHLy8a1nm/nTb9uUuoUn6Dniq3CU02aO/3a7cJTRZiznlrqDpujz2XrlLaLK3vrNmuUtoktX/9sX7w5i4Wetyl9BkT546tNwlNFn16uPKXQIAsBLQ8wwAAAAFhGcAAAAoIDwDAABAAeEZAAAACgjPAAAAUEB4BgAAgALCMwAAABQQngEAAKCA8AwAAAAFhGcAAAAoIDwDAABAAeEZAAAACgjPAAAAUEB4BgAAgALCMwAAABQQngEAAKCA8AwAAAAFhGcAAAAoIDwDAPCl0adPn1RUVGTIkCEN1vXo0SMVFRW5/vrrV3hdy1tFRUUqKiry2GOPlbsU+NISngEASJIMGTKkLoR99tW6deusueaa+da3vpU77rgjpVKp3KWuFN5+++0MGTJkkUH9y2Rxfxeff/3rX/9a7D7mzp2bK6+8MjvttFM6duyY1q1bp0ePHjnqqKPy8ssvr8CzgaXXotwFAACw8unWrVvdz9OmTct7772X9957L/fdd1+uv/763H333WnVqlUZK2y69dZbL61bt84qq6yyTPb39ttv5+yzz06SL32ATpKWLVumU6dOi13fosWio8WHH36Yfv36ZfTo0XX7qa6uzrhx4zJs2LDcfPPN+e///u8cdthhy6VuWFb0PAMA0MCHH35Y95o5c2ZefPHF7LHHHkmSP/7xjznzzDPLXGHTPfLII3nllVdywAEHlLuUL6Qddtih3t/F5189evRosE2pVMq3v/3tjB49OlVVVfntb3+b6dOnZ/LkyXn//fdzxBFHZO7cuRk4cGD+8Y9/rPiTgiYQngEAWKJmzZpl0003zb333ptevXolSa677rrMnz+/zJWxsvvDH/6QJ598Mkly4YUX5qijjkrr1q2TJN27d88NN9yQr33ta5k3b15OOeWUcpYKhYRnAAAapXXr1jnooIOSJJ988kleeeWVJAtvX64d9/r222/njTfeyI9+9KP07NkzrVq1atAjuWDBgtxyyy3p169funXrlsrKynTp0iV9+/bN//zP/yxxTHVNTU2uvPLKbL311mnbtm06deqUPn365M477yysvzETho0aNSpHHnlkevXqlTZt2qR9+/bZZJNN8v3vfz8PPvhgvX19/etfr/v98+N/Bw4c2GDfn3zySS666KJsv/326dSpU1q1apW11lorhxxySP7+978vsfYpU6bk5JNPrrv1vHv37jnooINW+t7aP/zhD0mStm3b5phjjllkm5NPPjlJ8uc//znvvPPOCqsNmsqYZwAAGm3NNdes+3n69OkN1j/55JMZNGhQZsyYkTZt2qRly5b11k+ePDkHHHBAHn/88bplq6yySiZOnJiRI0dm5MiRue222zJ8+PBUVlbW23bu3LnZb7/96kJss2bNUllZmccffzx/+ctfcuqppy71edXU1OTEE0/Mr371q7plbdu2TYsWLfLKK69k7NixueuuuzJ16tQkSZcuXTJ9+vRMmTIlSf0x4rXn9FljxozJvvvum3fffTdJ0rx587Rp0ybvvvtubr/99txxxx05//zzc9pppzWo7e23306fPn0ybty4JEllZWVmzZqVO++8M/fee2+GDx++xHMbOHBgbrjhhiRZ4ZO91dbcq1evBn8LtTbeeOO6nx966KEcddRRK6Q2aCo9zwAANNrbb79d9/OiJo8aNGhQNt100zzzzDOZOXNmZsyYkYceeijJwoB64IEH5vHHH89WW22V++67LzNnzszUqVMzY8aM3HDDDenatWvuvffeRQbh0047LQ8++GAqKipy3nnnZcqUKZkyZUo+/PDDHH300bn44oszZsyYpTqv008/vS44f//738+rr76aGTNmZPLkyZkyZUruueeefPOb36xr/8wzz+Suu+6q+/3z43+vuOKKunUffPBB9txzz7z77rs58MAD8+yzz2b27NmZPn16Pvroo/z85z9P8+bNc/rpp+eee+6pV1dNTU0OOuigjBs3Lh07dswdd9yRmTNnZtq0aXnppZey3Xbb5Xvf+95SnXNTvfTSS9lss83Spk2bVFdXZ8MNN8wPf/jDuonAlqSmpqZR61544YVlUissD8IzAACNMn369Nxyyy1JFgbnDTbYoEGbzp075+GHH84222xTt6y23a233pq//OUv2WijjfLYY49ln332SZs2bZIs7OU94ogj8sADD6SioiLXXHNNPv7447p9vP/++7nyyiuTJGeeeWbOOOOMtG/fPknStWvXXHPNNTn00EMzbdq0Jp/Xa6+9lksvvTRJcsopp2TYsGH1zm2VVVbJfvvtl9tuu63J+66t9+OPP85hhx2WESNGpHfv3nW9sF27ds0555yTSy65JEnDWbtHjBiRZ599NkkyfPjwHHTQQXWzWm+yySb505/+lM6dOy9VXU01ceLEjB07NlVVVZk7d25ee+21/O53v0vv3r0XO4Fc7S37//rXvzJnzpxFtnnxxRfrfn7//feXed2wrAjPAAAs0dSpU/PII49kt912qws3xx9/fJo1a3gpeeyxx6a6unqR+xk2bFiS5Oijj17s46J69+6dTTfdNJ9++mkeffTRuuV33nln5s+fn6qqqpx00kmL3HZpHxd1ww03ZMGCBencuXPdo6eWlTlz5uTWW29NkiXeVn7EEUckSZ5//vl89NFHdctrA/uOO+6Yb3zjGw22a9OmTeFEW9dff31KpdJS37K9/vrr55JLLsmrr76aOXPmZNKkSZk5c2YefPDB9O7dO6VSKeeff34uu+yyBtv269cvycL3YVHra2pqctFFF9X9vqihALCyMOYZAIAGKioqFrvuO9/5Ts4444xFrttxxx0XubympiZPPfVUkoUh94ILLljs/idPnpzk/8bLJqnrfd1mm23qepw/b4MNNsgaa6yR9957b7H7XpTa2aD32GOPupmgl5V//OMfdT2uffv2bdQ248aNqxtDXXveu+2222LbL2ndsnD44Yc3WFZZWZm+fftml112yS677JJnnnkmQ4YMyVFHHVXvi5G999472223XUaNGpUhQ4akoqIiRx55ZFZdddW8/PLLOeOMM/L888+nZcuWmTdv3iK/kIGVhfAMAEADn50Aq1WrVll11VXzla98JYcffni9WaY/r2vXrotcPnny5MydOzdJ6ibZKjJr1qy6n2tv4V5jjTWWuM2aa67Z5PD84YcfJknWWWedJm3XGJ+9DfmzPcpL0tTz/uwkbita69atc8EFF2SPPfbIjBkz8sgjj+TAAw+sW19RUZG77ror/fr1y/PPP58zzjijwRcvgwcPzqhRo/Lss8+mY8eOK/oUoNGEZwAAGqgNlE3VvHnzRS7/7KRQf/zjH+tNvlVuS+pl/3d99rxnz569zHu2Vwbbb7993c9vvvlmg/Wrr756Ro0aleuvvz533313/vWvfyVZOGb7hz/8Yfbdd9+6Ly4WNY4eVhbCMwAAy13nzp3TokWLzJ8/v97t2I1V26Nd1Kvc1F7nJFlttdUyduzYpaqrMfuuNW7cuGy44YZN2r5r164ZP378Es9rac55RWvVqlUGDRqUQYMGNVj38ccf1z3feYcddljRpUGjGVQAAMBy17Jly2y77bZJkvvuu6/J29fO3v3ss89mxowZi2zz+uuv1z1HuSlqA9vIkSMXOyP0onx2fO7iJuP66le/Wve86n/nvD87edrn/fnPf27yfpel2rHsSdKzZ88mb187g/saa6yx3Mdvw79DeAYAYIX40Y9+lCR54IEH8sADDyyxbe2kYbW+/e1vp3nz5pk9e3bdY6U+75xzzlmqugYOHJjmzZtn0qRJOeussxq93WcnLps6deoi27Rt2zaHHXZYkuTiiy+u62FdnM+f94ABA5IkTzzxRB577LEG7WfPnp1f/vKXja65qYpm6J47d27dGOa2bdsuckbwJXnjjTdy7rnnJln4HO/ax3DBykh4BgBghfjOd76T3XffPaVSKQcccEDOO++8ehNqzZw5M48++mgGDx6cddddt962a6yxRgYPHpwkOffcc3PhhRfmk08+SZJMmDAhxx57bG6++ebFPgJrSXr16pWTTz45SXLJJZfkqKOOyuuvv163fvr06bn99ttzwAEH1Ntugw02qOtV/t3vfrfYoHnBBRdk9dVXz8SJE7P99tvnpptuqqu9tv4RI0bkgAMOyKGHHlpv229/+9vZeuut634eMWJE3TjqsWPHZq+99sqECROWeH4DBw5MRUXFUo3tfvzxx7P77rvnpptuqterP2/evDzyyCPZeeedM2rUqCTJL37xi3To0KHBPm688cb89re/zbvvvpsFCxYkSaZNm5Zhw4Zlhx12yJQpU/LNb34zxxxzTJPrgxXJVzsAAKwQzZs3z4gRI3L44Yfn/vvvz89//vP8/Oc/T/v27dOsWbNMmzatLoAuqgfy4osvzssvv5yHH344p59+et22U6dOTalUyqmnnpqnnnoqf/nLX5pc23nnnZdPPvkkV199dYYNG5Zhw4aluro6LVu2rNv/54N5mzZt8t3vfjfDhg3LKaeckiFDhmTVVVdNRUVF+vfvX9dD3r179zz88MPZf//989prr+WII45Is2bN0qFDh8ydOzczZ86s2+fuu+9e7xgtWrTI8OHD06dPn4wfPz79+/dPq1at0rp160ybNi2VlZUZPnx49ttvvyafc2OUSqU88sgjeeSRR5IkVVVVadu2baZNm5Z58+YlWXj7+s9+9rPFPm/6ueeeyxVXXJFk4e37tdvX/rfu379/brrppuU6cRssC3qeAQBYYdq3b5/77rsvDzzwQAYMGJC11147c+fOzaxZs7LGGmukb9++ufDCC/Pqq6822LZ169b54x//mCuuuCJbbbVVKisrUyqVsvPOO+eOO+7IRRddtNR1NW/ePFdddVWeeOKJHH744Vl77bUzb968lEqlbLLJJvnBD36QESNGNNju6quvzpAhQ7L55psnSd55552MGzcuEydOrNdu4403zj//+c9cd9116du3b1ZdddVMnz49pVIpvXr1ykEHHZTf/OY3ueOOOxocY911182YMWNy4oknpmfPnimVSmndunX69++fJ598Mt/61reW+ryLbL755rn00kvz7W9/OxtssEGqqqoyderUVFVVZcstt8yxxx6bMWPG5Pzzz1/sPgYMGJAf/vCH2WyzzVJdXZ3Zs2dnzTXXzIABA/KnP/0pw4cP/1LOQs6XT0WpaCDD/++nYw5e3rUsc3+6bfviRiuRvgOeKm60knn0t9uVu4Qma9H4eUBWGl0eW/ln0fy8t75TvmdOLo3V//bF+8OYuNkX70LjyVOHlruEJqtefdnPvgsAfPHoeQYAAIACwjMAAAAUEJ4BAACggPAMAAAABYRnAAAAKCA8AwAAQIFGP6pqw7MvX961LHNrn/1kuUtoktn7b1vuEppsWs8W5S6hyeZu/0m5S2iyVk+2K3cJTVY5rVH/tKw0ZnerKHcJTTazx/xyl9Bka99f7gqa7q/3nlzuEgCAlYCeZwAAACggPAMAwErk+uuvT0VFRXr06FHuUoDPEJ4BACi7KVOmpKqqKhUVFamoqMjrr7++XI4zZsyYDBkyJEOHDl0u+/+imD17di6//PLsvPPO6dy5c1q2bJlVVlklvXv3zhlnnJEPP/yw3CXCSkd4BgCg7G655ZbMmTOn7vf//u//Xi7HGTNmTM4+++z/6PA8bty4bLnlljnxxBPzxBNPZPLkyWnbtm1mzJiR5557LhdccEE22mijPP744+UuFVYqwjMAAGU3bNiwJMmPf/zjJMkNN9yQmpqacpb0pXXEEUfk9ddfT2VlZa666qp88sknmTp1ambPnp3//d//zRprrJFp06bl4IMPzuzZs8tdLqw0hGcAAMrqueeey5gxY9KhQ4dccskl6dmzZz744IM88MAD5S7tS2fcuHF1PcqnnXZaBg8enOrq6iRJZWVlvvWtb+WGG25Iknz00Ud6n+EzhGcAAMqqttd5wIABad26dY444ogkjb91+6GHHsohhxySddZZJ1VVVenUqVO22GKL/PjHP87f//73unYVFRU58sgjkywMkbXjq2tfQ4YMqWvbp0+fBss+b8iQIamoqEifPn0arJsyZUqGDRuWgw8+OJtvvnk6deqU1q1bZ5111slhhx2Wp556qlHntqx98MEHdT9vs802i2yz7bb/9/jUGTNmLPea4ItCeAYAoGzmzJmTW2+9NUnqQvMRRxyRioqK3H///fnoo48Wu+2sWbNy8MEHZ88998ztt9+ed955Jy1btsyCBQvywgsv5KqrrsrRRx9d175bt25p3759kqRZs2bp1q1bvVdtD+yycMUVV+Soo47K8OHDM3bs2Lrl77zzTv7nf/4nO+ywQ371q18t1b579Oix2NBeZN111637+dlnn11km6effjrJwvfoK1/5ylLVCF9GwjMAAGUzYsSITJ06Nb169coOO+yQZGHA22mnnTJ//vzceOONi932yCOPzPDhw9OsWbOceuqpGT9+fKZPn56pU6dmwoQJueWWW7L99tvXtf/www9zxRVXJEnWWmutfPjhh/VeJ5100jI7r9VXXz1nnXVWnn322cyaNSuTJ0/O7Nmz8+abb+b4449Pkpx44okZPXr0MjtmY3Tt2jUHHnhgkuTCCy/M1VdfXde7PG/evNx777353ve+lyT56U9/Wi9sw3864RkAgLKpvWW7tte5VtGt24888kjuuOOOJMlVV12Viy66KGuuuWbd+lVXXTWHHXZYrr322uVRdqEf/ehHGTJkSHr37p3KysokC28b79mzZ4YOHZpjjjkmNTU1ufrqq1d4bb/73e+y55575tNPP82xxx6bdu3apUOHDmndunX222+/dOrUKb/97W9zySWXrPDaYGUmPAMAUBZvvvlmHnvssVRUVOS73/1uvXUHH3xwqqqq8sorr+TJJ59ssG1tqN5ss83q3Zr9RbH33nsnSZ544okmb/v222+nVCrlscceW6pjd+zYMXfddVd++tOfpqKiIkkybdq0LFiwIMnCcc4TJ0402zl8jvAMAEBZ/P73v0+pVMrOO++cHj161FvXvn377L///kn+r3f6s2oD9T777LO8y1xqb775Zk466aT07t07HTp0SPPmzesmJ+vXr1+S5N13313hdY0ePTobbbRRLr/88hxzzDF54YUXMnPmzLzxxhsZOnRoJk+enNNOOy377rtvXaAGhGcAAMpgwYIFuf7665M0vGW7Vu3Y2zvuuKPBrM8ffvhhkmSdddZZfkX+G+6+++5ssskmueyyy/Lcc89l2rRpqa6uTteuXdOtW7d07NgxSTJz5swVWtcnn3ySvfbaK+PHj8+ZZ56Zq666KptttlnatGmTddddN8cff3xGjBiRioqK/PGPf8zvf//7FVofrMyEZwAAVrgHH3ywrtf1qKOOavDYqIqKinzzm99MsvA24trxzbVqbzdeGU2aNCkDBw7M3Llzs9tuu+Wxxx7LrFmzMm3atHz00Uf58MMPM3z48LLUdvPNN9fNYP7Tn/50kW2+8Y1v1M2yPWLEiBVWG6zshGcAAFa4Rd2K3ZT2q622WpKFz2teHlq0aJFk4aO0FmfatGmLXP7AAw9k+vTp6dixY+67777suuuuqaqqqtemtud8RXv55ZeTJF26dKl7bNeirL/++kmSt956a4XUBV8EwjMAACvUhAkTcu+99yZJ7rzzznzyySeLfdU+c/jJJ5/Mq6++WreP2sda3XfffU06drNmCy9/S6XSEtvV3lY9fvz4xbYZNWrUIpfXbrPhhhumTZs2i2zz8MMPF9a6PNSe/8SJEzNr1qzFtqvtnW7Xrt0KqQu+CIRnAABWqJtuuinz5s3LKquskn333TfV1dWLfX31q1/NRhttlKR+7/MPfvCDJMlLL73UpMdR1fa2Tp06dYntttxyyyQLby9f1LjkP//5z/n73/++yG1XWWWVJMlrr722yJ7rMWPG5NZbb210zcvS1ltvnWThlwe//vWvF9nmxRdfrJsF/LPPyYb/dMIzAAArVG0I3m+//eqegbwkBx10UJLkxhtvzPz585MkX//613PIIYckSY499ticdtpp9WaunjhxYn73u9/Vhexam222WZJk+vTpDcZRf9bBBx+cZs2aZdKkSTn00EPr9j179uzccMMNOeCAA9KpU6dFbtu3b980a9YskydPzuGHH5733nsvSfLpp5/mjjvuSN++ff+tHt0ePXqkoqIiffr0afK2/fv3T/fu3ZMkp59+es4///xMmjQpycLJy2677bb07ds38+fPT2VlZY499tilrhO+bIRnAABWmKeeeqpu3G1tKC5S2+6jjz7KH/7wh7rlw4YNy4EHHpgFCxbkoosuylprrZVVVlklHTp0SJcuXfLDH/4w//jHP+rtq1evXvnGN76RJBkwYEDat2+fHj16pEePHhk6dGhduw022CBnnnlmkoW3hq+11lrp0KFD2rdvn4EDB2a33XbLMcccs8h6119//Zx88slJkrvuuitrrrlmOnTokOrq6gwYMCDV1dX51a9+1ahzX9batm2be+65J126dMncuXNz5plnZtVVV0379u3Trl27HHroofnggw/Spk2b3HLLLXVjnwHhGQCAFai213mVVVZJ3759G7XN5ptvno033rje9knSpk2bjBgxIvfff38OOOCArL766pkzZ05atGiRLbbYIscdd1x+85vfNNjfnXfemRNOOCEbbLBB5s2bl3HjxmXcuHENbuU+++yzc9NNN+VrX/ta2rZtm5qammy11Vb59a9/nbvuuivNmzdfbM0XXXRRbrzxxmy77bapqqrKvHnz0qtXr5x++ukZPXp0Vl999Uad+/Kw7bbbZuzYsTn33HPzta99LR07dsysWbPStm3bbLHFFjnhhBPywgsvpH///mWrEVZGFaWi2RL+fxueffnyrmWZW/vsJ8tdQpPM3n/bcpfQZNN6tih3CU02d/tPyl1Ck7V68os3WUfltEb907LSmN1t5X3kyeLM7DG/3CU02dr3l7uCpvvrvSeXuwQAYCWg5xkAAAAKCM8AAABQQHgGAACAAsIzAAAAFBCeAQAAoIDwDAAAAAWEZwAAACggPAMAAEAB4RkAAAAKCM8AAABQQHgGAACAAsIzAAAAFBCeAQAAoIDwDAAAAAWEZwAAACggPAMAAEAB4RkAAAAKCM8AAABQQHgGAACAAsIzAAAAFBCeAQAAoIDwDAAAAAWEZwAAACjQorEN23xYWp51LBfvnLVDuUtokq/t9UK5S2iyp/64eblLaLI2f64udwlN9twvril3CU32je/8oNwlNEnlgCnlLqHJZv2rS7lLaLL3dvWdLQDwxeQqBgAAAAoIzwAAAFBAeAYAAIACwjMAAAAUEJ4BAACggPAMAAAABYRnAAAAKCA8AwAAQAHhGQAAAAoIzwAAAFBAeAYAAIACwjMAAAAUEJ4BAACggPAMAAAABYRnAAAAKCA8AwAAQAHhGQAAAAoIzwAAAFBAeAYAAIACwjMAAAAUEJ4BAACggPAMAAAABYRnAAAAKCA8AwAAQAHhGQAAAAoIzwAAAFBAeAYAAIACwjMAAAAUEJ4BAACggPAMAAAABYRnAAAAKCA8AwAAQAHhGQAAAAoIzwAAAFBAeAYAAIACwjMAAAAUEJ4BAACggPAMAAAABYRnAAAAKCA8AwAAQAHhGQAAAAoIzwAAAFBAeAYAAIACwjMAAAAUaNHYhpO3qlmedSwXbd5p9OmtFMaftn65S2iyuQPnlLuEJqvZeH65S2iydYf/V7lLaLLW23+xvpur+Ue3cpfQZKXV5pW7hCarqfrifZYAACR6ngEAAKCQ8AwAAAAFhGcAAAAoIDwDAABAAeEZAAAACgjPAAAAUEB4BgAAgALCMwAAABQQngEAAKCA8AwAAAAFhGcAAAAoIDwDAABAAeEZAAAACgjPAAAAUEB4BgAAgALCMwAAABQQngEAAKCA8AwAAAAFhGcAAAAoIDwDAABAAeEZAAAACgjPAAAAUEB4BgAAgALCMwAAABQQngEAAKCA8AwAAAAFhGcAAAAoIDwDAABAAeEZAAAACgjPAAAAUEB4BgAAgALCMwAAABQQngEAAKCA8AwAAAAFhGcAAAAoIDwDAABAAeEZAAAACgjPAAAAUEB4BgAAgALCMwAAABQQngEAAKCA8AwAAAAFhGcAAAAo0KKxDVt2mLs861guajrPLncJTTLto+pyl9BkLceXu4KmW++m6eUuocneOKfcFTRdi3e+WH/PbT8odwVN1/ZvFeUuockqFpS7gqVwZLkLAABWBnqeAQAAoIDwDAAAAAWEZwAAACggPAMAAEAB4RkAAAAKCM8AAABQQHgGAACAAsIzAAAAFBCeAQAAoIDwDAAAAAWEZwAAACggPAMAAEAB4RkAAAAKCM8AAABQQHgGAACAAsIzAAAAFBCeAQAAoIDwDAAAAAWEZwAAACggPAMAAEAB4RkAAAAKCM8AAABQQHgGAACAAsIzAAAAFBCeAQAAoIDwDAAAAAWEZwAAACggPAMAAEAB4RkAAAAKCM8AAABQQHgGAACAAsIzAAAAFBCeAQAAoIDwDAAAAAWEZwAAACggPAMAAEAB4RkAAAAKCM8AAABQQHgGAACAAsIzAAAAFBCeAQAAoIDwDAAAAAWEZwAAACggPAMAAECBFo1tWPl82+VZx3LR/W+zy11Ck3ywQ0W5S2iy6ndK5S6hySpmzCp3CU3W/k9dyl1Cky1o+cX625iyyRer3iRpPrd5uUtostldfWcLAHwxuYoBAACAAsIzAAAAFBCeAQAAoIDwDAAAAAWEZwAAACggPAMAAEAB4RkAAAAKCM8AAABQQHgGAACAAsIzAAAAFBCeAQAAoIDwDAAAAAWEZwAAACggPAMAAEAB4RkAAAAKCM8AAABQQHgGAACAAsIzAAAAFBCeAQAAoIDwDAAAAAWEZwAAACggPAMAAEAB4RkAAAAKCM8AAABQQHgGAACAAsIzAAAAFBCeAQAAoIDwDAAAAAWEZwAAACggPAMAAEAB4RkAAAAKCM8AAABQQHgGAACAAsIzAAAAFBCeAQAAoIDwDAAAAAWEZwAAACggPAMAAEAB4RkAAAAKCM8AAABQQHgGAACAAsIzAAAAFBCeAQAAoIDwDAAAAAUqSqVSqdxFAAAAwMpMzzMAAAAUEJ4BAACggPAMAAAABYRnAAAAKCA8AwAAQAHhGQAAAAoIzwAAAFBAeAYAAIACwjMAAAAU+P8At17Zq8X5qvoAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualize_predictions(model, test_loader, device='cpu', num_samples=5):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    samples_visualized = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in test_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)  # Predicted class indices\n",
    "\n",
    "            for i in range(inputs.size(0)):\n",
    "                input_grid = inputs[i].cpu().numpy().reshape(10, 10)  # Input grid\n",
    "\n",
    "                # Use torch.argmax() to get the class index from targets\n",
    "                predicted_class = predicted[i].item()\n",
    "                actual_class = torch.argmax(targets[i]).item()\n",
    "\n",
    "                fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "                # Input Grid\n",
    "                axs[0].imshow(input_grid, cmap='viridis', interpolation='nearest')\n",
    "                axs[0].set_title(\"Input Grid (10x10)\")\n",
    "                axs[0].axis('off')\n",
    "\n",
    "                # Predicted and Actual Class Labels\n",
    "                axs[1].text(0.5, 0.5, f\"Predicted: {predicted_class}\\nActual: {actual_class}\",\n",
    "                            fontsize=18, ha='center', va='center')\n",
    "                axs[1].set_title(\"Class Prediction\")\n",
    "                axs[1].axis('off')\n",
    "\n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "\n",
    "                samples_visualized += 1\n",
    "                if samples_visualized >= num_samples:\n",
    "                    return\n",
    "\n",
    "# Visualize predictions\n",
    "visualize_predictions(model, test_loader, device=device, num_samples=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1ba210-96e1-4d32-9100-c6e7835972ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data/generate_and_visualize.py\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "def visualize_batch(batch):\n",
    "    \"\"\"\n",
    "    Visualizes a batch of images.\n",
    "\n",
    "    Args:\n",
    "        batch (dict): Batch containing color_image, grayscale_image, numeric_image, and grid.\n",
    "    \"\"\"\n",
    "    color_images = batch['color_image']\n",
    "    grayscale_images = batch['grayscale_image']\n",
    "    numeric_images = batch['numeric_image']\n",
    "    grids = batch['grid']\n",
    "\n",
    "    batch_size = color_images.size(0)\n",
    "    fig, axs = plt.subplots(batch_size, 3, figsize=(12, 4 * batch_size))\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        # Color Image\n",
    "        axs[i, 0].imshow(color_images[i].permute(1, 2, 0))\n",
    "        axs[i, 0].set_title(f\"Color Image\\nGrid:\\n{grids[i].numpy()}\")\n",
    "        axs[i, 0].axis('off')\n",
    "\n",
    "        # Grayscale Image\n",
    "        axs[i, 1].imshow(grayscale_images[i].squeeze(), cmap='gray')\n",
    "        axs[i, 1].set_title(\"Grayscale Image\")\n",
    "        axs[i, 1].axis('off')\n",
    "\n",
    "        # Numeric Image\n",
    "        axs[i, 2].imshow(numeric_images[i].permute(1, 2, 0))\n",
    "        axs[i, 2].set_title(\"Numeric Image\")\n",
    "        axs[i, 2].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def main():\n",
    "    train_loader, eval_loader = get_data_loaders(batch_size=4, grid_size=10, num_classes=11, augment=True)\n",
    "\n",
    "    # Get a batch of training data\n",
    "    batch = next(iter(train_loader))\n",
    "\n",
    "    # Visualize the batch\n",
    "    visualize_batch(batch)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04dcce3e-0e37-425e-a8b1-c9f03fcfb705",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data/data_conversion.py (continued)\n",
    "\n",
    "import pickle\n",
    "\n",
    "def save_datasets(train_grids, eval_grids, filepath='data/grids.pkl'):\n",
    "    \"\"\"\n",
    "    Saves the training and evaluation grids to a pickle file.\n",
    "\n",
    "    Args:\n",
    "        train_grids (list of np.ndarray): Training grids.\n",
    "        eval_grids (list of np.ndarray): Evaluation grids.\n",
    "        filepath (str, optional): Path to save the pickle file. Defaults to 'data/grids.pkl'.\n",
    "    \"\"\"\n",
    "    with open(filepath, 'wb') as f:\n",
    "        pickle.dump({'train_grids': train_grids, 'eval_grids': eval_grids}, f)\n",
    "    logger.info(f\"Saved grids to {filepath}.\")\n",
    "\n",
    "\n",
    "def load_datasets(filepath='data/grids.pkl'):\n",
    "    \"\"\"\n",
    "    Loads the training and evaluation grids from a pickle file.\n",
    "\n",
    "    Args:\n",
    "        filepath (str, optional): Path to the pickle file. Defaults to 'data/grids.pkl'.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (train_grids, eval_grids)\n",
    "    \"\"\"\n",
    "    if not os.path.exists(filepath):\n",
    "        logger.error(f\"File {filepath} does not exist.\")\n",
    "        return None, None\n",
    "\n",
    "    with open(filepath, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    logger.info(f\"Loaded grids from {filepath}.\")\n",
    "    return data['train_grids'], data['eval_grids']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d518c9-9d0a-43ec-b1cf-87834e72dbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training/trainer.py\n",
    "\n",
    "# ==========================\n",
    "# 1. Standard Library Imports\n",
    "# ==========================\n",
    "import logging\n",
    "\n",
    "# ==========================\n",
    "# 2. Third-Party Library Imports\n",
    "# ==========================\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "\n",
    "# ==========================\n",
    "# 3. Local Application/Module Imports\n",
    "# ==========================\n",
    "\n",
    "def train_regular_model(\n",
    "    model, train_loader, eval_loader, num_epochs, initial_lr, gui, model_num, \n",
    "    total_models, device, tuner, shared_layer=None, redis_manager=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Trains a single model over a specified number of epochs.\n",
    "    \"\"\"\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=initial_lr, weight_decay=1e-4)\n",
    "    scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3, verbose=True)\n",
    "    criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "    scaler = GradScaler() if torch.cuda.is_available() else None\n",
    "\n",
    "    best_val_loss, best_val_accuracy = float('inf'), 0.0\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        model.train()\n",
    "\n",
    "        total_loss, correct_predictions, total_samples = 0, 0, 0\n",
    "\n",
    "        for batch_idx, (inputs, labels) in enumerate(train_loader):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            if shared_layer:\n",
    "                inputs = shared_layer(inputs)\n",
    "\n",
    "            try:\n",
    "                with autocast(enabled=torch.cuda.is_available()):\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, labels) / 4\n",
    "\n",
    "                scaler.scale(loss).backward() if scaler else loss.backward()\n",
    "\n",
    "                if (batch_idx + 1) % 4 == 0:\n",
    "                    if scaler:\n",
    "                        scaler.step(optimizer)\n",
    "                        scaler.update()\n",
    "                    else:\n",
    "                        optimizer.step()\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                total_loss += loss.item() * 4\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                correct_predictions += (predicted == labels).sum().item()\n",
    "                total_samples += labels.size(0)\n",
    "\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Error in batch {batch_idx}: {e}\")\n",
    "                continue\n",
    "\n",
    "        avg_train_loss = total_loss / len(train_loader)\n",
    "        train_accuracy = correct_predictions / total_samples\n",
    "\n",
    "        val_loss, val_accuracy = evaluate_model(model, eval_loader, criterion, device)\n",
    "\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        # Use Hyperparameter Tuner to adjust learning rate\n",
    "        if tuner:\n",
    "            tuner.adjust_learning_rate(optimizer, val_loss)\n",
    "            if tuner.early_stopping():\n",
    "                logging.info(\"Early stopping triggered by HyperparameterTuner.\")\n",
    "                break\n",
    "\n",
    "        # Update Redis with current metrics\n",
    "        if redis_manager:\n",
    "            current_metrics = {\n",
    "                'model_num': model_num,\n",
    "                'total_models': total_models,\n",
    "                'epoch': epoch,\n",
    "                'total_epochs': num_epochs,\n",
    "                'loss': avg_train_loss,\n",
    "                'accuracy': train_accuracy,\n",
    "                'val_loss': val_loss,\n",
    "                'val_accuracy': val_accuracy,\n",
    "                'lr': optimizer.param_groups[0]['lr']\n",
    "            }\n",
    "            redis_manager.set_value('current_metrics', current_metrics)\n",
    "\n",
    "        gui.queue.put({\n",
    "            'type': 'epoch',\n",
    "            'model_num': model_num,\n",
    "            'total_models': total_models,\n",
    "            'epoch': epoch,\n",
    "            'total_epochs': num_epochs,\n",
    "            'loss': avg_train_loss,\n",
    "            'accuracy': train_accuracy,\n",
    "            'val_loss': val_loss,\n",
    "            'val_accuracy': val_accuracy,\n",
    "            'lr': optimizer.param_groups[0]['lr']\n",
    "        })\n",
    "\n",
    "    return model, None\n",
    "\n",
    "def evaluate_model(model, eval_loader, criterion, device):\n",
    "    \"\"\"\n",
    "    Evaluates the model on the evaluation dataset.\n",
    "    \n",
    "    Args:\n",
    "        model (nn.Module): The trained model.\n",
    "        eval_loader (DataLoader): DataLoader for evaluation data.\n",
    "        criterion (nn.Module): Loss function.\n",
    "        device (torch.device): Device to perform computation on.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (average_loss, accuracy)\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    total_loss, correct_predictions, total_samples = 0, 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in eval_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct_predictions += (predicted == labels).sum().item()\n",
    "            total_samples += labels.size(0)\n",
    "\n",
    "    avg_loss = total_loss / len(eval_loader)\n",
    "    accuracy = correct_predictions / total_samples\n",
    "\n",
    "    return avg_loss, accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9f9dff-29a6-445c-a924-b1ec899f82bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training/trainer.py (excerpt)\n",
    "\n",
    "from data.data_conversion import get_data_loaders_variable_sizes\n",
    "from models import MLPMagician, CNNMagician  # Import necessary models\n",
    "from torch import nn, optim\n",
    "\n",
    "def main_training():\n",
    "    # Parameters\n",
    "    batch_size = 32\n",
    "    grid_sizes = [3, 5, 10]\n",
    "    num_classes = 11\n",
    "    augment = True\n",
    "    num_models = 6\n",
    "    num_epochs = 50\n",
    "    initial_lr = 0.001\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Create data loaders\n",
    "    train_loader, eval_loader = get_data_loaders_variable_sizes(\n",
    "        batch_size=batch_size,\n",
    "        grid_sizes=grid_sizes,\n",
    "        num_classes=num_classes,\n",
    "        augment=augment\n",
    "    )\n",
    "\n",
    "    # Initialize models, optimizers, loss functions, etc.\n",
    "    models = []\n",
    "    for i in range(num_models):\n",
    "        model = MLPMagician(input_size=grid_sizes[-1]**2, hidden_sizes=[256, 128, 64], dropout_rate=0.5)\n",
    "        model.to(device)\n",
    "        models.append(model)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizers = [optim.AdamW(model.parameters(), lr=initial_lr, weight_decay=1e-4) for model in models]\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        for model, optimizer in zip(models, optimizers):\n",
    "            model.train()\n",
    "            running_loss = 0.0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "\n",
    "            for batch in train_loader:\n",
    "                inputs = batch['color_image'].to(device)\n",
    "                targets = batch['grid'].to(device).view(-1)  # Flatten targets\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += targets.size(0)\n",
    "                correct += (predicted == targets).sum().item()\n",
    "\n",
    "            epoch_loss = running_loss / len(train_loader.dataset)\n",
    "            epoch_acc = correct / total\n",
    "            logger.info(f\"Model {model.__class__.__name__} - Epoch {epoch}/{num_epochs} - Loss: {epoch_loss:.4f} - Accuracy: {epoch_acc:.4f}\")\n",
    "\n",
    "        # Evaluation at the end of each epoch\n",
    "        for model in models:\n",
    "            model.eval()\n",
    "            val_loss = 0.0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for batch in eval_loader:\n",
    "                    inputs = batch['color_image'].to(device)\n",
    "                    targets = batch['grid'].to(device).view(-1)\n",
    "\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, targets)\n",
    "                    val_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "                    _, predicted = torch.max(outputs.data, 1)\n",
    "                    total += targets.size(0)\n",
    "                    correct += (predicted == targets).sum().item()\n",
    "\n",
    "            avg_val_loss = val_loss / len(eval_loader.dataset)\n",
    "            val_accuracy = correct / total\n",
    "            logger.info(f\"Model {model.__class__.__name__} - Validation Loss: {avg_val_loss:.4f} - Validation Accuracy: {val_accuracy:.4f}\")\n",
    "\n",
    "    logger.info(\"Training completed.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main_training()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0bcb53-fa0a-4da1-993e-bb724de0be34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# models/mlp_magician.py\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import logging\n",
    "\n",
    "class MLPMagician(nn.Module):\n",
    "    def __init__(self, input_size, hidden_sizes, dropout_rate=0.5, num_classes=10):\n",
    "        \"\"\"\n",
    "        Initializes the MLPMagician model.\n",
    "\n",
    "        Args:\n",
    "            input_size (int): Number of input features.\n",
    "            hidden_sizes (list): List containing the number of neurons in each hidden layer.\n",
    "            dropout_rate (float): Dropout rate for regularization.\n",
    "            num_classes (int): Number of output classes.\n",
    "        \"\"\"\n",
    "        super(MLPMagician, self).__init__()\n",
    "        layers = []\n",
    "        prev_size = input_size\n",
    "        for idx, hidden_size in enumerate(hidden_sizes):\n",
    "            layers.append(nn.Linear(prev_size, hidden_size))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.Dropout(dropout_rate))\n",
    "            prev_size = hidden_size\n",
    "        layers.append(nn.Linear(prev_size, num_classes))\n",
    "        self.network = nn.Sequential(*layers)\n",
    "        \n",
    "        # Initialize weights\n",
    "        initialize_weights(self)\n",
    "        logging.info(\"Initialized MLPMagician model with layers: {}\".format(self.network))\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass of the model.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor of shape (batch_size, input_size).\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Output predictions of shape (batch_size, num_classes).\n",
    "        \"\"\"\n",
    "        return self.network(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59810f1e-3399-46fd-9ca0-1e5df112230e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data/test_data_conversion.py\n",
    "\n",
    "import unittest\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "class TestDataConversion(unittest.TestCase):\n",
    "    def setUp(self):\n",
    "        self.grid = np.array([\n",
    "            [0, 1, 2],\n",
    "            [3, 4, 5],\n",
    "            [6, 7, 8]\n",
    "        ])\n",
    "        self.color_map = {\n",
    "            0: [0, 0, 0],\n",
    "            1: [255, 0, 0],\n",
    "            2: [0, 255, 0],\n",
    "            3: [0, 0, 255],\n",
    "            4: [255, 255, 0],\n",
    "            5: [255, 165, 0],\n",
    "            6: [128, 0, 128],\n",
    "            7: [0, 255, 255],\n",
    "            8: [255, 192, 203],\n",
    "        }\n",
    "\n",
    "    def test_grid_to_image(self):\n",
    "        img = grid_to_image(self.grid, self.color_map)\n",
    "        self.assertIsInstance(img, Image.Image)\n",
    "        self.assertEqual(img.size, (3, 3))\n",
    "        pixels = img.load()\n",
    "        self.assertEqual(pixels[0, 0], (0, 0, 0))          # Black\n",
    "        self.assertEqual(pixels[1, 0], (255, 0, 0))        # Red\n",
    "        self.assertEqual(pixels[2, 0], (0, 255, 0))        # Green\n",
    "\n",
    "    def test_grid_to_grayscale(self):\n",
    "        img = grid_to_grayscale(self.grid)\n",
    "        self.assertIsInstance(img, Image.Image)\n",
    "        self.assertEqual(img.mode, 'L')                     # Grayscale\n",
    "        self.assertEqual(img.size, (3, 3))\n",
    "        pixels = img.load()\n",
    "        self.assertEqual(pixels[0, 0], 0)                   # Minimum value normalized to 0\n",
    "        self.assertEqual(pixels[1, 1], 127)                 # Mid value\n",
    "\n",
    "    def test_grid_to_numeric_image(self):\n",
    "        img = grid_to_numeric_image(self.grid)\n",
    "        self.assertIsInstance(img, Image.Image)\n",
    "        self.assertEqual(img.mode, 'RGB')\n",
    "        self.assertEqual(img.size, (150, 150))               # 3x3 grid with cell_size=50\n",
    "        pixels = img.load()\n",
    "        self.assertEqual(pixels[25, 25], (255, 0, 0))        # Number 1 in red cell\n",
    "        self.assertEqual(pixels[75, 75], (255, 255, 0))      # Number 4 in yellow cell\n",
    "\n",
    "    def test_augment_image(self):\n",
    "        img = grid_to_image(self.grid, self.color_map)\n",
    "        augmented_img, dead_squares = augment_image(img, self.grid, perturb_prob=0.0, dead_square_prob=1.0, noise_prob=0.0)\n",
    "        self.assertEqual(len(dead_squares), 1)               # Only one dead square expected\n",
    "        self.assertIsInstance(augmented_img, Image.Image)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    unittest.main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae5062f-51cd-4bf1-9c73-06b5697a28cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data/data_conversion.py (continued)\n",
    "\n",
    "def generate_grids_variable_sizes(num_grids_per_size, grid_sizes, num_classes):\n",
    "    \"\"\"\n",
    "    Generates grids of multiple sizes.\n",
    "\n",
    "    Args:\n",
    "        num_grids_per_size (int): Number of grids per size.\n",
    "        grid_sizes (list of int): List of grid sizes (e.g., [3, 5, 10]).\n",
    "        num_classes (int): Number of classes/colors.\n",
    "\n",
    "    Returns:\n",
    "        list of np.ndarray: Generated grids.\n",
    "    \"\"\"\n",
    "    grids = []\n",
    "    for size in grid_sizes:\n",
    "        grids.extend(generate_grids(num_grids=num_grids_per_size, grid_size=size, num_classes=num_classes))\n",
    "    logger.info(f\"Generated {len(grids)} grids of varying sizes: {grid_sizes}.\")\n",
    "    return grids\n",
    "\n",
    "\n",
    "def get_data_loaders_variable_sizes(batch_size=32, grid_sizes=[3, 5, 10], num_classes=11, augment=True):\n",
    "    \"\"\"\n",
    "    Creates DataLoader instances for training and evaluation with variable grid sizes.\n",
    "\n",
    "    Args:\n",
    "        batch_size (int, optional): Number of samples per batch. Defaults to 32.\n",
    "        grid_sizes (list of int, optional): List of grid sizes. Defaults to [3, 5, 10].\n",
    "        num_classes (int, optional): Number of classes/colors. Defaults to 11.\n",
    "        augment (bool, optional): Whether to apply data augmentation. Defaults to True.\n",
    "\n",
    "    Returns:\n",
    "        DataLoader: Training DataLoader.\n",
    "        DataLoader: Evaluation DataLoader.\n",
    "    \"\"\"\n",
    "    # Generate grids for training and evaluation\n",
    "    train_grids = generate_grids_variable_sizes(num_grids_per_size=1000, grid_sizes=grid_sizes, num_classes=num_classes)\n",
    "    eval_grids = generate_grids_variable_sizes(num_grids_per_size=200, grid_sizes=grid_sizes, num_classes=num_classes)\n",
    "\n",
    "    # Define transformations\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((256, 256)),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "\n",
    "    # Create datasets\n",
    "    train_dataset = GridDataset(train_grids, transform=transform, augmentation=augment)\n",
    "    eval_dataset = GridDataset(eval_grids, transform=transform, augmentation=False)\n",
    "\n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "    eval_loader = DataLoader(eval_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "    logger.info(\"Created training and evaluation DataLoaders with variable grid sizes.\")\n",
    "    return train_loader, eval_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b86de8-5763-43d0-9476-7bbdfb7cb1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# models/cnn_magician.py\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from utils.weight_initialization import initialize_weights\n",
    "import logging\n",
    "\n",
    "class CNNMagician(nn.Module):\n",
    "    def __init__(self, dropout_rate=0.5, num_classes=10):\n",
    "        \"\"\"\n",
    "        Initializes the CNNMagician model.\n",
    "\n",
    "        Args:\n",
    "            dropout_rate (float): Dropout rate for regularization.\n",
    "            num_classes (int): Number of output classes.\n",
    "        \"\"\"\n",
    "        super(CNNMagician, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)  # Assuming grayscale input\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.fc1 = nn.Linear(128 * 3 * 3, 128)  # Adjust based on input size\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        \n",
    "        # Initialize weights\n",
    "        initialize_weights(self)\n",
    "        logging.info(\"Initialized CNNMagician model with layers.\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass of the model.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor of shape (batch_size, 1, 28, 28).\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Output predictions of shape (batch_size, num_classes).\n",
    "        \"\"\"\n",
    "        x = self.pool(F.relu(self.bn1(self.conv1(x))))  # [32, H/2, W/2]\n",
    "        x = self.pool(F.relu(self.bn2(self.conv2(x))))  # [64, H/4, W/4]\n",
    "        x = self.pool(F.relu(self.bn3(self.conv3(x))))  # [128, H/8, W/8]\n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        return self.fc2(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72f429b-6e98-4f3a-a892-6512dac0b3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# models/resnet_magician.py\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import logging\n",
    "\n",
    "class ResNetBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        \"\"\"\n",
    "        Initializes a single ResNet block.\n",
    "\n",
    "        Args:\n",
    "            in_channels (int): Number of input channels.\n",
    "            out_channels (int): Number of output channels.\n",
    "            stride (int): Stride for the convolution.\n",
    "        \"\"\"\n",
    "        super(ResNetBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "        self.downsample = None\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.downsample = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass of the ResNet block.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Output tensor after residual connection.\n",
    "        \"\"\"\n",
    "        identity = x\n",
    "        out = self.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        if self.downsample:\n",
    "            identity = self.downsample(x)\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "class ResNetMagician(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        \"\"\"\n",
    "        Initializes the ResNetMagician model.\n",
    "\n",
    "        Args:\n",
    "            num_classes (int): Number of output classes.\n",
    "        \"\"\"\n",
    "        super(ResNetMagician, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3)  # Assuming grayscale input\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        \n",
    "        # Define ResNet layers\n",
    "        self.layer1 = self._make_layer(64, 64, blocks=2, stride=1)\n",
    "        self.layer2 = self._make_layer(64, 128, blocks=2, stride=2)\n",
    "        self.layer3 = self._make_layer(128, 256, blocks=2, stride=2)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(256, num_classes)\n",
    "        \n",
    "        # Initialize weights\n",
    "        initialize_weights(self)\n",
    "        logging.info(\"Initialized ResNetMagician model with layers.\")\n",
    "\n",
    "    def _make_layer(self, in_channels, out_channels, blocks, stride):\n",
    "        \"\"\"\n",
    "        Creates a ResNet layer composed of multiple ResNet blocks.\n",
    "\n",
    "        Args:\n",
    "            in_channels (int): Number of input channels.\n",
    "            out_channels (int): Number of output channels.\n",
    "            blocks (int): Number of ResNet blocks.\n",
    "            stride (int): Stride for the first block.\n",
    "\n",
    "        Returns:\n",
    "            nn.Sequential: Sequential container of ResNet blocks.\n",
    "        \"\"\"\n",
    "        layers = []\n",
    "        layers.append(ResNetBlock(in_channels, out_channels, stride))\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(ResNetBlock(out_channels, out_channels))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass of the ResNetMagician model.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor of shape (batch_size, 1, 224, 224).\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Output predictions of shape (batch_size, num_classes).\n",
    "        \"\"\"\n",
    "        x = self.relu(self.bn1(self.conv1(x)))  # [64, H/2, W/2]\n",
    "        x = self.maxpool(x)  # [64, H/4, W/4]\n",
    "        \n",
    "        x = self.layer1(x)  # [64, H/4, W/4]\n",
    "        x = self.layer2(x)  # [128, H/8, W/8]\n",
    "        x = self.layer3(x)  # [256, H/16, W/16]\n",
    "        \n",
    "        x = self.avgpool(x)  # [256, 1, 1]\n",
    "        x = torch.flatten(x, 1)  # [256]\n",
    "        x = self.fc(x)  # [num_classes]\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a91c10e-6114-4ebf-ab29-3d7c5e38deab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# models/vision_transformer_magician.py\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.models import vit_b_16\n",
    "import logging\n",
    "\n",
    "class VisionTransformerMagician(nn.Module):\n",
    "    def __init__(self, num_classes=10, pretrained=True):\n",
    "        \"\"\"\n",
    "        Initializes the VisionTransformerMagician model.\n",
    "\n",
    "        Args:\n",
    "            num_classes (int): Number of output classes.\n",
    "            pretrained (bool): Whether to use a pre-trained ViT model.\n",
    "        \"\"\"\n",
    "        super(VisionTransformerMagician, self).__init__()\n",
    "        self.vit = vit_b_16(pretrained=pretrained)\n",
    "        # Replace the classification head\n",
    "        self.vit.heads = nn.Linear(self.vit.heads.in_features, num_classes)\n",
    "        \n",
    "        # Initialize weights of the new head\n",
    "        initialize_weights(self.vit.heads)\n",
    "        logging.info(\"Initialized VisionTransformerMagician model with ViT backbone.\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass of the VisionTransformerMagician model.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor of shape (batch_size, 3, 224, 224).\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Output predictions of shape (batch_size, num_classes).\n",
    "        \"\"\"\n",
    "        return self.vit(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a359d1-f4bb-45f1-87d1-ea438b3b13a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# models/dnn_magician.py\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import logging\n",
    "\n",
    "class DNNMagician(nn.Module):\n",
    "    def __init__(self, input_size, hidden_sizes, dropout_rate=0.5, num_classes=10):\n",
    "        \"\"\"\n",
    "        Initializes the DNNMagician model.\n",
    "\n",
    "        Args:\n",
    "            input_size (int): Number of input features.\n",
    "            hidden_sizes (list): List containing the number of neurons in each hidden layer.\n",
    "            dropout_rate (float): Dropout rate for regularization.\n",
    "            num_classes (int): Number of output classes.\n",
    "        \"\"\"\n",
    "        super(DNNMagician, self).__init__()\n",
    "        layers = []\n",
    "        prev_size = input_size\n",
    "        for idx, hidden_size in enumerate(hidden_sizes):\n",
    "            layers.append(nn.Linear(prev_size, hidden_size))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.Dropout(dropout_rate))\n",
    "            prev_size = hidden_size\n",
    "        layers.append(nn.Linear(prev_size, num_classes))\n",
    "        self.network = nn.Sequential(*layers)\n",
    "        \n",
    "        # Initialize weights\n",
    "        initialize_weights(self)\n",
    "        logging.info(\"Initialized DNNMagician model with layers: {}\".format(self.network))\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass of the model.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor of shape (batch_size, input_size).\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Output predictions of shape (batch_size, num_classes).\n",
    "        \"\"\"\n",
    "        return self.network(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f959310c-9353-4207-9438-2b143ed4eacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# models/rnn_magician.py\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import logging\n",
    "\n",
    "class RNNMagician(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size, dropout_rate=0.3):\n",
    "        \"\"\"\n",
    "        Initializes the RNNMagician model.\n",
    "\n",
    "        Args:\n",
    "            input_size (int): Number of input features per time step.\n",
    "            hidden_size (int): Number of features in the hidden state.\n",
    "            num_layers (int): Number of recurrent layers.\n",
    "            output_size (int): Number of output classes.\n",
    "            dropout_rate (float): Dropout rate for regularization.\n",
    "        \"\"\"\n",
    "        super(RNNMagician, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, dropout=dropout_rate)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "        # Initialize weights\n",
    "        initialize_weights(self)\n",
    "        logging.info(\"Initialized RNNMagician model with LSTM layers.\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass of the RNNMagician model.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor of shape (batch_size, sequence_length, input_size).\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Output predictions of shape (batch_size, output_size).\n",
    "        \"\"\"\n",
    "        out, _ = self.lstm(x)  # out: (batch_size, sequence_length, hidden_size)\n",
    "        out = out[:, -1, :]    # Take the last time step\n",
    "        out = self.fc(out)     # (batch_size, output_size)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466ff08d-c912-4a55-a219-868d398cc2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils/logging_setup.py\n",
    "\n",
    "import logging\n",
    "import os\n",
    "\n",
    "def initialize_logging(log_file='logs/training.log', log_level=logging.INFO):\n",
    "    \"\"\"\n",
    "    Initializes the logging configuration.\n",
    "\n",
    "    Args:\n",
    "        log_file (str): Path to the log file.\n",
    "        log_level (int): Logging level (e.g., logging.INFO, logging.DEBUG).\n",
    "    \"\"\"\n",
    "    # Create logs directory if it doesn't exist\n",
    "    os.makedirs(os.path.dirname(log_file), exist_ok=True)\n",
    "    \n",
    "    # Define logging format\n",
    "    log_format = '%(asctime)s [%(levelname)s] %(message)s'\n",
    "    \n",
    "    # Configure logging\n",
    "    logging.basicConfig(\n",
    "        level=log_level,\n",
    "        format=log_format,\n",
    "        handlers=[\n",
    "            logging.FileHandler(log_file),\n",
    "            logging.StreamHandler()\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    logging.info(\"Logging is initialized.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232ac365-8bb6-4de4-bea4-1fc6090093ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils/redis_manager.py\n",
    "\n",
    "import redis\n",
    "import json\n",
    "import logging\n",
    "\n",
    "class RedisManager:\n",
    "    \"\"\"\n",
    "    Manages connections and interactions with Redis for shared memory.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, host='localhost', port=6379, db=0):\n",
    "        \"\"\"\n",
    "        Initializes the RedisManager by establishing a connection to the Redis server.\n",
    "\n",
    "        Args:\n",
    "            host (str): Redis server hostname.\n",
    "            port (int): Redis server port.\n",
    "            db (int): Redis database index.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.redis = redis.Redis(host=host, port=port, db=db)\n",
    "            # Test the connection\n",
    "            self.redis.ping()\n",
    "            logging.info(f\"Connected to Redis at {host}:{port}, DB: {db}\")\n",
    "        except redis.exceptions.ConnectionError as e:\n",
    "            logging.error(f\"Redis connection error: {e}\")\n",
    "            raise e\n",
    "\n",
    "    def set_value(self, key, value):\n",
    "        \"\"\"\n",
    "        Sets a value in Redis after serializing it to JSON.\n",
    "\n",
    "        Args:\n",
    "            key (str): The key under which the value is stored.\n",
    "            value (any): The value to store (must be JSON serializable).\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.redis.set(key, json.dumps(value))\n",
    "            logging.debug(f\"Set key '{key}' in Redis.\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error setting key '{key}' in Redis: {e}\")\n",
    "\n",
    "    def get_value(self, key):\n",
    "        \"\"\"\n",
    "        Retrieves a value from Redis and deserializes it from JSON.\n",
    "\n",
    "        Args:\n",
    "            key (str): The key to retrieve.\n",
    "\n",
    "        Returns:\n",
    "            any: The deserialized value, or None if the key does not exist.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            value = self.redis.get(key)\n",
    "            if value:\n",
    "                logging.debug(f\"Retrieved key '{key}' from Redis.\")\n",
    "                return json.loads(value)\n",
    "            else:\n",
    "                logging.debug(f\"Key '{key}' not found in Redis.\")\n",
    "                return None\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error retrieving key '{key}' from Redis: {e}\")\n",
    "            return None\n",
    "\n",
    "    def delete_key(self, key):\n",
    "        \"\"\"\n",
    "        Deletes a key from Redis.\n",
    "\n",
    "        Args:\n",
    "            key (str): The key to delete.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.redis.delete(key)\n",
    "            logging.debug(f\"Deleted key '{key}' from Redis.\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error deleting key '{key}' from Redis: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b0fb45-71d8-4321-9b3e-8abe7fb45eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils/plot_utils.py\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg\n",
    "import logging\n",
    "\n",
    "def plot_training_metrics(gui, loss_data, val_loss_data, acc_data, val_acc_data):\n",
    "    \"\"\"\n",
    "    Plots training and validation metrics in the GUI.\n",
    "\n",
    "    Args:\n",
    "        gui (TrainingGUI): Instance of the TrainingGUI.\n",
    "        loss_data (list): List of training loss values.\n",
    "        val_loss_data (list): List of validation loss values.\n",
    "        acc_data (list): List of training accuracy values.\n",
    "        val_acc_data (list): List of validation accuracy values.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        gui.ax.clear()\n",
    "        gui.ax.plot(range(1, len(loss_data)+1), loss_data, label='Training Loss', color='blue')\n",
    "        gui.ax.plot(range(1, len(val_loss_data)+1), val_loss_data, label='Validation Loss', color='orange')\n",
    "        gui.ax.plot(range(1, len(acc_data)+1), acc_data, label='Training Accuracy', color='green')\n",
    "        gui.ax.plot(range(1, len(val_acc_data)+1), val_acc_data, label='Validation Accuracy', color='red')\n",
    "        gui.ax.set_xlabel('Epochs')\n",
    "        gui.ax.set_ylabel('Metrics')\n",
    "        gui.ax.legend()\n",
    "        gui.ax.grid(True)\n",
    "        gui.canvas.draw()\n",
    "        logging.info(\"Updated training metrics plot.\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error plotting training metrics: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426975e7-af4b-4173-a28d-e0efb78b0c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils/weight_initialization.py\n",
    "\n",
    "import torch.nn as nn\n",
    "import logging\n",
    "\n",
    "def initialize_weights(model):\n",
    "    \"\"\"\n",
    "    Initializes weights of the model using Kaiming initialization for Conv layers\n",
    "    and Xavier initialization for Linear layers. BatchNorm layers are initialized\n",
    "    with constant weights and biases.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): The model to initialize.\n",
    "    \"\"\"\n",
    "    for m in model.modules():\n",
    "        if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n",
    "            nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            if m.bias is not None:\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            logging.debug(f\"Initialized Conv layer: {m}\")\n",
    "        elif isinstance(m, nn.Linear):\n",
    "            nn.init.xavier_normal_(m.weight)\n",
    "            if m.bias is not None:\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            logging.debug(f\"Initialized Linear layer: {m}\")\n",
    "        elif isinstance(m, (nn.BatchNorm1d, nn.BatchNorm2d)):\n",
    "            nn.init.constant_(m.weight, 1)\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "            logging.debug(f\"Initialized BatchNorm layer: {m}\")\n",
    "        elif isinstance(m, nn.LSTM):\n",
    "            for name, param in m.named_parameters():\n",
    "                if 'weight' in name:\n",
    "                    nn.init.xavier_normal_(param.data)\n",
    "                elif 'bias' in name:\n",
    "                    nn.init.constant_(param.data, 0)\n",
    "            logging.debug(f\"Initialized LSTM layer: {m}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559b24b9-42ab-40b4-a23d-a2dc0c76dc62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils/hyperparameter_tuner.py\n",
    "\n",
    "import logging\n",
    "\n",
    "class HyperparameterTuner:\n",
    "    \"\"\"\n",
    "    Adjusts hyperparameters like learning rate based on training progress.\n",
    "    Implements a simple strategy; can be expanded with reinforcement learning.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, initial_lr, factor=0.5, patience=3, min_lr=1e-6):\n",
    "        \"\"\"\n",
    "        Initializes the HyperparameterTuner.\n",
    "\n",
    "        Args:\n",
    "            initial_lr (float): Initial learning rate.\n",
    "            factor (float): Factor by which to reduce the learning rate.\n",
    "            patience (int): Number of epochs to wait before reducing LR.\n",
    "            min_lr (float): Minimum learning rate.\n",
    "        \"\"\"\n",
    "        self.initial_lr = initial_lr\n",
    "        self.factor = factor\n",
    "        self.patience = patience\n",
    "        self.min_lr = min_lr\n",
    "        self.best_loss = float('inf')\n",
    "        self.counter = 0\n",
    "        logging.info(\"Initialized HyperparameterTuner.\")\n",
    "\n",
    "    def adjust_learning_rate(self, optimizer, current_loss):\n",
    "        \"\"\"\n",
    "        Adjusts the learning rate based on current loss.\n",
    "\n",
    "        Args:\n",
    "            optimizer (torch.optim.Optimizer): Optimizer whose LR is to be adjusted.\n",
    "            current_loss (float): Current validation loss.\n",
    "        \"\"\"\n",
    "        if current_loss < self.best_loss:\n",
    "            self.best_loss = current_loss\n",
    "            self.counter = 0\n",
    "            logging.debug(\"Validation loss improved; resetting patience counter.\")\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            logging.debug(f\"No improvement in validation loss. Counter: {self.counter}/{self.patience}\")\n",
    "            if self.counter >= self.patience:\n",
    "                for param_group in optimizer.param_groups:\n",
    "                    new_lr = max(param_group['lr'] * self.factor, self.min_lr)\n",
    "                    if param_group['lr'] > self.min_lr:\n",
    "                        param_group['lr'] = new_lr\n",
    "                        logging.info(f\"Reducing learning rate to {new_lr}.\")\n",
    "                self.counter = 0  # Reset counter after adjusting\n",
    "\n",
    "    def early_stopping(self):\n",
    "        \"\"\"\n",
    "        Determines whether to perform early stopping.\n",
    "\n",
    "        Returns:\n",
    "            bool: True if early stopping criteria met, False otherwise.\n",
    "        \"\"\"\n",
    "        # Placeholder for actual early stopping logic\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b351e9ab-e843-4e1d-9d14-428e4b960250",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils/hyperparameter_helper.py\n",
    "\n",
    "import random\n",
    "import logging\n",
    "\n",
    "def randomize_params():\n",
    "    \"\"\"\n",
    "    Randomizes hyperparameters for model training.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (num_models, num_epochs, initial_lr, other_params)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        num_models = random.randint(5, 15)  # Example range\n",
    "        num_epochs = random.randint(50, 200)\n",
    "        initial_lr = random.choice([0.1, 0.01, 0.001, 0.0001])\n",
    "        other_params = {}  # Add other hyperparameters as needed\n",
    "        logging.info(f\"Randomized hyperparameters: num_models={num_models}, num_epochs={num_epochs}, initial_lr={initial_lr}\")\n",
    "        return num_models, num_epochs, initial_lr, other_params\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error randomizing parameters: {e}\")\n",
    "        return 10, 100, 0.001, {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f95c06a-3896-4c21-a825-33b13b04d85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gui/training_gui.py\n",
    "\n",
    "import tkinter as tk\n",
    "from tkinter import ttk, messagebox\n",
    "import queue\n",
    "from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "\n",
    "\n",
    "class TrainingGUI:\n",
    "    \"\"\"\n",
    "    A Tkinter-based GUI that displays real-time training progress, including model metrics,\n",
    "    learning rate adjustments, ensemble accuracy, and allows querying the LLM for explanations.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, root, total_models, total_epochs, redis_manager, llm):\n",
    "        \"\"\"\n",
    "        Initializes the TrainingGUI.\n",
    "\n",
    "        Args:\n",
    "            root (tk.Tk): The root Tkinter window.\n",
    "            total_models (int): Total number of models to train.\n",
    "            total_epochs (int): Total number of epochs per model.\n",
    "            redis_manager (RedisManager): Instance for interacting with Redis.\n",
    "            llm (StrategyLLM): Instance of the language model for generating explanations.\n",
    "        \"\"\"\n",
    "        self.root = root\n",
    "        self.queue = queue.Queue()\n",
    "        self.redis_manager = redis_manager\n",
    "        self.llm = llm\n",
    "        self.root.title(\"Model Training Progress Tracker\")\n",
    "\n",
    "        # Initialize GUI Components\n",
    "        self._init_labels(total_models, total_epochs)\n",
    "        self._init_progress_bar()\n",
    "        self._init_plots()\n",
    "        self._init_ensemble_accuracy()\n",
    "        self._init_query_section()\n",
    "\n",
    "        # Start real-time queue processing\n",
    "        self.root.after(100, self.process_queue)\n",
    "\n",
    "    def _init_labels(self, total_models, total_epochs):\n",
    "        \"\"\"Initialize the labels to display real-time metrics.\"\"\"\n",
    "        self.model_label = tk.Label(self.root, text=f\"Training Model: 0/{total_models}\", font=(\"Helvetica\", 14))\n",
    "        self.model_label.pack(pady=5)\n",
    "\n",
    "        self.epoch_label = tk.Label(self.root, text=f\"Epoch: 0/{total_epochs}\", font=(\"Helvetica\", 14))\n",
    "        self.epoch_label.pack(pady=5)\n",
    "\n",
    "        self.loss_label = tk.Label(self.root, text=\"Loss: 0.0000\", font=(\"Helvetica\", 12))\n",
    "        self.loss_label.pack(pady=2)\n",
    "\n",
    "        self.accuracy_label = tk.Label(self.root, text=\"Accuracy: 0.0000\", font=(\"Helvetica\", 12))\n",
    "        self.accuracy_label.pack(pady=2)\n",
    "\n",
    "        self.val_loss_label = tk.Label(self.root, text=\"Validation Loss: 0.0000\", font=(\"Helvetica\", 12))\n",
    "        self.val_loss_label.pack(pady=2)\n",
    "\n",
    "        self.val_accuracy_label = tk.Label(self.root, text=\"Validation Accuracy: 0.0000\", font=(\"Helvetica\", 12))\n",
    "        self.val_accuracy_label.pack(pady=2)\n",
    "\n",
    "        self.lr_label = tk.Label(self.root, text=\"Learning Rate: 0.000000\", font=(\"Helvetica\", 12))\n",
    "        self.lr_label.pack(pady=2)\n",
    "\n",
    "    def _init_progress_bar(self):\n",
    "        \"\"\"Initialize the progress bar.\"\"\"\n",
    "        self.progress_bar = ttk.Progressbar(self.root, orient=\"horizontal\", length=400, mode=\"determinate\")\n",
    "        self.progress_bar.pack(pady=10)\n",
    "\n",
    "    def _init_plots(self):\n",
    "        \"\"\"Initialize the real-time plots.\"\"\"\n",
    "        self.fig, self.ax = plt.subplots(figsize=(6, 4))\n",
    "        self.line_loss, = self.ax.plot([], [], label='Training Loss', color='blue')\n",
    "        self.line_val_loss, = self.ax.plot([], [], label='Validation Loss', color='orange')\n",
    "        self.line_acc, = self.ax.plot([], [], label='Training Accuracy', color='green')\n",
    "        self.line_val_acc, = self.ax.plot([], [], label='Validation Accuracy', color='red')\n",
    "\n",
    "        self.ax.set_xlabel('Epochs')\n",
    "        self.ax.set_ylabel('Metrics')\n",
    "        self.ax.legend()\n",
    "        self.ax.grid(True)\n",
    "\n",
    "        self.canvas = FigureCanvasTkAgg(self.fig, master=self.root)\n",
    "        self.canvas.draw()\n",
    "        self.canvas.get_tk_widget().pack()\n",
    "\n",
    "        # Data storage for plotting\n",
    "        self.loss_data = []\n",
    "        self.val_loss_data = []\n",
    "        self.acc_data = []\n",
    "        self.val_acc_data = []\n",
    "\n",
    "    def _init_ensemble_accuracy(self):\n",
    "        \"\"\"Initialize the ensemble accuracy display.\"\"\"\n",
    "        self.ensemble_label = tk.Label(self.root, text=\"Ensemble Accuracy: N/A\", font=(\"Helvetica\", 14))\n",
    "        self.ensemble_label.pack(pady=5)\n",
    "\n",
    "    def _init_query_section(self):\n",
    "        \"\"\"Initialize the section for querying the LLM for explanations.\"\"\"\n",
    "        self.query_frame = tk.Frame(self.root)\n",
    "        self.query_frame.pack(pady=10)\n",
    "\n",
    "        self.query_label = tk.Label(self.query_frame, text=\"LLM Query:\", font=(\"Helvetica\", 12))\n",
    "        self.query_label.pack(side=tk.LEFT, padx=5)\n",
    "\n",
    "        self.query_entry = tk.Entry(self.query_frame, width=50)\n",
    "        self.query_entry.pack(side=tk.LEFT, padx=5)\n",
    "\n",
    "        self.query_button = tk.Button(self.query_frame, text=\"Ask\", command=self.handle_query)\n",
    "        self.query_button.pack(side=tk.LEFT, padx=5)\n",
    "\n",
    "        self.response_text = tk.Text(self.root, height=10, width=80, state='disabled')\n",
    "        self.response_text.pack(pady=5)\n",
    "\n",
    "    def process_queue(self):\n",
    "        \"\"\"Process the queue for thread-safe GUI updates.\"\"\"\n",
    "        while not self.queue.empty():\n",
    "            message = self.queue.get()\n",
    "            if isinstance(message, dict):\n",
    "                self._handle_message(message)\n",
    "        self.root.after(100, self.process_queue)  # Schedule next update\n",
    "\n",
    "    def _handle_message(self, message):\n",
    "        \"\"\"Handle incoming messages from the queue.\"\"\"\n",
    "        msg_type = message.get('type')\n",
    "        if msg_type == 'epoch':\n",
    "            self.update_epoch(message)\n",
    "        elif msg_type == 'ensemble_accuracy':\n",
    "            self.update_ensemble_accuracy(message.get('accuracy'))\n",
    "        elif msg_type == 'training_completed':\n",
    "            self.model_label.config(text=\"Training Completed\")\n",
    "            messagebox.showinfo(\"Training Completed\", \"All models have been trained successfully!\")\n",
    "\n",
    "    def update_epoch(self, data):\n",
    "        \"\"\"Update the GUI with epoch metrics.\"\"\"\n",
    "        self._update_labels(data)\n",
    "        self._update_progress_bar(data['epoch'], data['total_epochs'])\n",
    "        self._update_plots(data)\n",
    "\n",
    "    def update_ensemble_accuracy(self, accuracy):\n",
    "        \"\"\"Update the ensemble accuracy label.\"\"\"\n",
    "        self.ensemble_label.config(text=f\"Ensemble Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "    def _update_labels(self, data):\n",
    "        \"\"\"Update the labels with new data.\"\"\"\n",
    "        self.model_label.config(text=f\"Training Model: {data['model_num']}/{data['total_models']}\")\n",
    "        self.epoch_label.config(text=f\"Epoch: {data['epoch']}/{data['total_epochs']}\")\n",
    "        self.loss_label.config(text=f\"Loss: {data['loss']:.4f}\")\n",
    "        self.accuracy_label.config(text=f\"Accuracy: {data['accuracy']:.4f}\")\n",
    "        self.val_loss_label.config(text=f\"Validation Loss: {data['val_loss']:.4f}\")\n",
    "        self.val_accuracy_label.config(text=f\"Validation Accuracy: {data['val_accuracy']:.4f}\")\n",
    "        self.lr_label.config(text=f\"Learning Rate: {data['lr']:.6f}\")\n",
    "\n",
    "    def _update_progress_bar(self, epoch, total_epochs):\n",
    "        \"\"\"Update the progress bar.\"\"\"\n",
    "        self.progress_bar[\"value\"] = (epoch / total_epochs) * 100\n",
    "        self.root.update_idletasks()\n",
    "\n",
    "    def _update_plots(self, data):\n",
    "        \"\"\"Update the real-time plots with new metrics.\"\"\"\n",
    "        self.loss_data.append(data['loss'])\n",
    "        self.val_loss_data.append(data['val_loss'])\n",
    "        self.acc_data.append(data['accuracy'])\n",
    "        self.val_acc_data.append(data['val_accuracy'])\n",
    "\n",
    "        self.ax.clear()\n",
    "        self.ax.plot(range(1, len(self.loss_data)+1), self.loss_data, label='Training Loss', color='blue')\n",
    "        self.ax.plot(range(1, len(self.val_loss_data)+1), self.val_loss_data, label='Validation Loss', color='orange')\n",
    "        self.ax.plot(range(1, len(self.acc_data)+1), self.acc_data, label='Training Accuracy', color='green')\n",
    "        self.ax.plot(range(1, len(self.val_acc_data)+1), self.val_acc_data, label='Validation Accuracy', color='red')\n",
    "        self.ax.set_xlabel('Epochs')\n",
    "        self.ax.set_ylabel('Metrics')\n",
    "        self.ax.legend()\n",
    "        self.ax.grid(True)\n",
    "        self.canvas.draw()\n",
    "\n",
    "    def handle_query(self):\n",
    "        \"\"\"Handle user queries to the LLM.\"\"\"\n",
    "        query = self.query_entry.get()\n",
    "        if not query:\n",
    "            messagebox.showwarning(\"Input Needed\", \"Please enter a query.\")\n",
    "            return\n",
    "\n",
    "        # Retrieve current metrics from Redis\n",
    "        current_metrics = self.redis_manager.get_value('current_metrics')\n",
    "        if not current_metrics:\n",
    "            messagebox.showwarning(\"No Data\", \"No current metrics available for explanation.\")\n",
    "            return\n",
    "\n",
    "        # Generate explanation using LLM\n",
    "        explanation = self.llm.explain_prediction(\n",
    "            model_num=current_metrics.get('model_num', 0),\n",
    "            epoch=current_metrics.get('epoch', 0),\n",
    "            input_data=None,       # Optionally, pass actual input data if available\n",
    "            prediction=None,      # Optionally, pass actual prediction if available\n",
    "            actual_label=None     # Optionally, pass actual label if available\n",
    "        )\n",
    "\n",
    "        # Display the explanation\n",
    "        response = f\"Query: {query}\\nExplanation: {explanation}\\n\"\n",
    "        self.response_text.config(state='normal')\n",
    "        self.response_text.insert(tk.END, response + \"\\n\")\n",
    "        self.response_text.config(state='disabled')\n",
    "        self.query_entry.delete(0, tk.END)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d98d04-aa25-4ec5-b8e1-577144026e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training/trainer.py\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import DataLoader\n",
    "import logging\n",
    "from queue import Queue\n",
    "import threading\n",
    "import time\n",
    "import joblib\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Ensure all models are imported in models/__init__.py for easy access\n",
    "\n",
    "class Trainer:\n",
    "    \"\"\"\n",
    "    Manages the training process for multiple models, interacts with the GUI,\n",
    "    handles hyperparameter tuning, evaluates models, and creates an ensemble.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 train_loader: DataLoader, \n",
    "                 eval_loader: DataLoader, \n",
    "                 total_models: int, \n",
    "                 total_epochs: int, \n",
    "                 initial_lr: float, \n",
    "                 device: torch.device,\n",
    "                 redis_manager: RedisManager,\n",
    "                 llm: StrategyLLM,\n",
    "                 gui: TrainingGUI):\n",
    "        \"\"\"\n",
    "        Initializes the Trainer with necessary components.\n",
    "\n",
    "        Args:\n",
    "            train_loader (DataLoader): DataLoader for training data.\n",
    "            eval_loader (DataLoader): DataLoader for evaluation data.\n",
    "            total_models (int): Total number of models to train.\n",
    "            total_epochs (int): Number of epochs per model.\n",
    "            initial_lr (float): Initial learning rate.\n",
    "            device (torch.device): Device to perform training on.\n",
    "            redis_manager (RedisManager): Instance for interacting with Redis.\n",
    "            llm (StrategyLLM): Instance of the language model for explanations.\n",
    "            gui (TrainingGUI): Instance of the GUI for updates.\n",
    "        \"\"\"\n",
    "        self.train_loader = train_loader\n",
    "        self.eval_loader = eval_loader\n",
    "        self.total_models = total_models\n",
    "        self.total_epochs = total_epochs\n",
    "        self.initial_lr = initial_lr\n",
    "        self.device = device\n",
    "        self.redis_manager = redis_manager\n",
    "        self.llm = llm\n",
    "        self.gui = gui\n",
    "        self.models = []\n",
    "        self.ensemble_model = None\n",
    "        self.scaler = None\n",
    "        self.tuner = HyperparameterTuner(initial_lr=initial_lr)\n",
    "        self.lock = threading.Lock()  # To manage access to shared resources\n",
    "\n",
    "    def get_model(self, model_num: int):\n",
    "        \"\"\"\n",
    "        Dynamically initializes a model based on the model number.\n",
    "\n",
    "        Args:\n",
    "            model_num (int): The current model number.\n",
    "\n",
    "        Returns:\n",
    "            nn.Module: An instance of the selected model.\n",
    "        \"\"\"\n",
    "        # Example strategy: cycle through different model architectures\n",
    "        architectures = [\n",
    "            MLPMagician,\n",
    "            CNNMagician,\n",
    "            ResNetMagician,\n",
    "            VisionTransformerMagician,\n",
    "            DNNMagician,\n",
    "            RNNMagician\n",
    "        ]\n",
    "        architecture = architectures[model_num % len(architectures)]\n",
    "        \n",
    "        if architecture == MLPMagician:\n",
    "            model = MLPMagician(input_size=784, hidden_sizes=[256, 128, 64], dropout_rate=0.5)\n",
    "        elif architecture == CNNMagician:\n",
    "            model = CNNMagician(dropout_rate=0.5, num_classes=10)\n",
    "        elif architecture == ResNetMagician:\n",
    "            model = ResNetMagician(num_classes=10)\n",
    "        elif architecture == VisionTransformerMagician:\n",
    "            model = VisionTransformerMagician(num_classes=10, pretrained=True)\n",
    "        elif architecture == DNNMagician:\n",
    "            model = DNNMagician(input_size=784, hidden_sizes=[512, 256, 128], dropout_rate=0.5)\n",
    "        elif architecture == RNNMagician:\n",
    "            model = RNNMagician(input_size=10, hidden_size=50, num_layers=2, output_size=10, dropout_rate=0.3)\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported architecture: {architecture}\")\n",
    "        \n",
    "        model.to(self.device)\n",
    "        logging.info(f\"Initialized {architecture.__name__} for Model {model_num}.\")\n",
    "        return model\n",
    "\n",
    "    def train(self):\n",
    "        \"\"\"\n",
    "        Starts the training process in a separate thread to keep the GUI responsive.\n",
    "        \"\"\"\n",
    "        training_thread = threading.Thread(target=self._training_loop, daemon=True)\n",
    "        training_thread.start()\n",
    "\n",
    "    def _training_loop(self):\n",
    "        \"\"\"\n",
    "        The main training loop that iterates over the number of models and epochs.\n",
    "        \"\"\"\n",
    "        for model_num in range(1, self.total_models + 1):\n",
    "            try:\n",
    "                model = self.get_model(model_num)\n",
    "                self.models.append(model)\n",
    "                optimizer = optim.AdamW(model.parameters(), lr=self.initial_lr, weight_decay=1e-4)\n",
    "                scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3, verbose=True)\n",
    "                criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "                scaler = torch.cuda.amp.GradScaler() if self.device.type == 'cuda' else None\n",
    "\n",
    "                best_val_loss = float('inf')\n",
    "                best_val_accuracy = 0.0\n",
    "\n",
    "                for epoch in range(1, self.total_epochs + 1):\n",
    "                    model.train()\n",
    "                    running_loss = 0.0\n",
    "                    correct = 0\n",
    "                    total = 0\n",
    "\n",
    "                    for batch_idx, (inputs, labels) in enumerate(self.train_loader):\n",
    "                        inputs, labels = inputs.to(self.device), labels.to(self.device)\n",
    "                        \n",
    "                        optimizer.zero_grad()\n",
    "                        \n",
    "                        with torch.cuda.amp.autocast(enabled=self.device.type == 'cuda'):\n",
    "                            outputs = model(inputs)\n",
    "                            loss = criterion(outputs, labels)\n",
    "                        \n",
    "                        if scaler:\n",
    "                            scaler.scale(loss).backward()\n",
    "                            scaler.step(optimizer)\n",
    "                            scaler.update()\n",
    "                        else:\n",
    "                            loss.backward()\n",
    "                            optimizer.step()\n",
    "                        \n",
    "                        running_loss += loss.item() * inputs.size(0)\n",
    "                        _, predicted = torch.max(outputs.data, 1)\n",
    "                        total += labels.size(0)\n",
    "                        correct += (predicted == labels).sum().item()\n",
    "                    \n",
    "                    epoch_loss = running_loss / len(self.train_loader.dataset)\n",
    "                    epoch_acc = correct / total\n",
    "\n",
    "                    val_loss, val_acc = self.evaluate(model, criterion)\n",
    "\n",
    "                    scheduler.step(val_loss)\n",
    "                    self.tuner.adjust_learning_rate(optimizer, val_loss)\n",
    "\n",
    "                    # Update Redis with current metrics\n",
    "                    current_metrics = {\n",
    "                        'model_num': model_num,\n",
    "                        'epoch': epoch,\n",
    "                        'total_models': self.total_models,\n",
    "                        'total_epochs': self.total_epochs,\n",
    "                        'loss': epoch_loss,\n",
    "                        'accuracy': epoch_acc,\n",
    "                        'val_loss': val_loss,\n",
    "                        'val_accuracy': val_acc,\n",
    "                        'lr': optimizer.param_groups[0]['lr']\n",
    "                    }\n",
    "                    self.redis_manager.set_value('current_metrics', current_metrics)\n",
    "\n",
    "                    # Send update to GUI\n",
    "                    self.gui.queue.put({\n",
    "                        'type': 'epoch',\n",
    "                        'model_num': model_num,\n",
    "                        'total_models': self.total_models,\n",
    "                        'epoch': epoch,\n",
    "                        'total_epochs': self.total_epochs,\n",
    "                        'loss': epoch_loss,\n",
    "                        'accuracy': epoch_acc,\n",
    "                        'val_loss': val_loss,\n",
    "                        'val_accuracy': val_acc,\n",
    "                        'lr': optimizer.param_groups[0]['lr']\n",
    "                    })\n",
    "\n",
    "                    logging.info(f\"Model {model_num}, Epoch {epoch}/{self.total_epochs} - \"\n",
    "                                 f\"Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.4f}, \"\n",
    "                                 f\"Val Loss: {val_loss:.4f}, Val Accuracy: {val_acc:.4f}, \"\n",
    "                                 f\"LR: {optimizer.param_groups[0]['lr']:.6f}\")\n",
    "\n",
    "                # Save model checkpoint\n",
    "                checkpoint_path = f'models/model_{model_num}.pth'\n",
    "                torch.save(model.state_dict(), checkpoint_path)\n",
    "                logging.info(f\"Saved Model {model_num} at '{checkpoint_path}'.\")\n",
    "\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Error training Model {model_num}: {e}\")\n",
    "                continue\n",
    "\n",
    "        # After training all models, create an ensemble\n",
    "        self.create_ensemble()\n",
    "\n",
    "        # Notify GUI that training is completed\n",
    "        self.gui.queue.put({'type': 'training_completed'})\n",
    "\n",
    "    def evaluate(self, model: nn.Module, criterion: nn.Module):\n",
    "        \"\"\"\n",
    "        Evaluates the model on the validation dataset.\n",
    "\n",
    "        Args:\n",
    "            model (nn.Module): The trained model.\n",
    "            criterion (nn.Module): The loss function.\n",
    "\n",
    "        Returns:\n",
    "            tuple: (validation_loss, validation_accuracy)\n",
    "        \"\"\"\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in self.eval_loader:\n",
    "                inputs, labels = inputs.to(self.device), labels.to(self.device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        avg_val_loss = val_loss / len(self.eval_loader.dataset)\n",
    "        val_accuracy = correct / total\n",
    "\n",
    "        logging.info(f\"Validation - Loss: {avg_val_loss:.4f}, Accuracy: {val_accuracy:.4f}\")\n",
    "\n",
    "        return avg_val_loss, val_accuracy\n",
    "\n",
    "    def create_ensemble(self):\n",
    "        \"\"\"\n",
    "        Creates an ensemble model using a Random Forest classifier based on the trained models' outputs.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Collect features and labels from training data\n",
    "            all_features = []\n",
    "            all_labels = []\n",
    "            for model in self.models:\n",
    "                model.eval()\n",
    "                features = []\n",
    "                labels = []\n",
    "                with torch.no_grad():\n",
    "                    for inputs, lbls in self.train_loader:\n",
    "                        inputs = inputs.to(self.device)\n",
    "                        outputs = model(inputs)\n",
    "                        features.append(outputs.cpu().numpy())\n",
    "                        labels.append(lbls.numpy())\n",
    "                all_features.append(np.vstack(features))\n",
    "                all_labels.append(np.hstack(labels))\n",
    "            \n",
    "            # Concatenate features from all models\n",
    "            combined_features = np.hstack(all_features)\n",
    "            combined_labels = all_labels[0]  # Assuming all models have the same labels\n",
    "\n",
    "            # Scale features\n",
    "            scaler = StandardScaler()\n",
    "            scaled_features = scaler.fit_transform(combined_features)\n",
    "\n",
    "            # Train Random Forest ensemble\n",
    "            rf = RandomForestClassifier(n_estimators=300, max_depth=12, random_state=42, n_jobs=-1)\n",
    "            rf.fit(scaled_features, combined_labels)\n",
    "            self.ensemble_model = rf\n",
    "            self.scaler = scaler\n",
    "\n",
    "            # Save ensemble model\n",
    "            ensemble_path = 'ensemble_random_forest.pkl'\n",
    "            joblib.dump((rf, scaler), ensemble_path)\n",
    "            logging.info(f\"Saved ensemble model at '{ensemble_path}'.\")\n",
    "\n",
    "            # Evaluate ensemble on validation data\n",
    "            val_loss, val_accuracy = self.evaluate_ensemble()\n",
    "            self.gui.queue.put({'type': 'ensemble_accuracy', 'accuracy': val_accuracy})\n",
    "\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error creating ensemble: {e}\")\n",
    "\n",
    "    def evaluate_ensemble(self):\n",
    "        \"\"\"\n",
    "        Evaluates the ensemble model on the validation dataset.\n",
    "\n",
    "        Returns:\n",
    "            tuple: (validation_loss, validation_accuracy)\n",
    "        \"\"\"\n",
    "        if not self.ensemble_model or not self.scaler:\n",
    "            logging.error(\"Ensemble model or scaler not found.\")\n",
    "            return float('inf'), 0.0\n",
    "\n",
    "        all_features = []\n",
    "        all_labels = []\n",
    "        for model in self.models:\n",
    "            model.eval()\n",
    "            features = []\n",
    "            labels = []\n",
    "            with torch.no_grad():\n",
    "                for inputs, lbls in self.eval_loader:\n",
    "                    inputs = inputs.to(self.device)\n",
    "                    outputs = model(inputs)\n",
    "                    features.append(outputs.cpu().numpy())\n",
    "                    labels.append(lbls.numpy())\n",
    "            all_features.append(np.vstack(features))\n",
    "            all_labels.append(np.hstack(labels))\n",
    "        \n",
    "        # Concatenate features from all models\n",
    "        combined_features = np.hstack(all_features)\n",
    "        combined_labels = all_labels[0]  # Assuming all models have the same labels\n",
    "\n",
    "        # Scale features\n",
    "        scaled_features = self.scaler.transform(combined_features)\n",
    "\n",
    "        # Predict with Random Forest\n",
    "        predictions = self.ensemble_model.predict(scaled_features)\n",
    "        prediction_probs = self.ensemble_model.predict_proba(scaled_features)\n",
    "\n",
    "        # Calculate metrics\n",
    "        accuracy = accuracy_score(combined_labels, predictions)\n",
    "        loss = log_loss(combined_labels, prediction_probs)\n",
    "\n",
    "        logging.info(f\"Ensemble Validation - Loss: {loss:.4f}, Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "        return loss, accuracy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99658f43-b76a-4ad0-8459-562f1fa18625",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa64048-7f54-44c3-be45-7e91a9d20a0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc50195-64a5-4b1f-a242-0d19ad1c09f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97390b85-1d9c-4fbb-877c-939041c53a0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0cf8ba-2c92-464e-86a0-2209204239da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae0d674-53b0-43b1-a901-19947b7f6fbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfea14bd-9fc2-471d-b757-6ae0c68784b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381cc436-36ed-49d7-a9c7-088923cdb43b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ee0ebb-df77-47ee-ba4d-7e852d8c3d86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b8b113-59e3-431b-a1d1-32335c7a6aa2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ac47e2-d7bb-4ad1-b7fd-0590a7d250ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b3d482-e576-4a00-997a-340209d39021",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils/__init__.py\n",
    "\n",
    "from .logging_setup import initialize_logging\n",
    "from .redis_manager import RedisManager\n",
    "from .plot_utils import plot_training_metrics\n",
    "from .weight_initialization import initialize_weights\n",
    "from .hyperparameter_tuner import HyperparameterTuner\n",
    "from .hyperparameter_helper import randomize_params\n",
    "\n",
    "__all__ = [\n",
    "    'initialize_logging',\n",
    "    'RedisManager',\n",
    "    'plot_training_metrics',\n",
    "    'initialize_weights',\n",
    "    'HyperparameterTuner',\n",
    "    'randomize_params'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09c32c6-74aa-49c8-8e04-e65ca46befca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# models/__init__.py\n",
    "\n",
    "from .mlp_magician import MLPMagician\n",
    "from .cnn_magician import CNNMagician\n",
    "from .resnet_magician import ResNetMagician\n",
    "from .vision_transformer_magician import VisionTransformerMagician\n",
    "from .dnn_magician import DNNMagician\n",
    "from .rnn_magician import RNNMagician\n",
    "\n",
    "__all__ = [\n",
    "    'MLPMagician',\n",
    "    'CNNMagician',\n",
    "    'ResNetMagician',\n",
    "    'VisionTransformerMagician',\n",
    "    'DNNMagician',\n",
    "    'RNNMagician'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d86660-756b-4afc-b396-9d11efe8099d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main.py\n",
    "\n",
    "import tkinter as tk\n",
    "from utils.logging_setup import initialize_logging\n",
    "from utils.redis_manager import RedisManager\n",
    "from utils.strategy_llm import StrategyLLM\n",
    "from gui.training_gui import TrainingGUI\n",
    "from data.data_loader import load_arc_data, prepare_training_data, prepare_evaluation_data\n",
    "from training.trainer import Trainer\n",
    "from utils.hyperparameter_helper import randomize_params\n",
    "import torch\n",
    "\n",
    "def main():\n",
    "    # Initialize logging\n",
    "    initialize_logging()\n",
    "\n",
    "    # Initialize Redis Manager\n",
    "    redis_manager = RedisManager(host='localhost', port=6379, db=0)\n",
    "\n",
    "    # Initialize Strategy LLM\n",
    "    llm = StrategyLLM(model_name='gpt2')  # Adjust model name as needed\n",
    "\n",
    "    # Load ARC data\n",
    "    arc_data = load_arc_data()\n",
    "    if arc_data is None:\n",
    "        print(\"Failed to load ARC data.\")\n",
    "        return\n",
    "\n",
    "    # Prepare data loaders\n",
    "    train_loader = prepare_training_data(\n",
    "        arc_data=arc_data, \n",
    "        batch_size=32, \n",
    "        shuffle=True, \n",
    "        augment=True, \n",
    "        seed_manager=None  # Initialize SeedManager if needed\n",
    "    )\n",
    "    eval_loader = prepare_evaluation_data(\n",
    "        arc_data=arc_data, \n",
    "        batch_size=32, \n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    # Randomize hyperparameters\n",
    "    num_models, num_epochs, initial_lr, _ = randomize_params()\n",
    "\n",
    "    # Determine device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    # Initialize GUI\n",
    "    root = tk.Tk()\n",
    "    gui = TrainingGUI(\n",
    "        root=root, \n",
    "        total_models=num_models, \n",
    "        total_epochs=num_epochs, \n",
    "        redis_manager=redis_manager, \n",
    "        llm=llm\n",
    "    )\n",
    "\n",
    "    # Initialize Trainer\n",
    "    trainer = Trainer(\n",
    "        train_loader=train_loader,\n",
    "        eval_loader=eval_loader,\n",
    "        total_models=num_models,\n",
    "        total_epochs=num_epochs,\n",
    "        initial_lr=initial_lr,\n",
    "        device=device,\n",
    "        redis_manager=redis_manager,\n",
    "        llm=llm,\n",
    "        gui=gui\n",
    "    )\n",
    "\n",
    "    # Start training\n",
    "    trainer.train()\n",
    "\n",
    "    # Start the Tkinter main loop\n",
    "    root.mainloop()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a645f15-66f0-4ffa-a7f0-d593ea3cd1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class CNNGridExtractor(nn.Module):\n",
    "    \"\"\"Extract spatial features from grid patterns using CNN.\"\"\"\n",
    "    def __init__(self):\n",
    "        super(CNNGridExtractor, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc = nn.Linear(64 * 15 * 15, 256)  # Adjust for 30x30 grid\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.pool(self.conv1(x)))\n",
    "        x = F.relu(self.pool(self.conv2(x)))\n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "        features = F.relu(self.fc(x))\n",
    "        return features\n",
    "\n",
    "class RNNLearner(nn.Module):\n",
    "    \"\"\"Learns temporal dependencies across iterations.\"\"\"\n",
    "    def __init__(self, input_size=256, hidden_size=128, num_layers=2):\n",
    "        super(RNNLearner, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, 64)\n",
    "\n",
    "    def forward(self, x, hidden_state):\n",
    "        out, hidden_state = self.lstm(x, hidden_state)\n",
    "        output = self.fc(out[:, -1, :])  # Use last hidden state output\n",
    "        return output, hidden_state\n",
    "\n",
    "class HybridGridNetwork(nn.Module):\n",
    "    \"\"\"Combines CNN and RNN to learn grid-based patterns.\"\"\"\n",
    "    def __init__(self):\n",
    "        super(HybridGridNetwork, self).__init__()\n",
    "        self.cnn = CNNGridExtractor()\n",
    "        self.rnn = RNNLearner()\n",
    "        self.fc = nn.Linear(64, 10)  # Example output layer (10 classes)\n",
    "\n",
    "    def forward(self, x, hidden_state):\n",
    "        features = self.cnn(x)\n",
    "        features = features.unsqueeze(1)  # Add batch dimension for LSTM\n",
    "        rnn_output, hidden_state = self.rnn(features, hidden_state)\n",
    "        output = self.fc(rnn_output)\n",
    "        return output, hidden_state\n",
    "\n",
    "def initialize_hidden(batch_size, hidden_size=128, num_layers=2):\n",
    "    \"\"\"Initialize LSTM hidden state.\"\"\"\n",
    "    return (\n",
    "        torch.zeros(num_layers, batch_size, hidden_size).to(device),\n",
    "        torch.zeros(num_layers, batch_size, hidden_size).to(device)\n",
    "    )\n",
    "\n",
    "def preprocess_grid(grid):\n",
    "    \"\"\"Convert grid to tensor and normalize it.\"\"\"\n",
    "    grid_tensor = torch.tensor(grid, dtype=torch.float32).unsqueeze(0)  # Add channel dimension\n",
    "    return grid_tensor / 10.0  # Normalize values\n",
    "\n",
    "def compute_reward(predicted, target):\n",
    "    \"\"\"Compute reward based on MSE difference.\"\"\"\n",
    "    return 1.0 - F.mse_loss(predicted, target).item()\n",
    "\n",
    "def train_hybrid_model(\n",
    "    model, train_loader, eval_loader, num_epochs, optimizer, criterion, device\n",
    "):\n",
    "    \"\"\"Train the hybrid model using reinforcement learning and SGD.\"\"\"\n",
    "    hidden_state = initialize_hidden(train_loader.batch_size)\n",
    "    rewards = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss, total_reward = 0, 0\n",
    "\n",
    "        for inputs, targets in train_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs, hidden_state = model(inputs, hidden_state)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            reward = compute_reward(outputs, targets)\n",
    "            total_reward += reward\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        val_loss, val_accuracy = evaluate_model(model, eval_loader, criterion, device)\n",
    "        print(f\"Epoch {epoch+1}, Loss: {total_loss:.4f}, Reward: {total_reward:.4f}, Val Acc: {val_accuracy:.4f}\")\n",
    "\n",
    "    return model\n",
    "\n",
    "def evaluate_model(model, eval_loader, criterion, device):\n",
    "    \"\"\"Evaluate the model on validation data.\"\"\"\n",
    "    model.eval()\n",
    "    total_loss, correct_predictions, total_samples = 0, 0, 0\n",
    "    hidden_state = initialize_hidden(eval_loader.batch_size)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in eval_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs, _ = model(inputs, hidden_state)\n",
    "            loss = criterion(outputs, targets)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct_predictions += (predicted == targets).sum().item()\n",
    "            total_samples += targets.size(0)\n",
    "\n",
    "    avg_loss = total_loss / len(eval_loader)\n",
    "    accuracy = correct_predictions / total_samples\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "# Example usage\n",
    "grid_data = np.random.randint(0, 10, (100, 30, 30))  # Generate random grid data\n",
    "grid_labels = np.random.randint(0, 10, (100,))  # Random labels\n",
    "\n",
    "# Prepare DataLoader\n",
    "grids = torch.stack([preprocess_grid(grid) for grid in grid_data])\n",
    "labels = torch.tensor(grid_labels)\n",
    "dataset = TensorDataset(grids, labels)\n",
    "train_loader = DataLoader(dataset, batch_size=8, shuffle=True)\n",
    "eval_loader = DataLoader(dataset, batch_size=8)\n",
    "\n",
    "model = HybridGridNetwork().to(device)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-3)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Train the model\n",
    "train_hybrid_model(model, train_loader, eval_loader, num_epochs=500, optimizer=optimizer, criterion=criterion, device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdacfb24-5a2d-48db-af6f-62c2b38237a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "\n",
    "class CNNExtractor(nn.Module):\n",
    "    \"\"\"Extract visual features from image data using CNN.\"\"\"\n",
    "    def __init__(self):\n",
    "        super(CNNExtractor, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc = nn.Linear(128 * 15 * 15, 512)  # Assuming 30x30 input size\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.pool(self.conv1(x)))\n",
    "        x = F.relu(self.pool(self.conv2(x)))\n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "        features = F.relu(self.fc(x))\n",
    "        return features\n",
    "\n",
    "class RNNLearner(nn.Module):\n",
    "    \"\"\"Learns long-term dependencies from extracted features.\"\"\"\n",
    "    def __init__(self, input_size=512, hidden_size=256, num_layers=2):\n",
    "        super(RNNLearner, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, 128)  # Output for reinforcement learning\n",
    "\n",
    "    def forward(self, x, hidden_state):\n",
    "        out, hidden_state = self.lstm(x, hidden_state)\n",
    "        output = self.fc(out[:, -1, :])  # Use the last hidden state\n",
    "        return output, hidden_state\n",
    "\n",
    "class HybridNetwork(nn.Module):\n",
    "    \"\"\"Combines CNN and RNN for visual data learning.\"\"\"\n",
    "    def __init__(self):\n",
    "        super(HybridNetwork, self).__init__()\n",
    "        self.cnn = CNNExtractor()\n",
    "        self.rnn = RNNLearner()\n",
    "        self.fc = nn.Linear(128, 10)  # Example output layer (10 classes)\n",
    "\n",
    "    def forward(self, x, hidden_state):\n",
    "        features = self.cnn(x)\n",
    "        features = features.unsqueeze(1)  # Add batch dimension for LSTM\n",
    "        rnn_output, hidden_state = self.rnn(features, hidden_state)\n",
    "        output = self.fc(rnn_output)\n",
    "        return output, hidden_state\n",
    "\n",
    "def initialize_hidden(batch_size, hidden_size=256, num_layers=2):\n",
    "    \"\"\"Initialize LSTM hidden state.\"\"\"\n",
    "    return (\n",
    "        torch.zeros(num_layers, batch_size, hidden_size).to(device),\n",
    "        torch.zeros(num_layers, batch_size, hidden_size).to(device)\n",
    "    )\n",
    "\n",
    "def compute_reward(predicted, target):\n",
    "    \"\"\"Compute reward based on accuracy.\"\"\"\n",
    "    return 1.0 - F.mse_loss(predicted, target).item()  # Reward is inverse of MSE\n",
    "\n",
    "def train_hybrid_model(\n",
    "    model, train_loader, eval_loader, num_epochs, optimizer, criterion, device\n",
    "):\n",
    "    \"\"\"Train the hybrid model using reinforcement learning and SGD.\"\"\"\n",
    "    hidden_state = initialize_hidden(train_loader.batch_size)\n",
    "    rewards = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss, total_reward = 0, 0\n",
    "\n",
    "        for inputs, targets in train_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            outputs, hidden_state = model(inputs, hidden_state)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Compute reward and update long-term memory\n",
    "            reward = compute_reward(outputs, targets)\n",
    "            total_reward += reward\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        # Evaluate on validation set\n",
    "        val_loss, val_accuracy = evaluate_model(model, eval_loader, criterion, device)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {total_loss}, Reward: {total_reward}, Val Acc: {val_accuracy}\")\n",
    "\n",
    "    return model\n",
    "\n",
    "def evaluate_model(model, eval_loader, criterion, device):\n",
    "    \"\"\"Evaluate model on validation set.\"\"\"\n",
    "    model.eval()\n",
    "    total_loss, correct_predictions, total_samples = 0, 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        hidden_state = initialize_hidden(eval_loader.batch_size)\n",
    "        for inputs, targets in eval_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs, _ = model(inputs, hidden_state)\n",
    "            loss = criterion(outputs, targets)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct_predictions += (predicted == targets).sum().item()\n",
    "            total_samples += targets.size(0)\n",
    "\n",
    "    accuracy = correct_predictions / total_samples\n",
    "    avg_loss = total_loss / len(eval_loader)\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "# Usage example:\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = HybridNetwork().to(device)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-3)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Train and evaluate the model\n",
    "num_epochs = 500\n",
    "train_hybrid_model(model, train_loader, eval_loader, num_epochs, optimizer, criterion, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899e3340-5f67-43f4-b220-88902cdf81e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data/data_conversion.py\n",
    "\n",
    "import os\n",
    "import random\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import logging\n",
    "\n",
    "# Configure logging for the data_conversion module\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "def grid_to_image(grid, color_map):\n",
    "    \"\"\"\n",
    "    Converts a numerical grid into a colored image based on the provided color map.\n",
    "\n",
    "    Args:\n",
    "        grid (np.ndarray): 2D array representing the grid values.\n",
    "        color_map (dict): Dictionary mapping grid values to RGB colors.\n",
    "\n",
    "    Returns:\n",
    "        PIL.Image: Colored image representation of the grid.\n",
    "    \"\"\"\n",
    "    height, width = grid.shape\n",
    "    img_array = np.zeros((height, width, 3), dtype=np.uint8)\n",
    "\n",
    "    for i in range(height):\n",
    "        for j in range(width):\n",
    "            img_array[i, j] = color_map.get(grid[i, j], [255, 255, 255])  # Default to white\n",
    "\n",
    "    return Image.fromarray(img_array)\n",
    "\n",
    "\n",
    "def grid_to_grayscale(grid):\n",
    "    \"\"\"\n",
    "    Converts a numerical grid into a grayscale image.\n",
    "\n",
    "    Args:\n",
    "        grid (np.ndarray): 2D array representing the grid values.\n",
    "\n",
    "    Returns:\n",
    "        PIL.Image: Grayscale image representation of the grid.\n",
    "    \"\"\"\n",
    "    height, width = grid.shape\n",
    "    # Normalize grid values to 0-255\n",
    "    normalized_grid = (grid - grid.min()) / (grid.max() - grid.min()) * 255\n",
    "    grayscale_array = normalized_grid.astype(np.uint8)\n",
    "    return Image.fromarray(grayscale_array, mode='L')\n",
    "\n",
    "\n",
    "def grid_to_numeric_image(grid, font_path=None, font_size=12):\n",
    "    \"\"\"\n",
    "    Converts a numerical grid into an image with numbers overlaid on a blank background.\n",
    "\n",
    "    Args:\n",
    "        grid (np.ndarray): 2D array representing the grid values.\n",
    "        font_path (str, optional): Path to a .ttf font file. Defaults to None.\n",
    "        font_size (int, optional): Font size for the numbers. Defaults to 12.\n",
    "\n",
    "    Returns:\n",
    "        PIL.Image: Image with numbers overlaid on the grid.\n",
    "    \"\"\"\n",
    "    height, width = grid.shape\n",
    "    cell_size = 50  # Pixels\n",
    "    img_width = width * cell_size\n",
    "    img_height = height * cell_size\n",
    "\n",
    "    image = Image.new('RGB', (img_width, img_height), color='white')\n",
    "    draw = ImageDraw.Draw(image)\n",
    "\n",
    "    # Load a font\n",
    "    if font_path and os.path.exists(font_path):\n",
    "        font = ImageFont.truetype(font_path, font_size)\n",
    "    else:\n",
    "        font = ImageFont.load_default()\n",
    "\n",
    "    for i in range(height):\n",
    "        for j in range(width):\n",
    "            top_left = (j * cell_size, i * cell_size)\n",
    "            bottom_right = ((j + 1) * cell_size, (i + 1) * cell_size)\n",
    "            draw.rectangle([top_left, bottom_right], outline='black', fill='white')\n",
    "\n",
    "            # Overlay the number\n",
    "            number = str(grid[i, j])\n",
    "            text_width, text_height = draw.textsize(number, font=font)\n",
    "            text_x = top_left[0] + (cell_size - text_width) / 2\n",
    "            text_y = top_left[1] + (cell_size - text_height) / 2\n",
    "            draw.text((text_x, text_y), number, fill='black', font=font)\n",
    "\n",
    "    return image\n",
    "\n",
    "\n",
    "# data/data_conversion.py (continued)\n",
    "\n",
    "def augment_image_with_transforms(image, grid, perturb_prob=0.1, dead_square_prob=0.05, noise_prob=0.05):\n",
    "    \"\"\"\n",
    "    Applies random perturbations, dead squares, noise, and additional transformations to the image.\n",
    "\n",
    "    Args:\n",
    "        image (PIL.Image): The original image to augment.\n",
    "        grid (np.ndarray): The original grid data.\n",
    "        perturb_prob (float): Probability of perturbing a cell.\n",
    "        dead_square_prob (float): Probability of marking a cell as dead.\n",
    "        noise_prob (float): Probability of adding noise to a cell.\n",
    "\n",
    "    Returns:\n",
    "        PIL.Image: Augmented image.\n",
    "        list: List of dead squares as (i, j) tuples.\n",
    "    \"\"\"\n",
    "    augmented_grid = grid.copy()\n",
    "    height, width = grid.shape\n",
    "    dead_squares = []\n",
    "\n",
    "    for i in range(height):\n",
    "        for j in range(width):\n",
    "            rand_val = random.random()\n",
    "            if rand_val < perturb_prob:\n",
    "                # Introduce random perturbation\n",
    "                original_value = augmented_grid[i, j]\n",
    "                augmented_grid[i, j] = random.randint(0, augmented_grid.max())\n",
    "                logger.debug(f\"Perturbed cell ({i}, {j}) from {original_value} to {augmented_grid[i, j]}\")\n",
    "\n",
    "            if rand_val < dead_square_prob:\n",
    "                # Mark square as dead\n",
    "                dead_squares.append((i, j))\n",
    "                logger.debug(f\"Marked cell ({i}, {j}) as dead.\")\n",
    "\n",
    "            if rand_val < noise_prob:\n",
    "                # Add random noise by altering the pixel color slightly\n",
    "                pixels = image.load()\n",
    "                current_color = pixels[j, i]\n",
    "                noise = np.random.randint(-30, 31, size=3)\n",
    "                noisy_color = np.clip(np.array(current_color) + noise, 0, 255)\n",
    "                pixels[j, i] = tuple(noisy_color)\n",
    "                logger.debug(f\"Added noise to cell ({i}, {j}): {current_color} -> {pixels[j, i]}\")\n",
    "\n",
    "    # Apply additional transformations\n",
    "    transform = transforms.Compose([\n",
    "        transforms.RandomRotation(15),          # Rotate image by 15 degrees\n",
    "        transforms.RandomHorizontalFlip(p=0.5), # Flip image horizontally with 50% probability\n",
    "        transforms.RandomVerticalFlip(p=0.5),   # Flip image vertically with 50% probability\n",
    "    ])\n",
    "    augmented_image = grid_to_image(augmented_grid, color_map={\n",
    "        0: [0, 0, 0],        # Black\n",
    "        1: [255, 0, 0],      # Red\n",
    "        2: [0, 255, 0],      # Green\n",
    "        3: [0, 0, 255],      # Blue\n",
    "        4: [255, 255, 0],    # Yellow\n",
    "        5: [255, 165, 0],    # Orange\n",
    "        6: [128, 0, 128],    # Purple\n",
    "        7: [0, 255, 255],    # Cyan\n",
    "        8: [255, 192, 203],  # Pink\n",
    "        9: [128, 128, 128],  # Gray\n",
    "        10: [255, 255, 255], # White\n",
    "        # Add more mappings as needed\n",
    "    })\n",
    "    augmented_image = transform(augmented_image)\n",
    "\n",
    "    return augmented_image, dead_squares\n",
    "\n",
    "\n",
    "class GridDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Custom Dataset for handling grid-based image data.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, grids, transform=None, augmentation=True):\n",
    "        \"\"\"\n",
    "        Initializes the GridDataset.\n",
    "\n",
    "        Args:\n",
    "            grids (list of np.ndarray): List of 2D grid arrays.\n",
    "            transform (callable, optional): Transformations to apply to images. Defaults to None.\n",
    "            augmentation (bool, optional): Whether to apply data augmentation. Defaults to True.\n",
    "        \"\"\"\n",
    "        self.grids = grids\n",
    "        self.transform = transform\n",
    "        self.augmentation = augmentation\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.grids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        grid = self.grids[idx]\n",
    "        # Generate images\n",
    "        color_image = grid_to_image(grid, color_map={\n",
    "            0: [0, 0, 0],        # Black\n",
    "            1: [255, 0, 0],      # Red\n",
    "            2: [0, 255, 0],      # Green\n",
    "            3: [0, 0, 255],      # Blue\n",
    "            4: [255, 255, 0],    # Yellow\n",
    "            5: [255, 165, 0],    # Orange\n",
    "            6: [128, 0, 128],    # Purple\n",
    "            7: [0, 255, 255],    # Cyan\n",
    "            8: [255, 192, 203],  # Pink\n",
    "            9: [128, 128, 128],  # Gray\n",
    "            10: [255, 255, 255], # White\n",
    "            # Add more mappings as needed\n",
    "        })\n",
    "        grayscale_image = grid_to_grayscale(grid)\n",
    "        numeric_image = grid_to_numeric_image(grid)\n",
    "    \n",
    "        # Apply augmentation\n",
    "        if self.augmentation:\n",
    "            color_image_aug, dead_squares = augment_image_with_transforms(color_image, grid)\n",
    "            grayscale_image_aug, _ = augment_image_with_transforms(grayscale_image.convert('RGB'), grid)\n",
    "            numeric_image_aug, _ = augment_image_with_transforms(numeric_image, grid)\n",
    "        else:\n",
    "            color_image_aug = color_image\n",
    "            grayscale_image_aug = grayscale_image\n",
    "            numeric_image_aug = numeric_image\n",
    "    \n",
    "        # Apply transformations\n",
    "        if self.transform:\n",
    "            color_image_aug = self.transform(color_image_aug)\n",
    "            grayscale_image_aug = self.transform(grayscale_image_aug)\n",
    "            numeric_image_aug = self.transform(numeric_image_aug)\n",
    "    \n",
    "        return {\n",
    "            'color_image': color_image_aug,\n",
    "            'grayscale_image': grayscale_image_aug,\n",
    "            'numeric_image': numeric_image_aug,\n",
    "            'grid': torch.tensor(grid, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "\n",
    "def generate_grids(num_grids, grid_size, num_classes):\n",
    "    \"\"\"\n",
    "    Generates random grids for training.\n",
    "\n",
    "    Args:\n",
    "        num_grids (int): Number of grids to generate.\n",
    "        grid_size (int): Size of each grid (grid_size x grid_size).\n",
    "        num_classes (int): Number of classes/colors.\n",
    "\n",
    "    Returns:\n",
    "        list of np.ndarray: Generated grids.\n",
    "    \"\"\"\n",
    "    grids = []\n",
    "    for _ in range(num_grids):\n",
    "        grid = np.random.randint(0, num_classes, size=(grid_size, grid_size))\n",
    "        grids.append(grid)\n",
    "    logger.info(f\"Generated {num_grids} grids of size {grid_size}x{grid_size}.\")\n",
    "    return grids\n",
    "\n",
    "\n",
    "def get_data_loaders(batch_size=32, grid_size=10, num_classes=11, augment=True):\n",
    "    \"\"\"\n",
    "    Creates DataLoader instances for training and evaluation.\n",
    "\n",
    "    Args:\n",
    "        batch_size (int, optional): Number of samples per batch. Defaults to 32.\n",
    "        grid_size (int, optional): Size of each grid. Defaults to 10.\n",
    "        num_classes (int, optional): Number of classes/colors. Defaults to 11.\n",
    "        augment (bool, optional): Whether to apply data augmentation. Defaults to True.\n",
    "\n",
    "    Returns:\n",
    "        DataLoader: Training DataLoader.\n",
    "        DataLoader: Evaluation DataLoader.\n",
    "    \"\"\"\n",
    "    # Generate grids\n",
    "    train_grids = generate_grids(num_grids=1000, grid_size=grid_size, num_classes=num_classes)\n",
    "    eval_grids = generate_grids(num_grids=200, grid_size=grid_size, num_classes=num_classes)\n",
    "\n",
    "    # Define transformations\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((256, 256)),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "\n",
    "    # Create datasets\n",
    "    train_dataset = GridDataset(train_grids, transform=transform, augmentation=augment)\n",
    "    eval_dataset = GridDataset(eval_grids, transform=transform, augmentation=False)\n",
    "\n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "    eval_loader = DataLoader(eval_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "    logger.info(\"Created training and evaluation DataLoaders.\")\n",
    "    return train_loader, eval_loader\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
