{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8cc1ebb-e7e9-4ab7-b9f0-660a8d23e2de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Using device: cpu\n",
      "INFO:__main__:Loaded arc-agi_training-challenges from arc-agi_training_challenges.json.\n",
      "INFO:__main__:Loaded arc-agi_evaluation-challenges from arc-agi_evaluation_challenges.json.\n",
      "INFO:__main__:Loaded arc-agi_training-solutions from arc-agi_training_solutions.json.\n",
      "INFO:__main__:Loaded arc-agi_evaluation-solutions from arc-agi_evaluation_solutions.json.\n",
      "INFO:__main__:Parsing task 007bbfb7...\n",
      "INFO:__main__:Parsing task 00d62c1b...\n",
      "INFO:__main__:Parsing task 017c7c7b...\n",
      "INFO:__main__:Parsing task 025d127b...\n",
      "INFO:__main__:Parsing task 045e512c...\n",
      "INFO:__main__:Parsing task 0520fde7...\n",
      "INFO:__main__:Parsing task 05269061...\n",
      "INFO:__main__:Parsing task 05f2a901...\n",
      "INFO:__main__:Parsing task 06df4c85...\n",
      "INFO:__main__:Parsing task 08ed6ac7...\n",
      "INFO:__main__:Parsing task 09629e4f...\n",
      "INFO:__main__:Parsing task 0962bcdd...\n",
      "INFO:__main__:Parsing task 0a938d79...\n",
      "INFO:__main__:Parsing task 0b148d64...\n",
      "INFO:__main__:Parsing task 0ca9ddb6...\n",
      "INFO:__main__:Parsing task 0d3d703e...\n",
      "INFO:__main__:Parsing task 0dfd9992...\n",
      "INFO:__main__:Parsing task 0e206a2e...\n",
      "INFO:__main__:Parsing task 10fcaaa3...\n",
      "INFO:__main__:Parsing task 11852cab...\n",
      "INFO:__main__:Parsing task 1190e5a7...\n",
      "INFO:__main__:Parsing task 137eaa0f...\n",
      "INFO:__main__:Parsing task 150deff5...\n",
      "INFO:__main__:Parsing task 178fcbfb...\n",
      "INFO:__main__:Parsing task 1a07d186...\n",
      "INFO:__main__:Parsing task 1b2d62fb...\n",
      "INFO:__main__:Parsing task 1b60fb0c...\n",
      "INFO:__main__:Parsing task 1bfc4729...\n",
      "INFO:__main__:Parsing task 1c786137...\n",
      "INFO:__main__:Parsing task 1caeab9d...\n",
      "INFO:__main__:Parsing task 1cf80156...\n",
      "INFO:__main__:Parsing task 1e0a9b12...\n",
      "INFO:__main__:Parsing task 1e32b0e9...\n",
      "INFO:__main__:Parsing task 1f0c79e5...\n",
      "INFO:__main__:Parsing task 1f642eb9...\n",
      "INFO:__main__:Parsing task 1f85a75f...\n",
      "INFO:__main__:Parsing task 1f876c06...\n",
      "INFO:__main__:Parsing task 1fad071e...\n",
      "INFO:__main__:Parsing task 2013d3e2...\n",
      "INFO:__main__:Parsing task 2204b7a8...\n",
      "INFO:__main__:Parsing task 22168020...\n",
      "INFO:__main__:Parsing task 22233c11...\n",
      "INFO:__main__:Parsing task 2281f1f4...\n",
      "INFO:__main__:Parsing task 228f6490...\n",
      "INFO:__main__:Parsing task 22eb0ac0...\n",
      "INFO:__main__:Parsing task 234bbc79...\n",
      "INFO:__main__:Parsing task 23581191...\n",
      "INFO:__main__:Parsing task 239be575...\n",
      "INFO:__main__:Parsing task 23b5c85d...\n",
      "INFO:__main__:Parsing task 253bf280...\n",
      "INFO:__main__:Parsing task 25d487eb...\n",
      "INFO:__main__:Parsing task 25d8a9c8...\n",
      "INFO:__main__:Parsing task 25ff71a9...\n",
      "INFO:__main__:Parsing task 264363fd...\n",
      "INFO:__main__:Parsing task 272f95fa...\n",
      "INFO:__main__:Parsing task 27a28665...\n",
      "INFO:__main__:Parsing task 28bf18c6...\n",
      "INFO:__main__:Parsing task 28e73c20...\n",
      "INFO:__main__:Parsing task 29623171...\n",
      "INFO:__main__:Parsing task 29c11459...\n",
      "INFO:__main__:Parsing task 29ec7d0e...\n",
      "INFO:__main__:Parsing task 2bcee788...\n",
      "INFO:__main__:Parsing task 2bee17df...\n",
      "INFO:__main__:Parsing task 2c608aff...\n",
      "INFO:__main__:Parsing task 2dc579da...\n",
      "INFO:__main__:Parsing task 2dd70a9a...\n",
      "INFO:__main__:Parsing task 2dee498d...\n",
      "INFO:__main__:Parsing task 31aa019c...\n",
      "INFO:__main__:Parsing task 321b1fc6...\n",
      "INFO:__main__:Parsing task 32597951...\n",
      "INFO:__main__:Parsing task 3345333e...\n",
      "INFO:__main__:Parsing task 3428a4f5...\n",
      "INFO:__main__:Parsing task 3618c87e...\n",
      "INFO:__main__:Parsing task 3631a71a...\n",
      "INFO:__main__:Parsing task 363442ee...\n",
      "INFO:__main__:Parsing task 36d67576...\n",
      "INFO:__main__:Parsing task 36fdfd69...\n",
      "INFO:__main__:Parsing task 3906de3d...\n",
      "INFO:__main__:Parsing task 39a8645d...\n",
      "INFO:__main__:Parsing task 39e1d7f9...\n",
      "INFO:__main__:Parsing task 3aa6fb7a...\n",
      "INFO:__main__:Parsing task 3ac3eb23...\n",
      "INFO:__main__:Parsing task 3af2c5a8...\n",
      "INFO:__main__:Parsing task 3bd67248...\n",
      "INFO:__main__:Parsing task 3bdb4ada...\n",
      "INFO:__main__:Parsing task 3befdf3e...\n",
      "INFO:__main__:Parsing task 3c9b0459...\n",
      "INFO:__main__:Parsing task 3de23699...\n",
      "INFO:__main__:Parsing task 3e980e27...\n",
      "INFO:__main__:Parsing task 3eda0437...\n",
      "INFO:__main__:Parsing task 3f7978a0...\n",
      "INFO:__main__:Parsing task 40853293...\n",
      "INFO:__main__:Parsing task 4093f84a...\n",
      "INFO:__main__:Parsing task 41e4d17e...\n",
      "INFO:__main__:Parsing task 4258a5f9...\n",
      "INFO:__main__:Parsing task 4290ef0e...\n",
      "INFO:__main__:Parsing task 42a50994...\n",
      "INFO:__main__:Parsing task 4347f46a...\n",
      "INFO:__main__:Parsing task 444801d8...\n",
      "INFO:__main__:Parsing task 445eab21...\n",
      "INFO:__main__:Parsing task 447fd412...\n",
      "INFO:__main__:Parsing task 44d8ac46...\n",
      "INFO:__main__:Parsing task 44f52bb0...\n",
      "INFO:__main__:Parsing task 4522001f...\n",
      "INFO:__main__:Parsing task 4612dd53...\n",
      "INFO:__main__:Parsing task 46442a0e...\n",
      "INFO:__main__:Parsing task 469497ad...\n",
      "INFO:__main__:Parsing task 46f33fce...\n",
      "INFO:__main__:Parsing task 47c1f68c...\n",
      "INFO:__main__:Parsing task 484b58aa...\n",
      "INFO:__main__:Parsing task 48d8fb45...\n",
      "INFO:__main__:Parsing task 4938f0c2...\n",
      "INFO:__main__:Parsing task 496994bd...\n",
      "INFO:__main__:Parsing task 49d1d64f...\n",
      "INFO:__main__:Parsing task 4be741c5...\n",
      "INFO:__main__:Parsing task 4c4377d9...\n",
      "INFO:__main__:Parsing task 4c5c2cf0...\n",
      "INFO:__main__:Parsing task 50846271...\n",
      "INFO:__main__:Parsing task 508bd3b6...\n",
      "INFO:__main__:Parsing task 50cb2852...\n",
      "INFO:__main__:Parsing task 5117e062...\n",
      "INFO:__main__:Parsing task 5168d44c...\n",
      "INFO:__main__:Parsing task 539a4f51...\n",
      "INFO:__main__:Parsing task 53b68214...\n",
      "INFO:__main__:Parsing task 543a7ed5...\n",
      "INFO:__main__:Parsing task 54d82841...\n",
      "INFO:__main__:Parsing task 54d9e175...\n",
      "INFO:__main__:Parsing task 5521c0d9...\n",
      "INFO:__main__:Parsing task 5582e5ca...\n",
      "INFO:__main__:Parsing task 5614dbcf...\n",
      "INFO:__main__:Parsing task 56dc2b01...\n",
      "INFO:__main__:Parsing task 56ff96f3...\n",
      "INFO:__main__:Parsing task 57aa92db...\n",
      "INFO:__main__:Parsing task 5ad4f10b...\n",
      "INFO:__main__:Parsing task 5bd6f4ac...\n",
      "INFO:__main__:Parsing task 5c0a986e...\n",
      "INFO:__main__:Parsing task 5c2c9af4...\n",
      "INFO:__main__:Parsing task 5daaa586...\n",
      "INFO:__main__:Parsing task 60b61512...\n",
      "INFO:__main__:Parsing task 6150a2bd...\n",
      "INFO:__main__:Parsing task 623ea044...\n",
      "INFO:__main__:Parsing task 62c24649...\n",
      "INFO:__main__:Parsing task 63613498...\n",
      "INFO:__main__:Parsing task 6430c8c4...\n",
      "INFO:__main__:Parsing task 6455b5f5...\n",
      "INFO:__main__:Parsing task 662c240a...\n",
      "INFO:__main__:Parsing task 67385a82...\n",
      "INFO:__main__:Parsing task 673ef223...\n",
      "INFO:__main__:Parsing task 6773b310...\n",
      "INFO:__main__:Parsing task 67a3c6ac...\n",
      "INFO:__main__:Parsing task 67a423a3...\n",
      "INFO:__main__:Parsing task 67e8384a...\n",
      "INFO:__main__:Parsing task 681b3aeb...\n",
      "INFO:__main__:Parsing task 6855a6e4...\n",
      "INFO:__main__:Parsing task 68b16354...\n",
      "INFO:__main__:Parsing task 694f12f3...\n",
      "INFO:__main__:Parsing task 6a1e5592...\n",
      "INFO:__main__:Parsing task 6aa20dc0...\n",
      "INFO:__main__:Parsing task 6b9890af...\n",
      "INFO:__main__:Parsing task 6c434453...\n",
      "INFO:__main__:Parsing task 6cdd2623...\n",
      "INFO:__main__:Parsing task 6cf79266...\n",
      "INFO:__main__:Parsing task 6d0160f0...\n",
      "INFO:__main__:Parsing task 6d0aefbc...\n",
      "INFO:__main__:Parsing task 6d58a25d...\n",
      "INFO:__main__:Parsing task 6d75e8bb...\n",
      "INFO:__main__:Parsing task 6e02f1e3...\n",
      "INFO:__main__:Parsing task 6e19193c...\n",
      "INFO:__main__:Parsing task 6e82a1ae...\n",
      "INFO:__main__:Parsing task 6ecd11f4...\n",
      "INFO:__main__:Parsing task 6f8cd79b...\n",
      "INFO:__main__:Parsing task 6fa7a44f...\n",
      "INFO:__main__:Parsing task 72322fa7...\n",
      "INFO:__main__:Parsing task 72ca375d...\n",
      "INFO:__main__:Parsing task 73251a56...\n",
      "INFO:__main__:Parsing task 7447852a...\n",
      "INFO:__main__:Parsing task 7468f01a...\n",
      "INFO:__main__:Parsing task 746b3537...\n",
      "INFO:__main__:Parsing task 74dd1130...\n",
      "INFO:__main__:Parsing task 75b8110e...\n",
      "INFO:__main__:Parsing task 760b3cac...\n",
      "INFO:__main__:Parsing task 776ffc46...\n",
      "INFO:__main__:Parsing task 77fdfe62...\n",
      "INFO:__main__:Parsing task 780d0b14...\n",
      "INFO:__main__:Parsing task 7837ac64...\n",
      "INFO:__main__:Parsing task 794b24be...\n",
      "INFO:__main__:Parsing task 7b6016b9...\n",
      "INFO:__main__:Parsing task 7b7f7511...\n",
      "INFO:__main__:Parsing task 7c008303...\n",
      "INFO:__main__:Parsing task 7ddcd7ec...\n",
      "INFO:__main__:Parsing task 7df24a62...\n",
      "INFO:__main__:Parsing task 7e0986d6...\n",
      "INFO:__main__:Parsing task 7f4411dc...\n",
      "INFO:__main__:Parsing task 7fe24cdd...\n",
      "INFO:__main__:Parsing task 80af3007...\n",
      "INFO:__main__:Parsing task 810b9b61...\n",
      "INFO:__main__:Parsing task 82819916...\n",
      "INFO:__main__:Parsing task 83302e8f...\n",
      "INFO:__main__:Parsing task 834ec97d...\n",
      "INFO:__main__:Parsing task 8403a5d5...\n",
      "INFO:__main__:Parsing task 846bdb03...\n",
      "INFO:__main__:Parsing task 855e0971...\n",
      "INFO:__main__:Parsing task 85c4e7cd...\n",
      "INFO:__main__:Parsing task 868de0fa...\n",
      "INFO:__main__:Parsing task 8731374e...\n",
      "INFO:__main__:Parsing task 88a10436...\n",
      "INFO:__main__:Parsing task 88a62173...\n",
      "INFO:__main__:Parsing task 890034e9...\n",
      "INFO:__main__:Parsing task 8a004b2b...\n",
      "INFO:__main__:Parsing task 8be77c9e...\n",
      "INFO:__main__:Parsing task 8d5021e8...\n",
      "INFO:__main__:Parsing task 8d510a79...\n",
      "INFO:__main__:Parsing task 8e1813be...\n",
      "INFO:__main__:Parsing task 8e5a5113...\n",
      "INFO:__main__:Parsing task 8eb1be9a...\n",
      "INFO:__main__:Parsing task 8efcae92...\n",
      "INFO:__main__:Parsing task 8f2ea7aa...\n",
      "INFO:__main__:Parsing task 90c28cc7...\n",
      "INFO:__main__:Parsing task 90f3ed37...\n",
      "INFO:__main__:Parsing task 913fb3ed...\n",
      "INFO:__main__:Parsing task 91413438...\n",
      "INFO:__main__:Parsing task 91714a58...\n",
      "INFO:__main__:Parsing task 9172f3a0...\n",
      "INFO:__main__:Parsing task 928ad970...\n",
      "INFO:__main__:Parsing task 93b581b8...\n",
      "INFO:__main__:Parsing task 941d9a10...\n",
      "INFO:__main__:Parsing task 94f9d214...\n",
      "INFO:__main__:Parsing task 952a094c...\n",
      "INFO:__main__:Parsing task 9565186b...\n",
      "INFO:__main__:Parsing task 95990924...\n",
      "INFO:__main__:Parsing task 963e52fc...\n",
      "INFO:__main__:Parsing task 97999447...\n",
      "INFO:__main__:Parsing task 97a05b5b...\n",
      "INFO:__main__:Parsing task 98cf29f8...\n",
      "INFO:__main__:Parsing task 995c5fa3...\n",
      "INFO:__main__:Parsing task 99b1bc43...\n",
      "INFO:__main__:Parsing task 99fa7670...\n",
      "INFO:__main__:Parsing task 9aec4887...\n",
      "INFO:__main__:Parsing task 9af7a82c...\n",
      "INFO:__main__:Parsing task 9d9215db...\n",
      "INFO:__main__:Parsing task 9dfd6313...\n",
      "INFO:__main__:Parsing task 9ecd008a...\n",
      "INFO:__main__:Parsing task 9edfc990...\n",
      "INFO:__main__:Parsing task 9f236235...\n",
      "INFO:__main__:Parsing task a1570a43...\n",
      "INFO:__main__:Parsing task a2fd1cf0...\n",
      "INFO:__main__:Parsing task a3325580...\n",
      "INFO:__main__:Parsing task a3df8b1e...\n",
      "INFO:__main__:Parsing task a416b8f3...\n",
      "INFO:__main__:Parsing task a48eeaf7...\n",
      "INFO:__main__:Parsing task a5313dff...\n",
      "INFO:__main__:Parsing task a5f85a15...\n",
      "INFO:__main__:Parsing task a61ba2ce...\n",
      "INFO:__main__:Parsing task a61f2674...\n",
      "INFO:__main__:Parsing task a64e4611...\n",
      "INFO:__main__:Parsing task a65b410d...\n",
      "INFO:__main__:Parsing task a68b268e...\n",
      "INFO:__main__:Parsing task a699fb00...\n",
      "INFO:__main__:Parsing task a740d043...\n",
      "INFO:__main__:Parsing task a78176bb...\n",
      "INFO:__main__:Parsing task a79310a0...\n",
      "INFO:__main__:Parsing task a85d4709...\n",
      "INFO:__main__:Parsing task a87f7484...\n",
      "INFO:__main__:Parsing task a8c38be5...\n",
      "INFO:__main__:Parsing task a8d7556c...\n",
      "INFO:__main__:Parsing task a9f96cdd...\n",
      "INFO:__main__:Parsing task aabf363d...\n",
      "INFO:__main__:Parsing task aba27056...\n",
      "INFO:__main__:Parsing task ac0a08a4...\n",
      "INFO:__main__:Parsing task ae3edfdc...\n",
      "INFO:__main__:Parsing task ae4f1146...\n",
      "INFO:__main__:Parsing task aedd82e4...\n",
      "INFO:__main__:Parsing task af902bf9...\n",
      "INFO:__main__:Parsing task b0c4d837...\n",
      "INFO:__main__:Parsing task b190f7f5...\n",
      "INFO:__main__:Parsing task b1948b0a...\n",
      "INFO:__main__:Parsing task b230c067...\n",
      "INFO:__main__:Parsing task b27ca6d3...\n",
      "INFO:__main__:Parsing task b2862040...\n",
      "INFO:__main__:Parsing task b527c5c6...\n",
      "INFO:__main__:Parsing task b548a754...\n",
      "INFO:__main__:Parsing task b60334d2...\n",
      "INFO:__main__:Parsing task b6afb2da...\n",
      "INFO:__main__:Parsing task b7249182...\n",
      "INFO:__main__:Parsing task b775ac94...\n",
      "INFO:__main__:Parsing task b782dc8a...\n",
      "INFO:__main__:Parsing task b8825c91...\n",
      "INFO:__main__:Parsing task b8cdaf2b...\n",
      "INFO:__main__:Parsing task b91ae062...\n",
      "INFO:__main__:Parsing task b94a9452...\n",
      "INFO:__main__:Parsing task b9b7f026...\n",
      "INFO:__main__:Parsing task ba26e723...\n",
      "INFO:__main__:Parsing task ba97ae07...\n",
      "INFO:__main__:Parsing task bb43febb...\n",
      "INFO:__main__:Parsing task bbc9ae5d...\n",
      "INFO:__main__:Parsing task bc1d5164...\n",
      "INFO:__main__:Parsing task bd4472b8...\n",
      "INFO:__main__:Parsing task bda2d7a6...\n",
      "INFO:__main__:Parsing task bdad9b1f...\n",
      "INFO:__main__:Parsing task be94b721...\n",
      "INFO:__main__:Parsing task beb8660c...\n",
      "INFO:__main__:Parsing task c0f76784...\n",
      "INFO:__main__:Parsing task c1d99e64...\n",
      "INFO:__main__:Parsing task c3e719e8...\n",
      "INFO:__main__:Parsing task c3f564a4...\n",
      "INFO:__main__:Parsing task c444b776...\n",
      "INFO:__main__:Parsing task c59eb873...\n",
      "INFO:__main__:Parsing task c8cbb738...\n",
      "INFO:__main__:Parsing task c8f0f002...\n",
      "INFO:__main__:Parsing task c909285e...\n",
      "INFO:__main__:Parsing task c9e6f938...\n",
      "INFO:__main__:Parsing task c9f8e694...\n",
      "INFO:__main__:Parsing task caa06a1f...\n",
      "INFO:__main__:Parsing task cbded52d...\n",
      "INFO:__main__:Parsing task cce03e0d...\n",
      "INFO:__main__:Parsing task cdecee7f...\n",
      "INFO:__main__:Parsing task ce22a75a...\n",
      "INFO:__main__:Parsing task ce4f8723...\n",
      "INFO:__main__:Parsing task ce602527...\n",
      "INFO:__main__:Parsing task ce9e57f2...\n",
      "INFO:__main__:Parsing task cf98881b...\n",
      "INFO:__main__:Parsing task d037b0a7...\n",
      "INFO:__main__:Parsing task d06dbe63...\n",
      "INFO:__main__:Parsing task d07ae81c...\n",
      "INFO:__main__:Parsing task d0f5fe59...\n",
      "INFO:__main__:Parsing task d10ecb37...\n",
      "INFO:__main__:Parsing task d13f3404...\n",
      "INFO:__main__:Parsing task d22278a0...\n",
      "INFO:__main__:Parsing task d23f8c26...\n",
      "INFO:__main__:Parsing task d2abd087...\n",
      "INFO:__main__:Parsing task d364b489...\n",
      "INFO:__main__:Parsing task d406998b...\n",
      "INFO:__main__:Parsing task d43fd935...\n",
      "INFO:__main__:Parsing task d4469b4b...\n",
      "INFO:__main__:Parsing task d4a91cb9...\n",
      "INFO:__main__:Parsing task d4f3cd78...\n",
      "INFO:__main__:Parsing task d511f180...\n",
      "INFO:__main__:Parsing task d5d6de2d...\n",
      "INFO:__main__:Parsing task d631b094...\n",
      "INFO:__main__:Parsing task d687bc17...\n",
      "INFO:__main__:Parsing task d6ad076f...\n",
      "INFO:__main__:Parsing task d89b689b...\n",
      "INFO:__main__:Parsing task d8c310e9...\n",
      "INFO:__main__:Parsing task d90796e8...\n",
      "INFO:__main__:Parsing task d9f24cd1...\n",
      "INFO:__main__:Parsing task d9fac9be...\n",
      "INFO:__main__:Parsing task dae9d2b5...\n",
      "INFO:__main__:Parsing task db3e9e38...\n",
      "INFO:__main__:Parsing task db93a21d...\n",
      "INFO:__main__:Parsing task dbc1a6ce...\n",
      "INFO:__main__:Parsing task dc0a314f...\n",
      "INFO:__main__:Parsing task dc1df850...\n",
      "INFO:__main__:Parsing task dc433765...\n",
      "INFO:__main__:Parsing task ddf7fa4f...\n",
      "INFO:__main__:Parsing task de1cd16c...\n",
      "INFO:__main__:Parsing task ded97339...\n",
      "INFO:__main__:Parsing task e179c5f4...\n",
      "INFO:__main__:Parsing task e21d9049...\n",
      "INFO:__main__:Parsing task e26a3af2...\n",
      "INFO:__main__:Parsing task e3497940...\n",
      "INFO:__main__:Parsing task e40b9e2f...\n",
      "INFO:__main__:Parsing task e48d4e1a...\n",
      "INFO:__main__:Parsing task e5062a87...\n",
      "INFO:__main__:Parsing task e509e548...\n",
      "INFO:__main__:Parsing task e50d258f...\n",
      "INFO:__main__:Parsing task e6721834...\n",
      "INFO:__main__:Parsing task e73095fd...\n",
      "INFO:__main__:Parsing task e76a88a6...\n",
      "INFO:__main__:Parsing task e8593010...\n",
      "INFO:__main__:Parsing task e8dc4411...\n",
      "INFO:__main__:Parsing task e9614598...\n",
      "INFO:__main__:Parsing task e98196ab...\n",
      "INFO:__main__:Parsing task e9afcf9a...\n",
      "INFO:__main__:Parsing task ea32f347...\n",
      "INFO:__main__:Parsing task ea786f4a...\n",
      "INFO:__main__:Parsing task eb281b96...\n",
      "INFO:__main__:Parsing task eb5a1d5d...\n",
      "INFO:__main__:Parsing task ec883f72...\n",
      "INFO:__main__:Parsing task ecdecbb3...\n",
      "INFO:__main__:Parsing task ed36ccf7...\n",
      "INFO:__main__:Parsing task ef135b50...\n",
      "INFO:__main__:Parsing task f15e1fac...\n",
      "INFO:__main__:Parsing task f1cefba8...\n",
      "INFO:__main__:Parsing task f25fbde4...\n",
      "INFO:__main__:Parsing task f25ffba3...\n",
      "INFO:__main__:Parsing task f2829549...\n",
      "INFO:__main__:Parsing task f35d900a...\n",
      "INFO:__main__:Parsing task f5b8619d...\n",
      "INFO:__main__:Parsing task f76d97a5...\n",
      "INFO:__main__:Parsing task f8a8fe49...\n",
      "INFO:__main__:Parsing task f8b3ba0a...\n",
      "INFO:__main__:Parsing task f8c80d96...\n",
      "INFO:__main__:Parsing task f8ff0b80...\n",
      "INFO:__main__:Parsing task f9012d9b...\n",
      "INFO:__main__:Parsing task fafffa47...\n",
      "INFO:__main__:Parsing task fcb5c309...\n",
      "INFO:__main__:Parsing task fcc82909...\n",
      "INFO:__main__:Parsing task feca6190...\n",
      "INFO:__main__:Parsing task ff28f65a...\n",
      "INFO:__main__:Parsing task ff805c23...\n",
      "INFO:__main__:Total valid grid pairs extracted: 1302\n",
      "INFO:__main__:Parsing task 00576224...\n",
      "INFO:__main__:Parsing task 009d5c81...\n",
      "INFO:__main__:Parsing task 00dbd492...\n",
      "INFO:__main__:Parsing task 03560426...\n",
      "INFO:__main__:Parsing task 05a7bcf2...\n",
      "INFO:__main__:Parsing task 0607ce86...\n",
      "INFO:__main__:Parsing task 0692e18c...\n",
      "INFO:__main__:Parsing task 070dd51e...\n",
      "INFO:__main__:Parsing task 08573cc6...\n",
      "INFO:__main__:Parsing task 0934a4d8...\n",
      "INFO:__main__:Parsing task 09c534e7...\n",
      "INFO:__main__:Parsing task 0a1d4ef5...\n",
      "INFO:__main__:Parsing task 0a2355a6...\n",
      "INFO:__main__:Parsing task 0b17323b...\n",
      "INFO:__main__:Parsing task 0bb8deee...\n",
      "INFO:__main__:Parsing task 0becf7df...\n",
      "INFO:__main__:Parsing task 0c786b71...\n",
      "INFO:__main__:Parsing task 0c9aba6e...\n",
      "INFO:__main__:Parsing task 0d87d2a6...\n",
      "INFO:__main__:Parsing task 0e671a1a...\n",
      "INFO:__main__:Parsing task 0f63c0b9...\n",
      "INFO:__main__:Parsing task 103eff5b...\n",
      "INFO:__main__:Parsing task 11e1fe23...\n",
      "INFO:__main__:Parsing task 12422b43...\n",
      "INFO:__main__:Parsing task 12997ef3...\n",
      "INFO:__main__:Parsing task 12eac192...\n",
      "INFO:__main__:Parsing task 136b0064...\n",
      "INFO:__main__:Parsing task 13713586...\n",
      "INFO:__main__:Parsing task 137f0df0...\n",
      "INFO:__main__:Parsing task 140c817e...\n",
      "INFO:__main__:Parsing task 14754a24...\n",
      "INFO:__main__:Parsing task 15113be4...\n",
      "INFO:__main__:Parsing task 15663ba9...\n",
      "INFO:__main__:Parsing task 15696249...\n",
      "INFO:__main__:Parsing task 16b78196...\n",
      "INFO:__main__:Parsing task 17b80ad2...\n",
      "INFO:__main__:Parsing task 17cae0c1...\n",
      "INFO:__main__:Parsing task 18419cfa...\n",
      "INFO:__main__:Parsing task 184a9768...\n",
      "INFO:__main__:Parsing task 195ba7dc...\n",
      "INFO:__main__:Parsing task 1990f7a8...\n",
      "INFO:__main__:Parsing task 19bb5feb...\n",
      "INFO:__main__:Parsing task 1a2e2828...\n",
      "INFO:__main__:Parsing task 1a6449f1...\n",
      "INFO:__main__:Parsing task 1acc24af...\n",
      "INFO:__main__:Parsing task 1c02dbbe...\n",
      "INFO:__main__:Parsing task 1c0d0a4b...\n",
      "INFO:__main__:Parsing task 1c56ad9f...\n",
      "INFO:__main__:Parsing task 1d0a4b61...\n",
      "INFO:__main__:Parsing task 1d398264...\n",
      "INFO:__main__:Parsing task 1da012fc...\n",
      "INFO:__main__:Parsing task 1e81d6f9...\n",
      "INFO:__main__:Parsing task 1e97544e...\n",
      "INFO:__main__:Parsing task 2037f2c7...\n",
      "INFO:__main__:Parsing task 2072aba6...\n",
      "INFO:__main__:Parsing task 20818e16...\n",
      "INFO:__main__:Parsing task 20981f0e...\n",
      "INFO:__main__:Parsing task 212895b5...\n",
      "INFO:__main__:Parsing task 21f83797...\n",
      "INFO:__main__:Parsing task 22a4bbc2...\n",
      "INFO:__main__:Parsing task 25094a63...\n",
      "INFO:__main__:Parsing task 2546ccf6...\n",
      "INFO:__main__:Parsing task 256b0a75...\n",
      "INFO:__main__:Parsing task 2685904e...\n",
      "INFO:__main__:Parsing task 2697da3f...\n",
      "INFO:__main__:Parsing task 2753e76c...\n",
      "INFO:__main__:Parsing task 27a77e38...\n",
      "INFO:__main__:Parsing task 27f8ce4f...\n",
      "INFO:__main__:Parsing task 281123b4...\n",
      "INFO:__main__:Parsing task 292dd178...\n",
      "INFO:__main__:Parsing task 29700607...\n",
      "INFO:__main__:Parsing task 2a5f8217...\n",
      "INFO:__main__:Parsing task 2b01abd0...\n",
      "INFO:__main__:Parsing task 2c0b0aff...\n",
      "INFO:__main__:Parsing task 2c737e39...\n",
      "INFO:__main__:Parsing task 2f0c5170...\n",
      "INFO:__main__:Parsing task 310f3251...\n",
      "INFO:__main__:Parsing task 3194b014...\n",
      "INFO:__main__:Parsing task 319f2597...\n",
      "INFO:__main__:Parsing task 31adaf00...\n",
      "INFO:__main__:Parsing task 31d5ba1a...\n",
      "INFO:__main__:Parsing task 32e9702f...\n",
      "INFO:__main__:Parsing task 332efdb3...\n",
      "INFO:__main__:Parsing task 3391f8c0...\n",
      "INFO:__main__:Parsing task 33b52de3...\n",
      "INFO:__main__:Parsing task 3490cc26...\n",
      "INFO:__main__:Parsing task 34b99a2b...\n",
      "INFO:__main__:Parsing task 351d6448...\n",
      "INFO:__main__:Parsing task 358ba94e...\n",
      "INFO:__main__:Parsing task 37d3e8b2...\n",
      "INFO:__main__:Parsing task 3979b1a8...\n",
      "INFO:__main__:Parsing task 3a301edc...\n",
      "INFO:__main__:Parsing task 3b4c2228...\n",
      "INFO:__main__:Parsing task 3d31c5b3...\n",
      "INFO:__main__:Parsing task 3ed85e70...\n",
      "INFO:__main__:Parsing task 3ee1011a...\n",
      "INFO:__main__:Parsing task 3f23242b...\n",
      "INFO:__main__:Parsing task 40f6cd08...\n",
      "INFO:__main__:Parsing task 414297c0...\n",
      "INFO:__main__:Parsing task 423a55dc...\n",
      "INFO:__main__:Parsing task 42918530...\n",
      "INFO:__main__:Parsing task 42a15761...\n",
      "INFO:__main__:Parsing task 4364c1c4...\n",
      "INFO:__main__:Parsing task 456873bc...\n",
      "INFO:__main__:Parsing task 45737921...\n",
      "INFO:__main__:Parsing task 45bbe264...\n",
      "INFO:__main__:Parsing task 477d2879...\n",
      "INFO:__main__:Parsing task 47996f11...\n",
      "INFO:__main__:Parsing task 48131b3c...\n",
      "INFO:__main__:Parsing task 4852f2fa...\n",
      "INFO:__main__:Parsing task 48f8583b...\n",
      "INFO:__main__:Parsing task 4aab4007...\n",
      "INFO:__main__:Parsing task 4acc7107...\n",
      "INFO:__main__:Parsing task 4b6b68e5...\n",
      "INFO:__main__:Parsing task 4c177718...\n",
      "INFO:__main__:Parsing task 4cd1b7b2...\n",
      "INFO:__main__:Parsing task 4e45f183...\n",
      "INFO:__main__:Parsing task 4e469f39...\n",
      "INFO:__main__:Parsing task 4f537728...\n",
      "INFO:__main__:Parsing task 4ff4c9da...\n",
      "INFO:__main__:Parsing task 505fff84...\n",
      "INFO:__main__:Parsing task 506d28a5...\n",
      "INFO:__main__:Parsing task 50a16a69...\n",
      "INFO:__main__:Parsing task 50aad11f...\n",
      "INFO:__main__:Parsing task 50f325b5...\n",
      "INFO:__main__:Parsing task 516b51b7...\n",
      "INFO:__main__:Parsing task 5207a7b5...\n",
      "INFO:__main__:Parsing task 5289ad53...\n",
      "INFO:__main__:Parsing task 52fd389e...\n",
      "INFO:__main__:Parsing task 54db823b...\n",
      "INFO:__main__:Parsing task 55059096...\n",
      "INFO:__main__:Parsing task 551d5bf1...\n",
      "INFO:__main__:Parsing task 55783887...\n",
      "INFO:__main__:Parsing task 575b1a71...\n",
      "INFO:__main__:Parsing task 5783df64...\n",
      "INFO:__main__:Parsing task 5833af48...\n",
      "INFO:__main__:Parsing task 58743b76...\n",
      "INFO:__main__:Parsing task 58e15b12...\n",
      "INFO:__main__:Parsing task 59341089...\n",
      "INFO:__main__:Parsing task 5a5a2103...\n",
      "INFO:__main__:Parsing task 5af49b42...\n",
      "INFO:__main__:Parsing task 5b526a93...\n",
      "INFO:__main__:Parsing task 5b692c0f...\n",
      "INFO:__main__:Parsing task 5b6cbef5...\n",
      "INFO:__main__:Parsing task 5d2a5c43...\n",
      "INFO:__main__:Parsing task 5ffb2104...\n",
      "INFO:__main__:Parsing task 604001fa...\n",
      "INFO:__main__:Parsing task 60a26a3e...\n",
      "INFO:__main__:Parsing task 60c09cac...\n",
      "INFO:__main__:Parsing task 626c0bcc...\n",
      "INFO:__main__:Parsing task 62ab2642...\n",
      "INFO:__main__:Parsing task 62b74c02...\n",
      "INFO:__main__:Parsing task 639f5a19...\n",
      "INFO:__main__:Parsing task 642248e4...\n",
      "INFO:__main__:Parsing task 642d658d...\n",
      "INFO:__main__:Parsing task 64a7c07e...\n",
      "INFO:__main__:Parsing task 66e6c45b...\n",
      "INFO:__main__:Parsing task 66f2d22f...\n",
      "INFO:__main__:Parsing task 67636eac...\n",
      "INFO:__main__:Parsing task 67b4a34d...\n",
      "INFO:__main__:Parsing task 67c52801...\n",
      "INFO:__main__:Parsing task 68b67ca3...\n",
      "INFO:__main__:Parsing task 692cd3b6...\n",
      "INFO:__main__:Parsing task 695367ec...\n",
      "INFO:__main__:Parsing task 696d4842...\n",
      "INFO:__main__:Parsing task 69889d6e...\n",
      "INFO:__main__:Parsing task 6a11f6da...\n",
      "INFO:__main__:Parsing task 6ad5bdfd...\n",
      "INFO:__main__:Parsing task 6df30ad6...\n",
      "INFO:__main__:Parsing task 6ea4a07e...\n",
      "INFO:__main__:Parsing task 6f473927...\n",
      "INFO:__main__:Parsing task 7039b2d7...\n",
      "INFO:__main__:Parsing task 705a3229...\n",
      "INFO:__main__:Parsing task 712bf12e...\n",
      "INFO:__main__:Parsing task 72207abc...\n",
      "INFO:__main__:Parsing task 72a961c9...\n",
      "INFO:__main__:Parsing task 73182012...\n",
      "INFO:__main__:Parsing task 73c3b0d8...\n",
      "INFO:__main__:Parsing task 73ccf9c2...\n",
      "INFO:__main__:Parsing task 759f3fd3...\n",
      "INFO:__main__:Parsing task 762cd429...\n",
      "INFO:__main__:Parsing task 770cc55f...\n",
      "INFO:__main__:Parsing task 782b5218...\n",
      "INFO:__main__:Parsing task 79369cc6...\n",
      "INFO:__main__:Parsing task 7953d61e...\n",
      "INFO:__main__:Parsing task 79fb03f4...\n",
      "INFO:__main__:Parsing task 7bb29440...\n",
      "INFO:__main__:Parsing task 7c8af763...\n",
      "INFO:__main__:Parsing task 7c9b52a0...\n",
      "INFO:__main__:Parsing task 7d18a6fb...\n",
      "INFO:__main__:Parsing task 7d1f7ee8...\n",
      "INFO:__main__:Parsing task 7d419a02...\n",
      "INFO:__main__:Parsing task 7e02026e...\n",
      "INFO:__main__:Parsing task 7ee1c6ea...\n",
      "INFO:__main__:Parsing task 817e6c09...\n",
      "INFO:__main__:Parsing task 81c0276b...\n",
      "INFO:__main__:Parsing task 833dafe3...\n",
      "INFO:__main__:Parsing task 845d6e51...\n",
      "INFO:__main__:Parsing task 84db8fc4...\n",
      "INFO:__main__:Parsing task 84f2aca1...\n",
      "INFO:__main__:Parsing task 8597cfd7...\n",
      "INFO:__main__:Parsing task 85b81ff1...\n",
      "INFO:__main__:Parsing task 85fa5666...\n",
      "INFO:__main__:Parsing task 8719f442...\n",
      "INFO:__main__:Parsing task 88207623...\n",
      "INFO:__main__:Parsing task 891232d6...\n",
      "INFO:__main__:Parsing task 896d5239...\n",
      "INFO:__main__:Parsing task 8a371977...\n",
      "INFO:__main__:Parsing task 8b28cd80...\n",
      "INFO:__main__:Parsing task 8ba14f53...\n",
      "INFO:__main__:Parsing task 8cb8642d...\n",
      "INFO:__main__:Parsing task 8dae5dfc...\n",
      "INFO:__main__:Parsing task 8e2edd66...\n",
      "INFO:__main__:Parsing task 8ee62060...\n",
      "INFO:__main__:Parsing task 8fbca751...\n",
      "INFO:__main__:Parsing task 90347967...\n",
      "INFO:__main__:Parsing task 903d1b4a...\n",
      "INFO:__main__:Parsing task 9110e3c5...\n",
      "INFO:__main__:Parsing task 917bccba...\n",
      "INFO:__main__:Parsing task 929ab4e9...\n",
      "INFO:__main__:Parsing task 92e50de0...\n",
      "INFO:__main__:Parsing task 9356391f...\n",
      "INFO:__main__:Parsing task 93b4f4b3...\n",
      "INFO:__main__:Parsing task 93c31fbe...\n",
      "INFO:__main__:Parsing task 94133066...\n",
      "INFO:__main__:Parsing task 94414823...\n",
      "INFO:__main__:Parsing task 94be5b80...\n",
      "INFO:__main__:Parsing task 95a58926...\n",
      "INFO:__main__:Parsing task 963f59bc...\n",
      "INFO:__main__:Parsing task 96a8c0cd...\n",
      "INFO:__main__:Parsing task 97239e3d...\n",
      "INFO:__main__:Parsing task 9772c176...\n",
      "INFO:__main__:Parsing task 981571dc...\n",
      "INFO:__main__:Parsing task 992798f6...\n",
      "INFO:__main__:Parsing task 99306f82...\n",
      "INFO:__main__:Parsing task 9a4bb226...\n",
      "INFO:__main__:Parsing task 9b2a60aa...\n",
      "INFO:__main__:Parsing task 9b365c51...\n",
      "INFO:__main__:Parsing task 9b4c17c4...\n",
      "INFO:__main__:Parsing task 9bebae7a...\n",
      "INFO:__main__:Parsing task 9c1e755f...\n",
      "INFO:__main__:Parsing task 9c56f360...\n",
      "INFO:__main__:Parsing task 9caba7c3...\n",
      "INFO:__main__:Parsing task 9ddd00f0...\n",
      "INFO:__main__:Parsing task 9def23fe...\n",
      "INFO:__main__:Parsing task 9f27f097...\n",
      "INFO:__main__:Parsing task a04b2602...\n",
      "INFO:__main__:Parsing task a096bf4d...\n",
      "INFO:__main__:Parsing task a3f84088...\n",
      "INFO:__main__:Parsing task a406ac07...\n",
      "INFO:__main__:Parsing task a57f2f04...\n",
      "INFO:__main__:Parsing task a59b95c0...\n",
      "INFO:__main__:Parsing task a680ac02...\n",
      "INFO:__main__:Parsing task a8610ef7...\n",
      "INFO:__main__:Parsing task a934301b...\n",
      "INFO:__main__:Parsing task aa18de87...\n",
      "INFO:__main__:Parsing task aa300dc3...\n",
      "INFO:__main__:Parsing task aa4ec2a5...\n",
      "INFO:__main__:Parsing task aab50785...\n",
      "INFO:__main__:Parsing task ac0c5833...\n",
      "INFO:__main__:Parsing task ac2e8ecf...\n",
      "INFO:__main__:Parsing task ac3e2b04...\n",
      "INFO:__main__:Parsing task ac605cbb...\n",
      "INFO:__main__:Parsing task ad7e01d0...\n",
      "INFO:__main__:Parsing task ae58858e...\n",
      "INFO:__main__:Parsing task aee291af...\n",
      "INFO:__main__:Parsing task af22c60d...\n",
      "INFO:__main__:Parsing task af24b4cc...\n",
      "INFO:__main__:Parsing task b0722778...\n",
      "INFO:__main__:Parsing task b0f4d537...\n",
      "INFO:__main__:Parsing task b15fca0b...\n",
      "INFO:__main__:Parsing task b1fc8b8e...\n",
      "INFO:__main__:Parsing task b20f7c8b...\n",
      "INFO:__main__:Parsing task b457fec5...\n",
      "INFO:__main__:Parsing task b4a43f3b...\n",
      "INFO:__main__:Parsing task b7999b51...\n",
      "INFO:__main__:Parsing task b7cb93ac...\n",
      "INFO:__main__:Parsing task b7f8a4d8...\n",
      "INFO:__main__:Parsing task b7fb29bc...\n",
      "INFO:__main__:Parsing task b942fd60...\n",
      "INFO:__main__:Parsing task b9630600...\n",
      "INFO:__main__:Parsing task ba9d41b8...\n",
      "INFO:__main__:Parsing task baf41dbf...\n",
      "INFO:__main__:Parsing task bb52a14b...\n",
      "INFO:__main__:Parsing task bbb1b8b6...\n",
      "INFO:__main__:Parsing task bc4146bd...\n",
      "INFO:__main__:Parsing task bcb3040b...\n",
      "INFO:__main__:Parsing task bd14c3bf...\n",
      "INFO:__main__:Parsing task be03b35f...\n",
      "INFO:__main__:Parsing task bf32578f...\n",
      "INFO:__main__:Parsing task bf699163...\n",
      "INFO:__main__:Parsing task bf89d739...\n",
      "INFO:__main__:Parsing task c074846d...\n",
      "INFO:__main__:Parsing task c1990cce...\n",
      "INFO:__main__:Parsing task c3202e5a...\n",
      "INFO:__main__:Parsing task c35c1b4c...\n",
      "INFO:__main__:Parsing task c48954c1...\n",
      "INFO:__main__:Parsing task c62e2108...\n",
      "INFO:__main__:Parsing task c64f1187...\n",
      "INFO:__main__:Parsing task c658a4bd...\n",
      "INFO:__main__:Parsing task c663677b...\n",
      "INFO:__main__:Parsing task c6e1b8da...\n",
      "INFO:__main__:Parsing task c7d4e6ad...\n",
      "INFO:__main__:Parsing task c87289bb...\n",
      "INFO:__main__:Parsing task c8b7cc0f...\n",
      "INFO:__main__:Parsing task c92b942c...\n",
      "INFO:__main__:Parsing task c97c0139...\n",
      "INFO:__main__:Parsing task ca8de6ea...\n",
      "INFO:__main__:Parsing task ca8f78db...\n",
      "INFO:__main__:Parsing task cad67732...\n",
      "INFO:__main__:Parsing task cb227835...\n",
      "INFO:__main__:Parsing task ccd554ac...\n",
      "INFO:__main__:Parsing task cd3c21df...\n",
      "INFO:__main__:Parsing task ce039d91...\n",
      "INFO:__main__:Parsing task ce8d95cc...\n",
      "INFO:__main__:Parsing task cf133acc...\n",
      "INFO:__main__:Parsing task cfb2ce5a...\n",
      "INFO:__main__:Parsing task d017b73f...\n",
      "INFO:__main__:Parsing task d19f7514...\n",
      "INFO:__main__:Parsing task d282b262...\n",
      "INFO:__main__:Parsing task d2acf2cb...\n",
      "INFO:__main__:Parsing task d304284e...\n",
      "INFO:__main__:Parsing task d37a1ef5...\n",
      "INFO:__main__:Parsing task d47aa2ff...\n",
      "INFO:__main__:Parsing task d492a647...\n",
      "INFO:__main__:Parsing task d4b1c2b1...\n",
      "INFO:__main__:Parsing task d4c90558...\n",
      "INFO:__main__:Parsing task d56f2372...\n",
      "INFO:__main__:Parsing task d5c634a2...\n",
      "INFO:__main__:Parsing task d931c21c...\n",
      "INFO:__main__:Parsing task d94c3b52...\n",
      "INFO:__main__:Parsing task da2b0fe3...\n",
      "INFO:__main__:Parsing task da515329...\n",
      "INFO:__main__:Parsing task dc2aa30b...\n",
      "INFO:__main__:Parsing task dc2e9a9d...\n",
      "INFO:__main__:Parsing task dd2401ed...\n",
      "INFO:__main__:Parsing task de493100...\n",
      "INFO:__main__:Parsing task df8cc377...\n",
      "INFO:__main__:Parsing task e0fb7511...\n",
      "INFO:__main__:Parsing task e133d23d...\n",
      "INFO:__main__:Parsing task e1baa8a4...\n",
      "INFO:__main__:Parsing task e1d2900e...\n",
      "INFO:__main__:Parsing task e2092e0c...\n",
      "INFO:__main__:Parsing task e21a174a...\n",
      "INFO:__main__:Parsing task e345f17b...\n",
      "INFO:__main__:Parsing task e4075551...\n",
      "INFO:__main__:Parsing task e41c6fd3...\n",
      "INFO:__main__:Parsing task e57337a4...\n",
      "INFO:__main__:Parsing task e5790162...\n",
      "INFO:__main__:Parsing task e5c44e8f...\n",
      "INFO:__main__:Parsing task e619ca6e...\n",
      "INFO:__main__:Parsing task e633a9e5...\n",
      "INFO:__main__:Parsing task e66aafb8...\n",
      "INFO:__main__:Parsing task e681b708...\n",
      "INFO:__main__:Parsing task e69241bd...\n",
      "INFO:__main__:Parsing task e6de6e8f...\n",
      "INFO:__main__:Parsing task e74e1818...\n",
      "INFO:__main__:Parsing task e760a62e...\n",
      "INFO:__main__:Parsing task e7639916...\n",
      "INFO:__main__:Parsing task e78887d1...\n",
      "INFO:__main__:Parsing task e7a25a18...\n",
      "INFO:__main__:Parsing task e7b06bea...\n",
      "INFO:__main__:Parsing task e7dd8335...\n",
      "INFO:__main__:Parsing task e872b94a...\n",
      "INFO:__main__:Parsing task e88171ec...\n",
      "INFO:__main__:Parsing task e95e3d8e...\n",
      "INFO:__main__:Parsing task e99362f0...\n",
      "INFO:__main__:Parsing task e9ac8c9e...\n",
      "INFO:__main__:Parsing task e9b4f6fc...\n",
      "INFO:__main__:Parsing task e9bb6954...\n",
      "INFO:__main__:Parsing task e9c9d9a1...\n",
      "INFO:__main__:Parsing task ea959feb...\n",
      "INFO:__main__:Parsing task ea9794b1...\n",
      "INFO:__main__:Parsing task ecaa0ec1...\n",
      "INFO:__main__:Parsing task ed74f2f2...\n",
      "INFO:__main__:Parsing task ed98d772...\n",
      "INFO:__main__:Parsing task ef26cbf6...\n",
      "INFO:__main__:Parsing task f0afb749...\n",
      "INFO:__main__:Parsing task f0df5ff0...\n",
      "INFO:__main__:Parsing task f21745ec...\n",
      "INFO:__main__:Parsing task f3b10344...\n",
      "INFO:__main__:Parsing task f3cdc58f...\n",
      "INFO:__main__:Parsing task f3e62deb...\n",
      "INFO:__main__:Parsing task f4081712...\n",
      "INFO:__main__:Parsing task f45f5ca7...\n",
      "INFO:__main__:Parsing task f5aa3634...\n",
      "INFO:__main__:Parsing task f5c89df1...\n",
      "INFO:__main__:Parsing task f823c43c...\n",
      "INFO:__main__:Parsing task f83cb3f6...\n",
      "INFO:__main__:Parsing task f8be4b64...\n",
      "INFO:__main__:Parsing task f9a67cb5...\n",
      "INFO:__main__:Parsing task f9d67f8b...\n",
      "INFO:__main__:Parsing task fafd9572...\n",
      "INFO:__main__:Parsing task fb791726...\n",
      "INFO:__main__:Parsing task fc754716...\n",
      "INFO:__main__:Parsing task fd096ab6...\n",
      "INFO:__main__:Parsing task fd4b2b02...\n",
      "INFO:__main__:Parsing task fe9372f3...\n",
      "INFO:__main__:Parsing task fea12743...\n",
      "INFO:__main__:Parsing task ff72ca3e...\n",
      "INFO:__main__:Total valid grid pairs extracted: 1363\n",
      "INFO:__main__:Number of training grid pairs: 1302\n",
      "INFO:__main__:Number of evaluation grid pairs: 1363\n",
      "INFO:__main__:Training DataLoader size: 66 batches\n",
      "INFO:__main__:Validation DataLoader size: 17 batches\n",
      "INFO:__main__:Number of training samples: 4166\n",
      "INFO:__main__:Number of validation samples: 1042\n",
      "INFO:__main__:Number of evaluation samples: 1363\n",
      "INFO:__main__:Model initialized successfully.\n",
      "INFO:__main__:Single batch forward and backward pass successful.\n",
      "INFO:__main__:Training thread started.\n",
      "INFO:__main__:Starting the training process.\n",
      "INFO:__main__:Starting epoch 1/10.\n",
      "INFO:__main__:Epoch [1/10], Batch [10/66], Loss: 1.2296\n",
      "INFO:__main__:Epoch [1/10], Batch [20/66], Loss: 0.6141\n",
      "INFO:__main__:Epoch [1/10], Batch [30/66], Loss: 0.6431\n",
      "INFO:__main__:Epoch [1/10], Batch [40/66], Loss: 0.4997\n",
      "INFO:__main__:Epoch [1/10], Batch [50/66], Loss: 0.5748\n",
      "INFO:__main__:Epoch [1/10], Batch [60/66], Loss: 0.4933\n",
      "INFO:__main__:Epoch [1/10] completed. Training Loss: 0.7782, Training Accuracy: 0.8744\n",
      "INFO:__main__:Validation Loss: 0.5407, Validation Accuracy: 0.8763\n",
      "ERROR:__main__:Error updating GUI: 'TrainingGUI' object has no attribute 'acc_data'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Owner\\AppData\\Local\\Temp\\ipykernel_48548\\267747584.py\", line 589, in update_gui\n",
      "    self.acc_data.append(data['epoch_acc'])\n",
      "    ^^^^^^^^^^^^^\n",
      "AttributeError: 'TrainingGUI' object has no attribute 'acc_data'\n",
      "INFO:__main__:Epoch 1/10 - Validation loss decreased. Saving model.\n",
      "INFO:__main__:Starting epoch 2/10.\n",
      "INFO:__main__:Epoch [2/10], Batch [10/66], Loss: 0.5506\n",
      "INFO:__main__:Epoch [2/10], Batch [20/66], Loss: 0.4810\n",
      "INFO:__main__:Epoch [2/10], Batch [30/66], Loss: 0.5175\n",
      "INFO:__main__:Model saved to C:/Users/Owner/Downloads/Trainedmodel.pth\n",
      "INFO:__main__:Epoch [2/10], Batch [40/66], Loss: 0.5579\n",
      "INFO:__main__:Epoch [2/10], Batch [50/66], Loss: 0.4586\n",
      "INFO:__main__:Epoch [2/10], Batch [60/66], Loss: 0.4652\n",
      "INFO:__main__:Epoch [2/10] completed. Training Loss: 0.5214, Training Accuracy: 0.8842\n",
      "INFO:__main__:Validation Loss: 0.5277, Validation Accuracy: 0.8763\n",
      "ERROR:__main__:Error updating GUI: 'TrainingGUI' object has no attribute 'acc_data'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Owner\\AppData\\Local\\Temp\\ipykernel_48548\\267747584.py\", line 589, in update_gui\n",
      "    self.acc_data.append(data['epoch_acc'])\n",
      "    ^^^^^^^^^^^^^\n",
      "AttributeError: 'TrainingGUI' object has no attribute 'acc_data'\n",
      "INFO:__main__:Epoch 2/10 - Validation loss decreased. Saving model.\n",
      "INFO:__main__:Starting epoch 3/10.\n",
      "INFO:__main__:Epoch [3/10], Batch [10/66], Loss: 0.5060\n",
      "INFO:__main__:Epoch [3/10], Batch [20/66], Loss: 0.5811\n",
      "INFO:__main__:Epoch [3/10], Batch [30/66], Loss: 0.5643\n",
      "INFO:__main__:Epoch [3/10], Batch [40/66], Loss: 0.5022\n",
      "INFO:__main__:Epoch [3/10], Batch [50/66], Loss: 0.5592\n",
      "INFO:__main__:Epoch [3/10], Batch [60/66], Loss: 0.5306\n",
      "INFO:__main__:Epoch [3/10] completed. Training Loss: 0.5092, Training Accuracy: 0.8842\n",
      "INFO:__main__:Validation Loss: 0.5236, Validation Accuracy: 0.8763\n",
      "ERROR:__main__:Error updating GUI: 'TrainingGUI' object has no attribute 'acc_data'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Owner\\AppData\\Local\\Temp\\ipykernel_48548\\267747584.py\", line 589, in update_gui\n",
      "    self.acc_data.append(data['epoch_acc'])\n",
      "    ^^^^^^^^^^^^^\n",
      "AttributeError: 'TrainingGUI' object has no attribute 'acc_data'\n",
      "INFO:__main__:Epoch 3/10 - Validation loss decreased. Saving model.\n",
      "INFO:__main__:Starting epoch 4/10.\n",
      "INFO:__main__:Epoch [4/10], Batch [10/66], Loss: 0.5274\n",
      "INFO:__main__:Epoch [4/10], Batch [20/66], Loss: 0.4325\n",
      "INFO:__main__:Epoch [4/10], Batch [30/66], Loss: 0.5736\n",
      "INFO:__main__:Epoch [4/10], Batch [40/66], Loss: 0.4351\n",
      "INFO:__main__:Epoch [4/10], Batch [50/66], Loss: 0.5341\n",
      "INFO:__main__:Epoch [4/10], Batch [60/66], Loss: 0.3977\n",
      "INFO:__main__:Epoch [4/10] completed. Training Loss: 0.4994, Training Accuracy: 0.8842\n",
      "INFO:__main__:Validation Loss: 0.5171, Validation Accuracy: 0.8763\n",
      "ERROR:__main__:Error updating GUI: 'TrainingGUI' object has no attribute 'acc_data'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Owner\\AppData\\Local\\Temp\\ipykernel_48548\\267747584.py\", line 589, in update_gui\n",
      "    self.acc_data.append(data['epoch_acc'])\n",
      "    ^^^^^^^^^^^^^\n",
      "AttributeError: 'TrainingGUI' object has no attribute 'acc_data'\n",
      "INFO:__main__:Epoch 4/10 - Validation loss decreased. Saving model.\n",
      "INFO:__main__:Starting epoch 5/10.\n",
      "INFO:__main__:Epoch [5/10], Batch [10/66], Loss: 0.5358\n",
      "INFO:__main__:Epoch [5/10], Batch [20/66], Loss: 0.4204\n",
      "INFO:__main__:Epoch [5/10], Batch [30/66], Loss: 0.4027\n",
      "INFO:__main__:Epoch [5/10], Batch [40/66], Loss: 0.4504\n",
      "INFO:__main__:Epoch [5/10], Batch [50/66], Loss: 0.5350\n",
      "INFO:__main__:Epoch [5/10], Batch [60/66], Loss: 0.4876\n",
      "INFO:__main__:Epoch [5/10] completed. Training Loss: 0.4955, Training Accuracy: 0.8842\n",
      "INFO:__main__:Validation Loss: 0.5129, Validation Accuracy: 0.8763\n",
      "INFO:__main__:Epoch 5/10 - Validation loss decreased. Saving model.\n",
      "ERROR:__main__:Error updating GUI: 'TrainingGUI' object has no attribute 'acc_data'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Owner\\AppData\\Local\\Temp\\ipykernel_48548\\267747584.py\", line 589, in update_gui\n",
      "    self.acc_data.append(data['epoch_acc'])\n",
      "    ^^^^^^^^^^^^^\n",
      "AttributeError: 'TrainingGUI' object has no attribute 'acc_data'\n",
      "INFO:__main__:Starting epoch 6/10.\n",
      "INFO:__main__:Epoch [6/10], Batch [10/66], Loss: 0.4693\n",
      "INFO:__main__:Epoch [6/10], Batch [20/66], Loss: 0.5238\n",
      "INFO:__main__:Epoch [6/10], Batch [30/66], Loss: 0.4446\n",
      "INFO:__main__:Epoch [6/10], Batch [40/66], Loss: 0.4473\n",
      "INFO:__main__:Epoch [6/10], Batch [50/66], Loss: 0.4395\n",
      "INFO:__main__:Epoch [6/10], Batch [60/66], Loss: 0.4095\n",
      "INFO:__main__:Epoch [6/10] completed. Training Loss: 0.4897, Training Accuracy: 0.8843\n",
      "INFO:__main__:Validation Loss: 0.5108, Validation Accuracy: 0.8764\n",
      "ERROR:__main__:Error updating GUI: 'TrainingGUI' object has no attribute 'acc_data'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Owner\\AppData\\Local\\Temp\\ipykernel_48548\\267747584.py\", line 589, in update_gui\n",
      "    self.acc_data.append(data['epoch_acc'])\n",
      "    ^^^^^^^^^^^^^\n",
      "AttributeError: 'TrainingGUI' object has no attribute 'acc_data'\n",
      "INFO:__main__:Epoch 6/10 - Validation loss decreased. Saving model.\n",
      "INFO:__main__:Starting epoch 7/10.\n",
      "INFO:__main__:Epoch [7/10], Batch [10/66], Loss: 0.4356\n",
      "INFO:__main__:Epoch [7/10], Batch [20/66], Loss: 0.4961\n",
      "INFO:__main__:Epoch [7/10], Batch [30/66], Loss: 0.4268\n",
      "INFO:__main__:Epoch [7/10], Batch [40/66], Loss: 0.5685\n",
      "INFO:__main__:Epoch [7/10], Batch [50/66], Loss: 0.5082\n",
      "INFO:__main__:Epoch [7/10], Batch [60/66], Loss: 0.4394\n",
      "INFO:__main__:Epoch [7/10] completed. Training Loss: 0.4837, Training Accuracy: 0.8854\n",
      "INFO:__main__:Validation Loss: 0.5127, Validation Accuracy: 0.8763\n",
      "INFO:__main__:Epoch 7/10 - No improvement in validation loss for 1 epochs.\n",
      "INFO:__main__:Starting epoch 8/10.\n",
      "ERROR:__main__:Error updating GUI: 'TrainingGUI' object has no attribute 'acc_data'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Owner\\AppData\\Local\\Temp\\ipykernel_48548\\267747584.py\", line 589, in update_gui\n",
      "    self.acc_data.append(data['epoch_acc'])\n",
      "    ^^^^^^^^^^^^^\n",
      "AttributeError: 'TrainingGUI' object has no attribute 'acc_data'\n",
      "INFO:__main__:Epoch [8/10], Batch [10/66], Loss: 0.4783\n",
      "INFO:__main__:Epoch [8/10], Batch [20/66], Loss: 0.5026\n",
      "INFO:__main__:Epoch [8/10], Batch [30/66], Loss: 0.4614\n",
      "INFO:__main__:Epoch [8/10], Batch [40/66], Loss: 0.4298\n",
      "INFO:__main__:Epoch [8/10], Batch [50/66], Loss: 0.5364\n",
      "INFO:__main__:Epoch [8/10], Batch [60/66], Loss: 0.4490\n",
      "INFO:__main__:Epoch [8/10] completed. Training Loss: 0.4832, Training Accuracy: 0.8857\n",
      "INFO:__main__:Validation Loss: 0.5105, Validation Accuracy: 0.8771\n",
      "INFO:__main__:Epoch 8/10 - Validation loss decreased. Saving model.\n",
      "INFO:__main__:Starting epoch 9/10.\n",
      "ERROR:__main__:Error updating GUI: 'TrainingGUI' object has no attribute 'acc_data'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Owner\\AppData\\Local\\Temp\\ipykernel_48548\\267747584.py\", line 589, in update_gui\n",
      "    self.acc_data.append(data['epoch_acc'])\n",
      "    ^^^^^^^^^^^^^\n",
      "AttributeError: 'TrainingGUI' object has no attribute 'acc_data'\n",
      "INFO:__main__:Epoch [9/10], Batch [10/66], Loss: 0.5644\n",
      "INFO:__main__:Epoch [9/10], Batch [20/66], Loss: 0.4724\n",
      "INFO:__main__:Epoch [9/10], Batch [30/66], Loss: 0.4478\n",
      "INFO:__main__:Epoch [9/10], Batch [40/66], Loss: 0.4661\n",
      "INFO:__main__:Epoch [9/10], Batch [50/66], Loss: 0.4556\n",
      "INFO:__main__:Epoch [9/10], Batch [60/66], Loss: 0.5419\n",
      "INFO:__main__:Epoch [9/10] completed. Training Loss: 0.4810, Training Accuracy: 0.8861\n",
      "INFO:__main__:Validation Loss: 0.5137, Validation Accuracy: 0.8740\n",
      "INFO:__main__:Epoch 9/10 - No improvement in validation loss for 1 epochs.\n",
      "INFO:__main__:Starting epoch 10/10.\n",
      "ERROR:__main__:Error updating GUI: 'TrainingGUI' object has no attribute 'acc_data'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Owner\\AppData\\Local\\Temp\\ipykernel_48548\\267747584.py\", line 589, in update_gui\n",
      "    self.acc_data.append(data['epoch_acc'])\n",
      "    ^^^^^^^^^^^^^\n",
      "AttributeError: 'TrainingGUI' object has no attribute 'acc_data'\n",
      "INFO:__main__:Epoch [10/10], Batch [10/66], Loss: 0.4761\n",
      "INFO:__main__:Epoch [10/10], Batch [20/66], Loss: 0.4660\n",
      "INFO:__main__:Epoch [10/10], Batch [30/66], Loss: 0.4409\n",
      "INFO:__main__:Epoch [10/10], Batch [40/66], Loss: 0.4875\n",
      "INFO:__main__:Epoch [10/10], Batch [50/66], Loss: 0.5223\n",
      "INFO:__main__:Epoch [10/10], Batch [60/66], Loss: 0.4282\n",
      "INFO:__main__:Epoch [10/10] completed. Training Loss: 0.4767, Training Accuracy: 0.8857\n",
      "INFO:__main__:Validation Loss: 0.5096, Validation Accuracy: 0.8762\n",
      "INFO:__main__:Epoch 10/10 - Validation loss decreased. Saving model.\n",
      "ERROR:__main__:Error updating GUI: 'TrainingGUI' object has no attribute 'acc_data'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Owner\\AppData\\Local\\Temp\\ipykernel_48548\\267747584.py\", line 589, in update_gui\n",
      "    self.acc_data.append(data['epoch_acc'])\n",
      "    ^^^^^^^^^^^^^\n",
      "AttributeError: 'TrainingGUI' object has no attribute 'acc_data'\n",
      "INFO:__main__:Training completed.\n",
      "INFO:__main__:Training completed successfully.\n",
      "INFO:__main__:Model saved to C:/Users/Owner/Downloads/Trainedmodel.pth\n"
     ]
    }
   ],
   "source": [
    "# ===============================================================\n",
    "# Optimized Implementation\n",
    "# ===============================================================\n",
    "\n",
    "# -----------------------------\n",
    "# 1. Import Libraries\n",
    "# -----------------------------\n",
    "import math\n",
    "import json\n",
    "import logging\n",
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "import threading\n",
    "import queue\n",
    "import sys\n",
    "import matplotlib\n",
    "matplotlib.use('TkAgg')  # Ensure the correct backend is used\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import tkinter as tk\n",
    "from tkinter import ttk, filedialog, messagebox\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from dataclasses import dataclass\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "# Set default font to reduce font scanning time\n",
    "matplotlib.rcParams['font.family'] = 'DejaVu Sans'\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Configure Logging and Seed\n",
    "# -----------------------------\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, stream=sys.stdout)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_seed()\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Define Constants\n",
    "# -----------------------------\n",
    "\n",
    "GRID_SIZE = 30        # Fixed grid size (adjust as needed)\n",
    "NUM_CLASSES = 11      # 0-10, where 10 represents dead squares\n",
    "\n",
    "# -----------------------------\n",
    "# 4. Define Data Structures and Loading Functions\n",
    "# -----------------------------\n",
    "\n",
    "# Data Class for Grid Pairs\n",
    "@dataclass\n",
    "class GridPair:\n",
    "    task_id: str\n",
    "    input_grid: list\n",
    "    output_grid: list\n",
    "\n",
    "# Load ARC Data\n",
    "def load_arc_data():\n",
    "    file_paths = {\n",
    "        \"arc-agi_training-challenges\": \"arc-agi_training_challenges.json\",\n",
    "        \"arc-agi_evaluation-challenges\": \"arc-agi_evaluation_challenges.json\",\n",
    "        \"arc-agi_training-solutions\": \"arc-agi_training_solutions.json\",\n",
    "        \"arc-agi_evaluation-solutions\": \"arc-agi_evaluation_solutions.json\",\n",
    "    }\n",
    "    arc_data = {}\n",
    "    for key, path in file_paths.items():\n",
    "        try:\n",
    "            with open(path, 'r') as f:\n",
    "                arc_data[key] = json.load(f)\n",
    "                logger.info(f\"Loaded {key} from {path}.\")\n",
    "        except (FileNotFoundError, json.JSONDecodeError) as e:\n",
    "            logger.error(f\"Error loading {path}: {e}\")\n",
    "            arc_data[key] = {}\n",
    "    return arc_data\n",
    "\n",
    "# Reshape to Fixed Square Grid\n",
    "def reshape_to_square_grid(flat_list, grid_size=GRID_SIZE):\n",
    "    required_length = grid_size * grid_size\n",
    "    current_length = len(flat_list)\n",
    "\n",
    "    if current_length > required_length:\n",
    "        # Truncate if the grid is larger than grid_size x grid_size\n",
    "        flat_list = flat_list[:required_length]\n",
    "    else:\n",
    "        # Pad with -1 to reach the required length\n",
    "        flat_list = np.pad(flat_list, (0, required_length - current_length), 'constant', constant_values=-1)\n",
    "\n",
    "    return flat_list.reshape(grid_size, grid_size).tolist()\n",
    "\n",
    "# Extract and Reshape Grid\n",
    "def extract_and_reshape_grid(grid, grid_size=GRID_SIZE):\n",
    "    try:\n",
    "        # Flatten the grid if it's a list of lists\n",
    "        if isinstance(grid[0], list):\n",
    "            flat_list = [item for sublist in grid for item in sublist]\n",
    "        else:\n",
    "            flat_list = grid\n",
    "        return reshape_to_square_grid(flat_list, grid_size)\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error processing grid: {e}\")\n",
    "        return None\n",
    "\n",
    "# Flatten and Reshape Grid Data\n",
    "def flatten_and_reshape(task_data, grid_size=GRID_SIZE):\n",
    "    flattened_pairs = []\n",
    "    for task_id, task_content in task_data.items():\n",
    "        logger.info(f\"Parsing task {task_id}...\")\n",
    "        train_pairs = task_content.get('train', [])\n",
    "        for pair in train_pairs:\n",
    "            input_grid = extract_and_reshape_grid(pair.get(\"input\"), grid_size)\n",
    "            output_grid = extract_and_reshape_grid(pair.get(\"output\"), grid_size)\n",
    "            if input_grid and output_grid:\n",
    "                flattened_pairs.append(GridPair(task_id, input_grid, output_grid))\n",
    "            else:\n",
    "                logger.warning(f\"Task ID: {task_id} has invalid input/output grids.\")\n",
    "    logger.info(f\"Total valid grid pairs extracted: {len(flattened_pairs)}\")\n",
    "    return flattened_pairs\n",
    "\n",
    "# -----------------------------\n",
    "# 5. Data Augmentation Functions\n",
    "# -----------------------------\n",
    "\n",
    "def augment_grid(grid, noise_prob=0.2, dead_square_prob=0.1):\n",
    "    \"\"\"Applies augmentation to the grid by adding noise and dead squares.\"\"\"\n",
    "    augmented_grid = np.array(grid)\n",
    "\n",
    "    # Generate random masks for noise and dead squares\n",
    "    noise_mask = np.random.rand(*augmented_grid.shape) < noise_prob\n",
    "    dead_square_mask = np.random.rand(*augmented_grid.shape) < dead_square_prob\n",
    "\n",
    "    # Generate random noise values where noise_mask is True\n",
    "    noise_values = np.random.randint(0, NUM_CLASSES - 2, size=augmented_grid.shape)\n",
    "    augmented_grid = np.where(noise_mask, noise_values, augmented_grid)\n",
    "    augmented_grid = np.where(dead_square_mask, -1, augmented_grid)\n",
    "\n",
    "    return augmented_grid.tolist()\n",
    "\n",
    "def rotate_grid(grid):\n",
    "    \"\"\"Randomly rotates the grid.\"\"\"\n",
    "    rotations = random.choice([0, 1, 2, 3])\n",
    "    return np.rot90(grid, rotations).tolist()\n",
    "\n",
    "def flip_grid(grid):\n",
    "    \"\"\"Randomly flips the grid.\"\"\"\n",
    "    flip_choice = random.choice(['none', 'vertical', 'horizontal'])\n",
    "    if flip_choice == 'vertical':\n",
    "        return np.flipud(grid).tolist()  # Vertical flip\n",
    "    elif flip_choice == 'horizontal':\n",
    "        return np.fliplr(grid).tolist()  # Horizontal flip\n",
    "    else:\n",
    "        return grid  # No flip\n",
    "\n",
    "# Generate Multiple Augmented Datasets\n",
    "def generate_multiple_augmented_datasets(grid_pairs, num_augmented_sets=3):\n",
    "    augmented_pairs = []\n",
    "    for _ in range(num_augmented_sets):\n",
    "        for pair in grid_pairs:\n",
    "            augmented_input = augment_grid(pair.input_grid)\n",
    "            augmented_input = rotate_grid(augmented_input)\n",
    "            augmented_input = flip_grid(augmented_input)\n",
    "            augmented_pairs.append(GridPair(pair.task_id, augmented_input, pair.output_grid))\n",
    "    return augmented_pairs\n",
    "\n",
    "# -----------------------------\n",
    "# 6. Custom Collate Function (Removed if Not Necessary)\n",
    "# -----------------------------\n",
    "\n",
    "# Since all tensors are of the same size, the default collate function suffices.\n",
    "# We can remove the custom collate_fn unless specific processing is required.\n",
    "\n",
    "# -----------------------------\n",
    "# 7. PyTorch Dataset Class\n",
    "# -----------------------------\n",
    "\n",
    "class AugmentedARCDataset(Dataset):\n",
    "    def __init__(self, grid_pairs, augment=False):\n",
    "        self.grid_pairs = grid_pairs\n",
    "        self.augment = augment\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.grid_pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        pair = self.grid_pairs[idx]\n",
    "        input_grid = pair.input_grid\n",
    "        output_grid = pair.output_grid\n",
    "\n",
    "        if self.augment:\n",
    "            input_grid = augment_grid(input_grid)\n",
    "            input_grid = rotate_grid(input_grid)\n",
    "            input_grid = flip_grid(input_grid)\n",
    "\n",
    "        # Convert to tensors\n",
    "        input_tensor = torch.tensor(input_grid, dtype=torch.float32).unsqueeze(0)  # Shape: (1, GRID_SIZE, GRID_SIZE)\n",
    "\n",
    "        # Map -1 to NUM_CLASSES -1 (10)\n",
    "        output_grid = np.array(output_grid)\n",
    "        output_grid_mapped = np.where(output_grid == -1, NUM_CLASSES - 1, output_grid)\n",
    "        output_tensor = torch.tensor(output_grid_mapped, dtype=torch.long)  # Shape: (GRID_SIZE, GRID_SIZE)\n",
    "\n",
    "        return input_tensor, output_tensor\n",
    "\n",
    "# -----------------------------\n",
    "# 8. Define the Deep Neural Network Model\n",
    "# -----------------------------\n",
    "\n",
    "class CNNGridMapper(nn.Module):\n",
    "    def __init__(self, num_classes=NUM_CLASSES, grid_size=GRID_SIZE):\n",
    "        super(CNNGridMapper, self).__init__()\n",
    "        self.grid_size = grid_size\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        # CNN Backbone: ResNet18 pretrained on ImageNet\n",
    "        self.cnn = resnet18(weights=ResNet18_Weights.DEFAULT)\n",
    "        # Modify the first convolutional layer to accept single-channel input\n",
    "        self.cnn.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        # Initialize the new conv1 weights\n",
    "        nn.init.kaiming_normal_(self.cnn.conv1.weight, mode='fan_out', nonlinearity='relu')\n",
    "        # Remove the fully connected layer and average pool\n",
    "        self.cnn_layers = nn.Sequential(*list(self.cnn.children())[:-2])  # Output: (batch_size, 512, H, W)\n",
    "\n",
    "        # Replace in-place ReLU activations with out-of-place versions\n",
    "        def replace_relu(module):\n",
    "            for child_name, child in module.named_children():\n",
    "                if isinstance(child, nn.ReLU):\n",
    "                    setattr(module, child_name, nn.ReLU(inplace=False))\n",
    "                else:\n",
    "                    replace_relu(child)\n",
    "        replace_relu(self.cnn_layers)\n",
    "\n",
    "        # Interpolation to match GRID_SIZE\n",
    "        self.interpolate = nn.Upsample(size=(grid_size, grid_size), mode='bilinear', align_corners=False)\n",
    "\n",
    "        # RNN Module: LSTM\n",
    "        # Treat each row as a sequence of cells\n",
    "        self.rnn = nn.LSTM(input_size=512,  # Number of features per cell from CNN\n",
    "                           hidden_size=128,\n",
    "                           num_layers=2,\n",
    "                           batch_first=True,\n",
    "                           bidirectional=True)\n",
    "\n",
    "        # Fully Connected Layer\n",
    "        self.fc = nn.Linear(128 * 2, num_classes)  # *2 for bidirectional\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "\n",
    "        # Pass through CNN\n",
    "        features = self.cnn_layers(x)  # Shape: (batch_size, 512, H, W)\n",
    "\n",
    "        # Interpolate to (batch_size, 512, GRID_SIZE, GRID_SIZE)\n",
    "        features = self.interpolate(features)  # Shape: (batch_size, 512, GRID_SIZE, GRID_SIZE)\n",
    "\n",
    "        # Reshape for RNN\n",
    "        features = features.permute(0, 2, 3, 1)  # Shape: (batch_size, GRID_SIZE, GRID_SIZE, 512)\n",
    "        features = features.contiguous().view(batch_size * self.grid_size, self.grid_size, 512)\n",
    "\n",
    "        # Pass through RNN\n",
    "        rnn_out, _ = self.rnn(features)  # Shape: (batch_size * GRID_SIZE, GRID_SIZE, hidden_size * 2)\n",
    "\n",
    "        # Pass through Fully Connected layer\n",
    "        logits = self.fc(rnn_out)  # Shape: (batch_size * GRID_SIZE, GRID_SIZE, num_classes)\n",
    "\n",
    "        # Reshape logits back to (batch_size, GRID_SIZE * GRID_SIZE, num_classes)\n",
    "        logits = logits.view(batch_size, self.grid_size * self.grid_size, self.num_classes)\n",
    "\n",
    "        return logits  # (batch_size, GRID_SIZE * GRID_SIZE, num_classes)\n",
    "\n",
    "# -----------------------------\n",
    "# 9. Define a Simple Transformer-based LLM\n",
    "# -----------------------------\n",
    "\n",
    "class SimpleTransformer(nn.Module):\n",
    "    def __init__(self, vocab_size=5000, d_model=512, nhead=8, num_layers=6, dim_feedforward=2048):\n",
    "        super(SimpleTransformer, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "        self.pos_encoder = PositionalEncoding(d_model)\n",
    "        encoder_layers = nn.TransformerEncoderLayer(d_model, nhead, dim_feedforward)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, num_layers)\n",
    "        self.decoder = nn.Linear(d_model, vocab_size)\n",
    "\n",
    "    def forward(self, src):\n",
    "        src = self.embedding(src) * math.sqrt(src.size(-1))\n",
    "        src = self.pos_encoder(src)\n",
    "        output = self.transformer_encoder(src)\n",
    "        output = self.decoder(output)\n",
    "        return output\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)  # (max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float32).unsqueeze(1)  # (max_len, 1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2, dtype=torch.float32) * (-math.log(10000.0) / d_model))  # (d_model/2)\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)  # Apply sin to even indices\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)  # Apply cos to odd indices\n",
    "        pe = pe.unsqueeze(0)  # (1, max_len, d_model)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:, :x.size(1), :].to(x.device)\n",
    "        return self.dropout(x)\n",
    "\n",
    "# -----------------------------\n",
    "# 10. GUI Class\n",
    "# -----------------------------\n",
    "\n",
    "class TrainingGUI:\n",
    "    \"\"\"\n",
    "    A Tkinter-based GUI that displays real-time training progress, including epoch, batch, loss, and accuracy.\n",
    "    Provides buttons to load, save, evaluate, retrain, select, stop, and ensemble models.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, root, total_epochs, total_batches, model, train_loader, val_loader, eval_loader, device):\n",
    "        self.root = root\n",
    "        self.root.title(\"Model Training and Evaluation\")\n",
    "        self.queue = queue.Queue()\n",
    "\n",
    "        # Model and DataLoaders\n",
    "        self.model = model\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.eval_loader = eval_loader\n",
    "        self.device = device\n",
    "\n",
    "        # Training Parameters\n",
    "        self.total_epochs = total_epochs\n",
    "        self.total_batches = total_batches\n",
    "        self.training_thread = None\n",
    "        self.stop_event = threading.Event()\n",
    "\n",
    "        # Initialize GUI\n",
    "        self.setup_gui()\n",
    "\n",
    "        # Start processing the queue\n",
    "        self.root.after(100, self.process_queue)\n",
    "\n",
    "    def setup_gui(self):\n",
    "        \"\"\"Set up the GUI components.\"\"\"\n",
    "        self.frame = tk.Frame(self.root)\n",
    "        self.frame.pack(fill=tk.BOTH, expand=1)\n",
    "\n",
    "        # Labels\n",
    "        self.epoch_label = tk.Label(self.frame, text=f\"Epoch: 0/{self.total_epochs}\", font=(\"Helvetica\", 14))\n",
    "        self.epoch_label.pack(pady=5)\n",
    "\n",
    "        self.batch_label = tk.Label(self.frame, text=f\"Batch: 0/{self.total_batches}\", font=(\"Helvetica\", 12))\n",
    "        self.batch_label.pack(pady=2)\n",
    "\n",
    "        self.loss_label = tk.Label(self.frame, text=\"Loss: 0.0000\", font=(\"Helvetica\", 12))\n",
    "        self.loss_label.pack(pady=2)\n",
    "\n",
    "        self.accuracy_label = tk.Label(self.frame, text=\"Accuracy: 0.0000\", font=(\"Helvetica\", 12))\n",
    "        self.accuracy_label.pack(pady=2)\n",
    "\n",
    "        self.val_loss_label = tk.Label(self.frame, text=\"Validation Loss: 0.0000\", font=(\"Helvetica\", 12))\n",
    "        self.val_loss_label.pack(pady=2)\n",
    "\n",
    "        self.val_accuracy_label = tk.Label(self.frame, text=\"Validation Accuracy: 0.0000\", font=(\"Helvetica\", 12))\n",
    "        self.val_accuracy_label.pack(pady=2)\n",
    "\n",
    "        # Progress Bar\n",
    "        self.progress_bar = ttk.Progressbar(self.frame, orient=\"horizontal\", length=400, mode=\"determinate\")\n",
    "        self.progress_bar.pack(pady=10)\n",
    "\n",
    "        # Button Frame\n",
    "        self.button_frame = tk.Frame(self.frame)\n",
    "        self.button_frame.pack(pady=10)\n",
    "\n",
    "        # Buttons\n",
    "        self.load_button = tk.Button(self.button_frame, text=\"Load Model\", command=self.load_model)\n",
    "        self.load_button.grid(row=0, column=0, padx=5)\n",
    "\n",
    "        self.save_button = tk.Button(self.button_frame, text=\"Save Model\", command=self.save_model)\n",
    "        self.save_button.grid(row=0, column=1, padx=5)\n",
    "\n",
    "        self.evaluate_button = tk.Button(self.button_frame, text=\"Evaluate Model\", command=self.evaluate_model_button)\n",
    "        self.evaluate_button.grid(row=0, column=2, padx=5)\n",
    "\n",
    "        self.start_button = tk.Button(self.button_frame, text=\"Start Training\", command=self.start_training)\n",
    "        self.start_button.grid(row=0, column=3, padx=5)\n",
    "\n",
    "        self.stop_button = tk.Button(self.button_frame, text=\"Stop Training\", command=self.stop_training, state=tk.DISABLED)\n",
    "        self.stop_button.grid(row=0, column=4, padx=5)\n",
    "\n",
    "        self.ensemble_button = tk.Button(self.button_frame, text=\"Ensemble Models\", command=self.ensemble_models)\n",
    "        self.ensemble_button.grid(row=0, column=5, padx=5)\n",
    "\n",
    "        # Real-time Plot Setup\n",
    "        self.fig, self.ax = plt.subplots(figsize=(6, 4))\n",
    "        self.line_loss, = self.ax.plot([], [], label='Training Loss', color='blue')\n",
    "        self.line_val_loss, = self.ax.plot([], [], label='Validation Loss', color='orange')\n",
    "        self.ax.set_xlabel('Epochs')\n",
    "        self.ax.set_ylabel('Loss')\n",
    "        self.ax.legend()\n",
    "        self.ax.grid(True)\n",
    "        self.canvas_plot = FigureCanvasTkAgg(self.fig, master=self.frame)\n",
    "        self.canvas_plot.draw()\n",
    "        self.canvas_plot.get_tk_widget().pack()\n",
    "\n",
    "        # Data for plots\n",
    "        self.loss_data = []\n",
    "        self.val_loss_data = []\n",
    "\n",
    "    def load_model(self):\n",
    "        \"\"\"Load a model from a file.\"\"\"\n",
    "        model_path = filedialog.askopenfilename(title=\"Select Model File\", filetypes=[(\"PyTorch Models\", \"*.pth\")])\n",
    "        if model_path:\n",
    "            try:\n",
    "                state_dict = torch.load(model_path, map_location=self.device)\n",
    "                self.model.load_state_dict(state_dict)\n",
    "                self.model.to(self.device)\n",
    "                logger.info(f\"Model loaded from {model_path}\")\n",
    "                messagebox.showinfo(\"Load Model\", f\"Model loaded from {model_path}\")\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error loading model: {e}\")\n",
    "                messagebox.showerror(\"Error\", f\"Could not load model: {e}\")\n",
    "\n",
    "    def save_model(self):\n",
    "        \"\"\"Save the current model to a file.\"\"\"\n",
    "        model_path = filedialog.asksaveasfilename(title=\"Save Model As\", defaultextension=\".pth\",\n",
    "                                                  filetypes=[(\"PyTorch Models\", \"*.pth\")])\n",
    "        if model_path:\n",
    "            try:\n",
    "                torch.save(self.model.state_dict(), model_path)\n",
    "                logger.info(f\"Model saved to {model_path}\")\n",
    "                messagebox.showinfo(\"Save Model\", f\"Model saved to {model_path}\")\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error saving model: {e}\")\n",
    "                messagebox.showerror(\"Error\", f\"Could not save model: {e}\")\n",
    "\n",
    "    def start_training(self):\n",
    "        \"\"\"Start the training process in a new thread.\"\"\"\n",
    "        self.stop_event.clear()\n",
    "        self.start_button.config(state=tk.DISABLED)\n",
    "        self.stop_button.config(state=tk.NORMAL)\n",
    "        self.training_thread = threading.Thread(target=self.train_model, daemon=True)\n",
    "        self.training_thread.start()\n",
    "\n",
    "    def stop_training(self):\n",
    "        \"\"\"Stop the training process.\"\"\"\n",
    "        self.stop_event.set()\n",
    "        self.start_button.config(state=tk.NORMAL)\n",
    "        self.stop_button.config(state=tk.DISABLED)\n",
    "\n",
    "    def train_model(self):\n",
    "        \"\"\"Training logic executed in a separate thread.\"\"\"\n",
    "        try:\n",
    "            for epoch in range(1, self.total_epochs + 1):\n",
    "                if self.stop_event.is_set():\n",
    "                    break\n",
    "\n",
    "                running_loss = 0.0\n",
    "                for batch_idx, (inputs, targets) in enumerate(self.train_loader, 1):\n",
    "                    inputs, targets = inputs.to(self.device), targets.to(self.device)\n",
    "                    self.model.train()\n",
    "\n",
    "                    outputs = self.model(inputs)\n",
    "                    loss = torch.nn.functional.cross_entropy(outputs, targets)\n",
    "                    loss.backward()\n",
    "\n",
    "                    optimizer.step()\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    running_loss += loss.item()\n",
    "                    progress = (epoch - 1 + batch_idx / len(self.train_loader)) / self.total_epochs * 100\n",
    "\n",
    "                    # Send progress updates to the queue\n",
    "                    self.queue.put({\n",
    "                        'epoch': epoch,\n",
    "                        'batch': batch_idx,\n",
    "                        'loss': running_loss / batch_idx,\n",
    "                        'progress': progress\n",
    "                    })\n",
    "\n",
    "            self.queue.put('training_complete')\n",
    "\n",
    "        except Exception as e:\n",
    "            self.queue.put({'error': str(e)})\n",
    "\n",
    "    def process_queue(self):\n",
    "        \"\"\"Process the queue for thread-safe GUI updates.\"\"\"\n",
    "        while not self.queue.empty():\n",
    "            message = self.queue.get()\n",
    "            if isinstance(message, dict):\n",
    "                if 'error' in message:\n",
    "                    messagebox.showerror(\"Error\", message['error'])\n",
    "                else:\n",
    "                    self.update_gui(message)\n",
    "            elif message == 'training_complete':\n",
    "                messagebox.showinfo(\"Training\", \"Training completed successfully.\")\n",
    "                self.start_button.config(state=tk.NORMAL)\n",
    "                self.stop_button.config(state=tk.DISABLED)\n",
    "\n",
    "        self.root.after(100, self.process_queue)\n",
    "        \n",
    "    def retrain_model(self):\n",
    "        \"\"\"Start the model training in a separate thread.\"\"\"\n",
    "        try:\n",
    "            # Start the training thread as a daemon to avoid blocking the GUI\n",
    "            threading.Thread(target=self.train_thread, daemon=True).start()\n",
    "        except Exception as e:\n",
    "            logger.exception(\"An error occurred while starting the training thread.\")\n",
    "            messagebox.showerror(\"Training Error\", f\"An error occurred: {e}\")\n",
    "\n",
    "    def process_queue(self):\n",
    "        \"\"\"Process the queue to handle updates and messages from the training thread.\"\"\"\n",
    "        while not self.queue.empty():\n",
    "            message = self.queue.get()\n",
    "            if message == 'training_complete':\n",
    "                messagebox.showinfo(\"Training\", \"Training completed successfully.\")\n",
    "        self.root.after(100, self.process_queue)\n",
    "\n",
    "    def evaluate_model_button(self):\n",
    "        \"\"\"Evaluate the model in a separate thread.\"\"\"\n",
    "        threading.Thread(target=self.evaluate_model, daemon=True).start()\n",
    "\n",
    "    def evaluate_model(self):\n",
    "        \"\"\"Evaluate the model and show results.\"\"\"\n",
    "        avg_loss, accuracy = evaluate_model(self.model, self.val_loader, device=self.device)\n",
    "        messagebox.showinfo(\"Evaluation\", f\"Loss: {avg_loss:.4f}, Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "    def ensemble_models(self):\n",
    "        \"\"\"Ensemble multiple models.\"\"\"\n",
    "        # Implementation for ensembling models (omitted for brevity)\n",
    "\n",
    "    def process_queue(self):\n",
    "        \"\"\"Process the queue for thread-safe GUI updates.\"\"\"\n",
    "        while not self.queue.empty():\n",
    "            message = self.queue.get()\n",
    "            if isinstance(message, dict):\n",
    "                if 'error' in message:\n",
    "                    messagebox.showerror(\"Error\", message['error'])\n",
    "                else:\n",
    "                    self.update_gui(message)\n",
    "            elif message == 'training_complete':\n",
    "                messagebox.showinfo(\"Training\", \"Training completed successfully.\")\n",
    "                self.start_button.config(state=tk.NORMAL)\n",
    "                self.stop_button.config(state=tk.DISABLED)\n",
    "\n",
    "        self.root.after(100, self.process_queue)\n",
    "\n",
    "    def update_gui(self, data):\n",
    "        \"\"\"\n",
    "        Updates the GUI elements with new training information.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if 'batch' in data:\n",
    "                # Update batch-level information (for progress during each epoch)\n",
    "                self.batch_label.config(text=f\"Batch: {data['batch']}/{self.total_batches}\")\n",
    "                self.loss_label.config(text=f\"Loss: {data['loss']:.4f}\")\n",
    "                self.accuracy_label.config(text=f\"Accuracy: {data.get('accuracy', 0.0):.4f}\")\n",
    "                \n",
    "                # Ensure the GUI stays responsive during intensive updates\n",
    "                self.root.update_idletasks()\n",
    "    \n",
    "            elif 'epoch' in data:\n",
    "                # Update epoch-level information (after each epoch completion)\n",
    "                self.epoch_label.config(text=f\"Epoch: {data['epoch']}/{self.total_epochs}\")\n",
    "                self.val_loss_label.config(text=f\"Validation Loss: {data.get('val_loss', 0.0):.4f}\")\n",
    "                self.val_accuracy_label.config(text=f\"Validation Accuracy: {data.get('val_accuracy', 0.0):.4f}\")\n",
    "    \n",
    "                # Update the progress bar based on completed epochs\n",
    "                progress = (data['epoch'] / self.total_epochs) * 100\n",
    "                self.progress_bar[\"value\"] = progress\n",
    "                \n",
    "                # Ensure smooth GUI interaction\n",
    "                self.root.update_idletasks()\n",
    "    \n",
    "                # Update the real-time loss and accuracy plots\n",
    "                self.loss_data.append(data['epoch_loss'])\n",
    "                self.val_loss_data.append(data['val_loss'])\n",
    "                self.acc_data.append(data['epoch_acc'])\n",
    "                self.val_acc_data.append(data['val_accuracy'])\n",
    "    \n",
    "                # Update the plots with the new data points\n",
    "                self.line_loss.set_data(range(1, len(self.loss_data) + 1), self.loss_data)\n",
    "                self.line_val_loss.set_data(range(1, len(self.val_loss_data) + 1), self.val_loss_data)\n",
    "                self.line_acc.set_data(range(1, len(self.acc_data) + 1), self.acc_data)\n",
    "                self.line_val_acc.set_data(range(1, len(self.val_acc_data) + 1), self.val_acc_data)\n",
    "    \n",
    "                # Rescale the axes to fit the new data\n",
    "                self.ax.relim()\n",
    "                self.ax.autoscale_view()\n",
    "                self.canvas_plot.draw()\n",
    "    \n",
    "        except Exception as e:\n",
    "            # Handle any unexpected errors gracefully\n",
    "            logger.exception(f\"Error updating GUI: {e}\")\n",
    "            messagebox.showerror(\"GUI Update Error\", f\"An error occurred while updating the GUI: {e}\")\n",
    "\n",
    "\n",
    "    # Training thread\n",
    "    def train_thread(self):\n",
    "        logger.info(\"Training thread started.\")\n",
    "        try:\n",
    "            train_deep_model(self.model, self.train_loader, self.val_loader, epochs=self.total_epochs, lr=0.01,\n",
    "                             device=self.device, gui=self, patience=5)\n",
    "            logger.info(\"Training completed successfully.\")\n",
    "            self.queue.put('training_complete')\n",
    "        except Exception as e:\n",
    "            logger.exception(\"An error occurred in the training thread.\")\n",
    "            messagebox.showerror(\"Training Error\", f\"An error occurred during training: {e}\")\n",
    "\n",
    "    def train_thread(self):\n",
    "        \"\"\"Training logic executed in a separate thread to avoid blocking the GUI.\"\"\"\n",
    "        logger.info(\"Training thread started.\")\n",
    "        try:\n",
    "            train_deep_model(\n",
    "                self.model, self.train_loader, self.val_loader,\n",
    "                epochs=self.total_epochs, lr=0.01, device=self.device,\n",
    "                gui=self, patience=5\n",
    "            )\n",
    "            logger.info(\"Training completed successfully.\")\n",
    "            self.queue.put('training_complete')\n",
    "    \n",
    "        except Exception as e:\n",
    "            logger.exception(\"An error occurred during the training process.\")\n",
    "            self.queue.put({'error': str(e)})\n",
    "        finally:\n",
    "            # Ensure the stop button is disabled and start button is enabled when the thread ends\n",
    "            self.stop_button.config(state=tk.DISABLED)\n",
    "            self.start_button.config(state=tk.NORMAL)\n",
    "\n",
    "\n",
    "    # Visualize predictions\n",
    "    def visualize_predictions(self, model, loader, device='cpu', num_samples=5):\n",
    "        \"\"\"\n",
    "        Visualizes predictions in the GUI.\n",
    "        \"\"\"\n",
    "        model.to(device)\n",
    "        model.eval()\n",
    "\n",
    "        samples_visualized = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in loader:\n",
    "                inputs = inputs.to(device)\n",
    "                targets = targets.to(device)\n",
    "\n",
    "                outputs = model(inputs)  # Shape: (batch_size, grid_size * grid_size, num_classes)\n",
    "                # Reshape outputs to (batch_size, GRID_SIZE, GRID_SIZE, NUM_CLASSES)\n",
    "                outputs = outputs.view(-1, GRID_SIZE, GRID_SIZE, NUM_CLASSES)\n",
    "                # Get predicted classes\n",
    "                _, predicted = torch.max(outputs, dim=3)  # Shape: (batch_size, GRID_SIZE, GRID_SIZE)\n",
    "\n",
    "                for i in range(inputs.size(0)):\n",
    "                    input_grid = inputs[i].cpu().numpy().squeeze()  # Shape: (GRID_SIZE, GRID_SIZE)\n",
    "                    predicted_grid = predicted[i].cpu().numpy()      # Shape: (GRID_SIZE, GRID_SIZE)\n",
    "                    actual_grid = targets[i].cpu().numpy()           # Shape: (GRID_SIZE, GRID_SIZE)\n",
    "\n",
    "                    # Map the dead square label back to -1 for display purposes\n",
    "                    predicted_grid_display = np.where(predicted_grid == NUM_CLASSES - 1, -1, predicted_grid)\n",
    "                    actual_grid_display = np.where(actual_grid == NUM_CLASSES - 1, -1, actual_grid)\n",
    "\n",
    "                    # Define a custom colormap to handle -1 values\n",
    "                    cmap = matplotlib.cm.get_cmap('viridis', NUM_CLASSES)\n",
    "                    cmap.set_bad(color='black')  # Set color for masked values (dead squares)\n",
    "\n",
    "                    # Mask the dead squares\n",
    "                    input_masked = np.ma.masked_where(input_grid == -1, input_grid)\n",
    "                    predicted_masked = np.ma.masked_where(predicted_grid_display == -1, predicted_grid_display)\n",
    "                    actual_masked = np.ma.masked_where(actual_grid_display == -1, actual_grid_display)\n",
    "\n",
    "                    fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "                    # Input Grid\n",
    "                    im_input = axs[0].imshow(input_masked, cmap=cmap, interpolation='nearest', vmin=0, vmax=NUM_CLASSES - 2)\n",
    "                    axs[0].set_title(\"Input Grid\")\n",
    "                    axs[0].axis('off')\n",
    "\n",
    "                    # Predicted Grid\n",
    "                    im_pred = axs[1].imshow(predicted_masked, cmap=cmap, interpolation='nearest', vmin=0, vmax=NUM_CLASSES - 2)\n",
    "                    axs[1].set_title(\"Predicted Grid\")\n",
    "                    axs[1].axis('off')\n",
    "\n",
    "                    # Actual Grid\n",
    "                    im_actual = axs[2].imshow(actual_masked, cmap=cmap, interpolation='nearest', vmin=0, vmax=NUM_CLASSES - 2)\n",
    "                    axs[2].set_title(\"Actual Grid\")\n",
    "                    axs[2].axis('off')\n",
    "\n",
    "                    # Adjust layout to fill the space\n",
    "                    plt.subplots_adjust(wspace=0.05, hspace=0)\n",
    "                    plt.tight_layout()\n",
    "                    # Display the plot in a new window\n",
    "                    self.show_plot_in_new_window(fig)\n",
    "                    plt.close(fig)  # Close the figure to free memory\n",
    "\n",
    "                    samples_visualized += 1\n",
    "                    if samples_visualized >= num_samples:\n",
    "                        return\n",
    "\n",
    "    def show_plot_in_new_window(self, fig):\n",
    "        \"\"\"\n",
    "        Displays the Matplotlib figure in a new Tkinter window.\n",
    "        \"\"\"\n",
    "        new_window = tk.Toplevel(self.root)\n",
    "        canvas = FigureCanvasTkAgg(fig, master=new_window)\n",
    "        canvas.draw()\n",
    "        canvas.get_tk_widget().pack()\n",
    "        toolbar = ttk.Frame(new_window)\n",
    "        toolbar.pack()\n",
    "        canvas._tkcanvas.pack()\n",
    "\n",
    "# -----------------------------\n",
    "# 11. Training Function with GUI Integration\n",
    "# -----------------------------\n",
    "\n",
    "def train_deep_model(model, train_loader, val_loader, epochs, lr, device, gui, patience=5):\n",
    "    logger.info(\"Starting the training process.\")\n",
    "    torch.autograd.set_detect_anomaly(False)  # Disable anomaly detection for better performance\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9, nesterov=True, weight_decay=1e-4)\n",
    "    scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "    model.to(device)\n",
    "\n",
    "    # Use GradScaler and autocast only if CUDA is available\n",
    "    use_amp = torch.cuda.is_available()\n",
    "    if use_amp:\n",
    "        scaler = GradScaler()\n",
    "    else:\n",
    "        scaler = None\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    epochs_no_improve = 0\n",
    "\n",
    "    total_batches = len(train_loader)\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        logger.info(f\"Starting epoch {epoch}/{epochs}.\")\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for batch_idx, (inputs, targets) in enumerate(train_loader, 1):\n",
    "            inputs = inputs.to(device, non_blocking=True)\n",
    "            targets = targets.to(device, non_blocking=True)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            if use_amp:\n",
    "                with autocast():\n",
    "                    outputs = model(inputs)\n",
    "                    targets_flat = targets.view(-1)\n",
    "                    outputs_flat = outputs.view(-1, NUM_CLASSES)\n",
    "                    loss = criterion(outputs_flat, targets_flat)\n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "            else:\n",
    "                outputs = model(inputs)\n",
    "                targets_flat = targets.view(-1)\n",
    "                outputs_flat = outputs.view(-1, NUM_CLASSES)\n",
    "                loss = criterion(outputs_flat, targets_flat)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs_flat.detach(), 1)\n",
    "            correct += (predicted == targets_flat).sum().item()\n",
    "            total += targets_flat.size(0)\n",
    "\n",
    "            # Update GUI per batch\n",
    "            batch_loss = running_loss / batch_idx\n",
    "            batch_acc = correct / total\n",
    "            gui.queue.put({\n",
    "                'batch': batch_idx,\n",
    "                'total_batches': total_batches,\n",
    "                'loss': batch_loss,\n",
    "                'accuracy': batch_acc\n",
    "            })\n",
    "\n",
    "            if batch_idx % 10 == 0:\n",
    "                logger.info(f\"Epoch [{epoch}/{epochs}], Batch [{batch_idx}/{total_batches}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "        epoch_loss = running_loss / total_batches\n",
    "        epoch_acc = correct / total\n",
    "        logger.info(f\"Epoch [{epoch}/{epochs}] completed. Training Loss: {epoch_loss:.4f}, Training Accuracy: {epoch_acc:.4f}\")\n",
    "\n",
    "        # Validation Phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in val_loader:\n",
    "                inputs = inputs.to(device, non_blocking=True)\n",
    "                targets = targets.to(device, non_blocking=True)\n",
    "\n",
    "                if use_amp:\n",
    "                    with autocast():\n",
    "                        outputs = model(inputs)\n",
    "                        targets_flat = targets.view(-1)\n",
    "                        outputs_flat = outputs.view(-1, NUM_CLASSES)\n",
    "                        loss = criterion(outputs_flat, targets_flat)\n",
    "                else:\n",
    "                    outputs = model(inputs)\n",
    "                    targets_flat = targets.view(-1)\n",
    "                    outputs_flat = outputs.view(-1, NUM_CLASSES)\n",
    "                    loss = criterion(outputs_flat, targets_flat)\n",
    "\n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "                _, predicted = torch.max(outputs_flat, 1)\n",
    "                val_correct += (predicted == targets_flat).sum().item()\n",
    "                val_total += targets_flat.size(0)\n",
    "\n",
    "        avg_val_loss = val_loss / len(val_loader.dataset)\n",
    "        val_acc = val_correct / val_total\n",
    "        logger.info(f\"Validation Loss: {avg_val_loss:.4f}, Validation Accuracy: {val_acc:.4f}\")\n",
    "\n",
    "        # Update GUI per epoch\n",
    "        gui.queue.put({\n",
    "            'epoch': epoch,\n",
    "            'total_epochs': epochs,\n",
    "            'epoch_loss': epoch_loss,\n",
    "            'epoch_acc': epoch_acc,\n",
    "            'val_loss': avg_val_loss,\n",
    "            'val_accuracy': val_acc\n",
    "        })\n",
    "\n",
    "        # Check for improvement\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            epochs_no_improve = 0\n",
    "            # Save the best model\n",
    "            torch.save(model.state_dict(), \"best_deep_model.pth\")\n",
    "            logger.info(f\"Epoch {epoch}/{epochs} - Validation loss decreased. Saving model.\")\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            logger.info(f\"Epoch {epoch}/{epochs} - No improvement in validation loss for {epochs_no_improve} epochs.\")\n",
    "\n",
    "        # Step the scheduler\n",
    "        scheduler.step()\n",
    "\n",
    "        # Early Stopping\n",
    "        if epochs_no_improve >= patience:\n",
    "            logger.info(\"Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "    logger.info(\"Training completed.\")\n",
    "\n",
    "# -----------------------------\n",
    "# 12. Evaluation and Prediction Functions\n",
    "# -----------------------------\n",
    "\n",
    "def evaluate_model(model, test_loader, device='cpu'):\n",
    "    \"\"\"\n",
    "    Evaluates the model on the test dataset.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): Trained model.\n",
    "        test_loader (DataLoader): DataLoader for the test dataset.\n",
    "        device (str): Device to run evaluation on.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (average_loss, accuracy)\n",
    "    \"\"\"\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in test_loader:\n",
    "            inputs = inputs.to(device, non_blocking=True)\n",
    "            targets = targets.to(device, non_blocking=True)\n",
    "\n",
    "            outputs = model(inputs)  # Shape: (batch_size, grid_size * grid_size, num_classes)\n",
    "            outputs_flat = outputs.view(-1, NUM_CLASSES)\n",
    "            targets_flat = targets.view(-1)\n",
    "            loss = criterion(outputs_flat, targets_flat)\n",
    "            total_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "            _, predicted = torch.max(outputs_flat, 1)\n",
    "            correct += (predicted == targets_flat).sum().item()\n",
    "            total += targets_flat.size(0)\n",
    "\n",
    "    avg_loss = total_loss / len(test_loader.dataset)\n",
    "    accuracy = correct / total\n",
    "\n",
    "    logger.info(f\"Test Loss: {avg_loss:.4f}, Test Accuracy: {accuracy:.4f}\")\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "def ensemble_predictions(base_model, model_paths, test_loader, device='cpu', num_samples=5):\n",
    "    \"\"\"\n",
    "    Performs ensemble predictions using multiple models.\n",
    "    \"\"\"\n",
    "    models = []\n",
    "    for path in model_paths:\n",
    "        model = CNNGridMapper(num_classes=NUM_CLASSES, grid_size=GRID_SIZE)\n",
    "        model.load_state_dict(torch.load(path, map_location=device))\n",
    "        model.to(device)\n",
    "        model.eval()\n",
    "        models.append(model)\n",
    "        logger.info(f\"Loaded model from {path}\")\n",
    "\n",
    "    samples_visualized = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in test_loader:\n",
    "            inputs = inputs.to(device, non_blocking=True)\n",
    "            targets = targets.to(device, non_blocking=True)\n",
    "\n",
    "            # Collect predictions from all models\n",
    "            outputs_list = []\n",
    "            for model in models:\n",
    "                outputs = model(inputs)\n",
    "                outputs_list.append(outputs.unsqueeze(0))  # Add a new dimension for stacking\n",
    "\n",
    "            # Stack outputs and average\n",
    "            outputs_stack = torch.cat(outputs_list, dim=0)  # Shape: (num_models, batch_size, grid_size * grid_size, num_classes)\n",
    "            outputs_avg = torch.mean(outputs_stack, dim=0)  # Shape: (batch_size, grid_size * grid_size, num_classes)\n",
    "\n",
    "            # Reshape outputs to (batch_size, GRID_SIZE, GRID_SIZE, NUM_CLASSES)\n",
    "            outputs_avg = outputs_avg.view(-1, GRID_SIZE, GRID_SIZE, NUM_CLASSES)\n",
    "            # Get predicted classes\n",
    "            _, predicted = torch.max(outputs_avg, dim=3)  # Shape: (batch_size, GRID_SIZE, GRID_SIZE)\n",
    "\n",
    "            for i in range(inputs.size(0)):\n",
    "                input_grid = inputs[i].cpu().numpy().squeeze()  # Shape: (GRID_SIZE, GRID_SIZE)\n",
    "                predicted_grid = predicted[i].cpu().numpy()      # Shape: (GRID_SIZE, GRID_SIZE)\n",
    "                actual_grid = targets[i].cpu().numpy()           # Shape: (GRID_SIZE, GRID_SIZE)\n",
    "\n",
    "                # Map the dead square label back to -1 for display purposes\n",
    "                predicted_grid_display = np.where(predicted_grid == NUM_CLASSES - 1, -1, predicted_grid)\n",
    "                actual_grid_display = np.where(actual_grid == NUM_CLASSES - 1, -1, actual_grid)\n",
    "\n",
    "                # Define a custom colormap to handle -1 values\n",
    "                cmap = matplotlib.cm.get_cmap('viridis', NUM_CLASSES)\n",
    "                cmap.set_bad(color='black')  # Set color for masked values (dead squares)\n",
    "\n",
    "                # Mask the dead squares\n",
    "                input_masked = np.ma.masked_where(input_grid == -1, input_grid)\n",
    "                predicted_masked = np.ma.masked_where(predicted_grid_display == -1, predicted_grid_display)\n",
    "                actual_masked = np.ma.masked_where(actual_grid_display == -1, actual_grid_display)\n",
    "\n",
    "                fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "                # Input Grid\n",
    "                im_input = axs[0].imshow(input_masked, cmap=cmap, interpolation='nearest', vmin=0, vmax=NUM_CLASSES - 2)\n",
    "                axs[0].set_title(\"Input Grid\")\n",
    "                axs[0].axis('off')\n",
    "\n",
    "                # Predicted Grid\n",
    "                im_pred = axs[1].imshow(predicted_masked, cmap=cmap, interpolation='nearest', vmin=0, vmax=NUM_CLASSES - 2)\n",
    "                axs[1].set_title(\"Ensembled Prediction\")\n",
    "                axs[1].axis('off')\n",
    "\n",
    "                # Actual Grid\n",
    "                im_actual = axs[2].imshow(actual_masked, cmap=cmap, interpolation='nearest', vmin=0, vmax=NUM_CLASSES - 2)\n",
    "                axs[2].set_title(\"Actual Grid\")\n",
    "                axs[2].axis('off')\n",
    "\n",
    "                # Adjust layout to fill the space\n",
    "                plt.subplots_adjust(wspace=0.05, hspace=0)\n",
    "                plt.tight_layout()\n",
    "                # Display the plot\n",
    "                plt.show()\n",
    "                plt.close(fig)  # Close the figure to free memory\n",
    "\n",
    "                samples_visualized += 1\n",
    "                if samples_visualized >= num_samples:\n",
    "                    return\n",
    "\n",
    "# -----------------------------\n",
    "# 13. Main Workflow with Modifications\n",
    "# -----------------------------\n",
    "\n",
    "def main():\n",
    "    # Define device\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    logger.info(f\"Using device: {device}\")\n",
    "\n",
    "    # Load ARC data\n",
    "    arc_data = load_arc_data()\n",
    "\n",
    "    # Extract and reshape training and evaluation grid pairs\n",
    "    train_grid_pairs = flatten_and_reshape(arc_data.get(\"arc-agi_training-challenges\", {}), grid_size=GRID_SIZE)\n",
    "    eval_grid_pairs = flatten_and_reshape(arc_data.get(\"arc-agi_evaluation-challenges\", {}), grid_size=GRID_SIZE)\n",
    "\n",
    "    logger.info(f\"Number of training grid pairs: {len(train_grid_pairs)}\")\n",
    "    logger.info(f\"Number of evaluation grid pairs: {len(eval_grid_pairs)}\")\n",
    "\n",
    "    # Generate multiple augmented datasets\n",
    "    augmented_pairs = generate_multiple_augmented_datasets(train_grid_pairs, num_augmented_sets=3)\n",
    "\n",
    "    # Combine all datasets\n",
    "    combined_train_pairs = train_grid_pairs + augmented_pairs\n",
    "\n",
    "    # Split into training and validation sets (e.g., 80-20 split)\n",
    "    train_pairs, val_pairs = train_test_split(combined_train_pairs, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Create DataLoaders\n",
    "    train_dataset = AugmentedARCDataset(train_pairs, augment=False)  # Already augmented\n",
    "    val_dataset = AugmentedARCDataset(val_pairs, augment=False)\n",
    "    eval_dataset = AugmentedARCDataset(eval_grid_pairs, augment=False)\n",
    "\n",
    "    batch_size = 64  # Adjust batch size as needed\n",
    "    num_workers = os.cpu_count() if os.name != 'nt' else 0  # Use multiprocessing except on Windows\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=True\n",
    "    )\n",
    "\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True\n",
    "    )\n",
    "\n",
    "    eval_loader = DataLoader(\n",
    "        eval_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True\n",
    "    )\n",
    "\n",
    "    logger.info(f\"Training DataLoader size: {len(train_loader)} batches\")\n",
    "    logger.info(f\"Validation DataLoader size: {len(val_loader)} batches\")\n",
    "    logger.info(f\"Number of training samples: {len(train_dataset)}\")\n",
    "    logger.info(f\"Number of validation samples: {len(val_dataset)}\")\n",
    "    logger.info(f\"Number of evaluation samples: {len(eval_dataset)}\")\n",
    "\n",
    "    # Initialize the model\n",
    "    model = CNNGridMapper(num_classes=NUM_CLASSES, grid_size=GRID_SIZE).to(device)\n",
    "    logger.info(\"Model initialized successfully.\")\n",
    "\n",
    "    # Test model forward and backward pass\n",
    "    try:\n",
    "        model.train()\n",
    "        sample_inputs, sample_targets = next(iter(train_loader))\n",
    "        sample_inputs = sample_inputs.to(device)\n",
    "        sample_targets = sample_targets.to(device)\n",
    "\n",
    "        outputs = model(sample_inputs)\n",
    "        targets_flat = sample_targets.view(-1)\n",
    "        outputs_flat = outputs.view(-1, NUM_CLASSES)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        loss = criterion(outputs_flat, targets_flat)\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        logger.info(\"Single batch forward and backward pass successful.\")\n",
    "    except Exception as e:\n",
    "        logger.exception(\"Model forward or backward pass failed.\")\n",
    "        return\n",
    "\n",
    "    # Initialize the GUI\n",
    "    root = tk.Tk()\n",
    "    total_epochs = 10  # Adjust as needed\n",
    "    total_batches = len(train_loader)\n",
    "    gui = TrainingGUI(root, total_epochs, total_batches, model, train_loader, val_loader, eval_loader, device)\n",
    "\n",
    "    # Start the training without blocking the GUI\n",
    "    root.after(100, gui.retrain_model)  # Schedule training to start without blocking\n",
    "\n",
    "    # Start the GUI main loop\n",
    "    root.mainloop()\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 14. Execute the Main Function\n",
    "# -----------------------------\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4bce97f-437d-4d9a-b5ad-bc921292b513",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
