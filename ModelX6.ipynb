{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e312ef-678a-4268-9e98-0252bddaaab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================================================\n",
    "# Comprehensive Implementation with Modifications for Debugging\n",
    "# ===============================================================\n",
    "\n",
    "# -----------------------------\n",
    "# 1. Import Libraries\n",
    "# -----------------------------\n",
    "import math\n",
    "import json\n",
    "import logging\n",
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "import threading\n",
    "import time\n",
    "import subprocess\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from dataclasses import dataclass\n",
    "from torchvision import models\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import matplotlib\n",
    "matplotlib.use('TkAgg')  # Ensure the correct backend is used\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import tkinter as tk\n",
    "from tkinter import ttk\n",
    "import queue\n",
    "from PIL import Image, ImageTk\n",
    "import sys\n",
    "from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg\n",
    "\n",
    "# Set default font to reduce font scanning time\n",
    "matplotlib.rcParams['font.family'] = 'DejaVu Sans'\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Configure Logging and Seed\n",
    "# -----------------------------\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, stream=sys.stdout)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_seed()\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Define Constants\n",
    "# -----------------------------\n",
    "\n",
    "GRID_SIZE = 30        # Fixed grid size (adjust as needed)\n",
    "NUM_CLASSES = 11      # 0-10, where 10 represents dead squares\n",
    "\n",
    "# -----------------------------\n",
    "# 4. Define Data Structures and Loading Functions\n",
    "# -----------------------------\n",
    "\n",
    "# Data Class for Grid Pairs\n",
    "@dataclass\n",
    "class GridPair:\n",
    "    task_id: str\n",
    "    input_grid: list\n",
    "    output_grid: list\n",
    "\n",
    "# Load ARC Data\n",
    "def load_arc_data():\n",
    "    file_paths = {\n",
    "        \"arc-agi_training-challenges\": \"arc-agi_training_challenges.json\",\n",
    "        \"arc-agi_evaluation-challenges\": \"arc-agi_evaluation_challenges.json\",\n",
    "        \"arc-agi_training-solutions\": \"arc-agi_training_solutions.json\",\n",
    "        \"arc-agi_evaluation-solutions\": \"arc-agi_evaluation_solutions.json\",\n",
    "    }\n",
    "    arc_data = {}\n",
    "    for key, path in file_paths.items():\n",
    "        try:\n",
    "            with open(path, 'r') as f:\n",
    "                arc_data[key] = json.load(f)\n",
    "                logger.info(f\"Loaded {key} from {path}.\")\n",
    "        except (FileNotFoundError, json.JSONDecodeError) as e:\n",
    "            logger.error(f\"Error loading {path}: {e}\")\n",
    "            arc_data[key] = {}\n",
    "    return arc_data\n",
    "\n",
    "# Reshape to Fixed Square Grid\n",
    "def reshape_to_square_grid(flat_list, grid_size=30):\n",
    "    required_length = grid_size * grid_size\n",
    "    current_length = len(flat_list)\n",
    "    \n",
    "    if current_length > required_length:\n",
    "        # Truncate if the grid is larger than grid_size x grid_size\n",
    "        flat_list = flat_list[:required_length]\n",
    "    else:\n",
    "        # Pad with -1 to reach the required length\n",
    "        flat_list = np.pad(flat_list, (0, required_length - current_length), 'constant', constant_values=-1)\n",
    "    \n",
    "    return flat_list.reshape(grid_size, grid_size).tolist()\n",
    "\n",
    "# Extract and Reshape Grid\n",
    "def extract_and_reshape_grid(grid, grid_size=30):\n",
    "    try:\n",
    "        # Flatten the grid if it's a list of lists\n",
    "        if isinstance(grid[0], list):\n",
    "            flat_list = [item for sublist in grid for item in sublist]\n",
    "        else:\n",
    "            flat_list = grid\n",
    "        return reshape_to_square_grid(flat_list, grid_size)\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error processing grid: {e}\")\n",
    "        return None\n",
    "\n",
    "# Flatten and Reshape Grid Data\n",
    "def flatten_and_reshape(task_data, grid_size=30):\n",
    "    flattened_pairs = []\n",
    "    for task_id, task_content in task_data.items():\n",
    "        logger.info(f\"Parsing task {task_id}...\")\n",
    "        train_pairs = task_content.get('train', [])\n",
    "        for pair in train_pairs:\n",
    "            input_grid = extract_and_reshape_grid(pair.get(\"input\"), grid_size)\n",
    "            output_grid = extract_and_reshape_grid(pair.get(\"output\"), grid_size)\n",
    "            if input_grid and output_grid:\n",
    "                flattened_pairs.append(GridPair(task_id, input_grid, output_grid))\n",
    "            else:\n",
    "                logger.warning(f\"Task ID: {task_id} has invalid input/output grids.\")\n",
    "    logger.info(f\"Total valid grid pairs extracted: {len(flattened_pairs)}\")\n",
    "    return flattened_pairs\n",
    "\n",
    "# -----------------------------\n",
    "# 5. Data Augmentation Functions\n",
    "# -----------------------------\n",
    "\n",
    "def augment_grid(grid, noise_prob=0.2, dead_square_prob=0.1):\n",
    "    \"\"\"Applies augmentation to the grid by adding noise and dead squares.\"\"\"\n",
    "    augmented_grid = np.array(grid).copy()\n",
    "\n",
    "    for i in range(augmented_grid.shape[0]):\n",
    "        for j in range(augmented_grid.shape[1]):\n",
    "            if random.random() < noise_prob:\n",
    "                augmented_grid[i, j] = random.randint(0, NUM_CLASSES - 2)  # Add noise within 0-9\n",
    "            if random.random() < dead_square_prob:\n",
    "                augmented_grid[i, j] = -1  # Dead square\n",
    "    return augmented_grid.tolist()\n",
    "\n",
    "def rotate_grid(grid):\n",
    "    \"\"\"Randomly rotates the grid.\"\"\"\n",
    "    rotations = random.choice([0, 1, 2, 3])\n",
    "    return np.rot90(grid, rotations).tolist()\n",
    "\n",
    "def flip_grid(grid):\n",
    "    \"\"\"Randomly flips the grid.\"\"\"\n",
    "    flip_choice = random.choice(['none', 'vertical', 'horizontal'])\n",
    "    if flip_choice == 'vertical':\n",
    "        return np.flipud(grid).tolist()  # Vertical flip\n",
    "    elif flip_choice == 'horizontal':\n",
    "        return np.fliplr(grid).tolist()  # Horizontal flip\n",
    "    else:\n",
    "        return grid  # No flip\n",
    "\n",
    "# Generate Multiple Augmented Datasets\n",
    "def generate_multiple_augmented_datasets(grid_pairs, num_augmented_sets=3):\n",
    "    augmented_pairs = []\n",
    "    for _ in range(num_augmented_sets):\n",
    "        for pair in grid_pairs:\n",
    "            augmented_input = augment_grid(pair.input_grid)\n",
    "            augmented_input = rotate_grid(augmented_input)\n",
    "            augmented_input = flip_grid(augmented_input)\n",
    "            augmented_pairs.append(GridPair(pair.task_id, augmented_input, pair.output_grid))\n",
    "    return augmented_pairs\n",
    "\n",
    "# -----------------------------\n",
    "# 6. Custom Collate Function\n",
    "# -----------------------------\n",
    "\n",
    "def collate_fn(batch):\n",
    "    \"\"\"\n",
    "    Stack input and output grids into batch tensors.\n",
    "    All grids are already padded to GRID_SIZE x GRID_SIZE.\n",
    "    \"\"\"\n",
    "    inputs, outputs = zip(*batch)  # Unzip the batch\n",
    "    inputs = torch.stack(inputs)    # Shape: (batch_size, 1, GRID_SIZE, GRID_SIZE)\n",
    "    outputs = torch.stack(outputs)  # Shape: (batch_size, GRID_SIZE, GRID_SIZE)\n",
    "    return inputs, outputs\n",
    "\n",
    "# -----------------------------\n",
    "# 7. PyTorch Dataset Class\n",
    "# -----------------------------\n",
    "\n",
    "class AugmentedARCDataset(Dataset):\n",
    "    def __init__(self, grid_pairs, augment=False):\n",
    "        self.grid_pairs = grid_pairs\n",
    "        self.augment = augment\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.grid_pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        pair = self.grid_pairs[idx]\n",
    "        input_grid = pair.input_grid\n",
    "        output_grid = pair.output_grid\n",
    "\n",
    "        if self.augment:\n",
    "            input_grid = augment_grid(input_grid)\n",
    "            input_grid = rotate_grid(input_grid)\n",
    "            input_grid = flip_grid(input_grid)\n",
    "\n",
    "        # Convert to tensors\n",
    "        input_tensor = torch.tensor(input_grid, dtype=torch.float32).unsqueeze(0)  # Shape: (1, GRID_SIZE, GRID_SIZE)\n",
    "\n",
    "        # Map -1 to NUM_CLASSES -1 (10)\n",
    "        output_grid_mapped = [\n",
    "            [NUM_CLASSES - 1 if cell == -1 else cell for cell in row]\n",
    "            for row in output_grid\n",
    "        ]\n",
    "        output_tensor = torch.tensor(output_grid_mapped, dtype=torch.long)  # Shape: (GRID_SIZE, GRID_SIZE)\n",
    "\n",
    "        return input_tensor, output_tensor\n",
    "\n",
    "# -----------------------------\n",
    "# 8. Define the Deep Neural Network Model\n",
    "# -----------------------------\n",
    "\n",
    "class CNNGridMapper(nn.Module):\n",
    "    def __init__(self, num_classes=NUM_CLASSES, grid_size=GRID_SIZE):\n",
    "        super(CNNGridMapper, self).__init__()\n",
    "        self.grid_size = grid_size\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        # CNN Backbone: ResNet18 pretrained on ImageNet\n",
    "        self.cnn = resnet18(weights=ResNet18_Weights.DEFAULT)\n",
    "        # Modify the first convolutional layer to accept single-channel input\n",
    "        self.cnn.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        # Initialize the new conv1 weights\n",
    "        nn.init.kaiming_normal_(self.cnn.conv1.weight, mode='fan_out', nonlinearity='relu')\n",
    "        # Remove the fully connected layer and average pool\n",
    "        self.cnn_layers = nn.Sequential(*list(self.cnn.children())[:-2])  # Output: (batch_size, 512, H, W)\n",
    "\n",
    "        # Interpolation to match GRID_SIZE\n",
    "        self.interpolate = nn.Upsample(size=(grid_size, grid_size), mode='bilinear', align_corners=False)\n",
    "\n",
    "        # RNN Module: LSTM\n",
    "        # Treat each row as a sequence of cells\n",
    "        self.rnn = nn.LSTM(input_size=512,  # Number of features per cell from CNN\n",
    "                           hidden_size=128,\n",
    "                           num_layers=2,\n",
    "                           batch_first=True,\n",
    "                           bidirectional=True)\n",
    "\n",
    "        # Fully Connected Layers\n",
    "        self.fc = nn.Linear(128 * 2, num_classes)  # *2 for bidirectional\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "\n",
    "        # Pass through CNN\n",
    "        features = self.cnn_layers(x)  # Shape: (batch_size, 512, H, W)\n",
    "\n",
    "        # Interpolate to (512, GRID_SIZE, GRID_SIZE)\n",
    "        features = self.interpolate(features)  # Shape: (batch_size, 512, GRID_SIZE, GRID_SIZE)\n",
    "\n",
    "        # Reshape to (batch_size, GRID_SIZE, GRID_SIZE, 512)\n",
    "        features = features.permute(0, 2, 3, 1)  # Shape: (batch_size, GRID_SIZE, GRID_SIZE, 512)\n",
    "\n",
    "        # Reshape to (batch_size * GRID_SIZE, GRID_SIZE, 512) for RNN\n",
    "        features = features.contiguous().view(batch_size * self.grid_size, self.grid_size, 512)\n",
    "\n",
    "        # Pass through RNN\n",
    "        rnn_out, _ = self.rnn(features)  # Shape: (batch_size * GRID_SIZE, GRID_SIZE, hidden_size * 2)\n",
    "\n",
    "        # Pass through Fully Connected layer\n",
    "        logits = self.fc(rnn_out)  # Shape: (batch_size * GRID_SIZE, GRID_SIZE, num_classes)\n",
    "\n",
    "        # Reshape logits back to (batch_size, GRID_SIZE * GRID_SIZE, num_classes)\n",
    "        logits = logits.contiguous().view(batch_size, self.grid_size * self.grid_size, self.num_classes)\n",
    "\n",
    "        return logits  # (batch_size, GRID_SIZE * GRID_SIZE, num_classes)\n",
    "\n",
    "# -----------------------------\n",
    "# 9. GUI Class\n",
    "# -----------------------------\n",
    "\n",
    "class TrainingGUI:\n",
    "    \"\"\"\n",
    "    A Tkinter-based GUI that displays real-time training progress, including current epoch, loss, and accuracy.\n",
    "    \"\"\"\n",
    "    def __init__(self, root, total_epochs):\n",
    "        self.root = root\n",
    "        self.root.title(\"Model Training Progress Tracker\")\n",
    "        self.queue = queue.Queue()\n",
    "\n",
    "        # Create main frame\n",
    "        self.frame = tk.Frame(root)\n",
    "        self.frame.pack(fill=tk.BOTH, expand=1)\n",
    "\n",
    "        # Initialize GUI components\n",
    "        self.epoch_label = tk.Label(self.frame, text=f\"Epoch: 0/{total_epochs}\", font=(\"Helvetica\", 14))\n",
    "        self.epoch_label.pack(pady=5)\n",
    "\n",
    "        self.loss_label = tk.Label(self.frame, text=\"Loss: 0.0000\", font=(\"Helvetica\", 12))\n",
    "        self.loss_label.pack(pady=2)\n",
    "\n",
    "        self.accuracy_label = tk.Label(self.frame, text=\"Accuracy: 0.0000\", font=(\"Helvetica\", 12))\n",
    "        self.accuracy_label.pack(pady=2)\n",
    "\n",
    "        self.val_loss_label = tk.Label(self.frame, text=\"Validation Loss: 0.0000\", font=(\"Helvetica\", 12))\n",
    "        self.val_loss_label.pack(pady=2)\n",
    "\n",
    "        self.val_accuracy_label = tk.Label(self.frame, text=\"Validation Accuracy: 0.0000\", font=(\"Helvetica\", 12))\n",
    "        self.val_accuracy_label.pack(pady=2)\n",
    "\n",
    "        self.progress_bar = ttk.Progressbar(self.frame, orient=\"horizontal\", length=400, mode=\"determinate\")\n",
    "        self.progress_bar.pack(pady=10)\n",
    "\n",
    "        # Real-time plots\n",
    "        self.fig, self.ax = plt.subplots(figsize=(6, 4))\n",
    "        self.line_loss, = self.ax.plot([], [], label='Training Loss', color='blue')\n",
    "        self.line_val_loss, = self.ax.plot([], [], label='Validation Loss', color='orange')\n",
    "        self.line_acc, = self.ax.plot([], [], label='Training Accuracy', color='green')\n",
    "        self.line_val_acc, = self.ax.plot([], [], label='Validation Accuracy', color='red')\n",
    "        self.ax.set_xlabel('Epochs')\n",
    "        self.ax.set_ylabel('Metrics')\n",
    "        self.ax.legend()\n",
    "        self.ax.grid(True)\n",
    "        self.canvas_plot = FigureCanvasTkAgg(self.fig, master=self.frame)\n",
    "        self.canvas_plot.draw()\n",
    "        self.canvas_plot.get_tk_widget().pack()\n",
    "\n",
    "        self.loss_data = []\n",
    "        self.val_loss_data = []\n",
    "        self.acc_data = []\n",
    "        self.val_acc_data = []\n",
    "\n",
    "        # Start processing the queue\n",
    "        self.root.after(100, self.process_queue)\n",
    "\n",
    "    def process_queue(self):\n",
    "        \"\"\"\n",
    "        Process the queue for thread-safe GUI updates.\n",
    "        \"\"\"\n",
    "        while not self.queue.empty():\n",
    "            message = self.queue.get()\n",
    "            if isinstance(message, dict):\n",
    "                self.update_gui(message)\n",
    "        self.root.after(100, self.process_queue)\n",
    "\n",
    "    def update_gui(self, data):\n",
    "        \"\"\"\n",
    "        Updates the GUI elements with new training epoch information.\n",
    "        \"\"\"\n",
    "        self.epoch_label.config(text=f\"Epoch: {data['epoch']}/{data['total_epochs']}\")\n",
    "        self.loss_label.config(text=f\"Loss: {data['loss']:.4f}\")\n",
    "        self.accuracy_label.config(text=f\"Accuracy: {data['accuracy']:.4f}\")\n",
    "        self.val_loss_label.config(text=f\"Validation Loss: {data['val_loss']:.4f}\")\n",
    "        self.val_accuracy_label.config(text=f\"Validation Accuracy: {data['val_accuracy']:.4f}\")\n",
    "\n",
    "        # Update progress bar\n",
    "        self.progress_bar[\"value\"] = (data['epoch'] / data['total_epochs']) * 100\n",
    "        self.root.update_idletasks()\n",
    "\n",
    "        # Update plots\n",
    "        self.loss_data.append(data['loss'])\n",
    "        self.val_loss_data.append(data['val_loss'])\n",
    "        self.acc_data.append(data['accuracy'])\n",
    "        self.val_acc_data.append(data['val_accuracy'])\n",
    "\n",
    "        self.line_loss.set_data(range(1, len(self.loss_data) + 1), self.loss_data)\n",
    "        self.line_val_loss.set_data(range(1, len(self.val_loss_data) + 1), self.val_loss_data)\n",
    "        self.line_acc.set_data(range(1, len(self.acc_data) + 1), self.acc_data)\n",
    "        self.line_val_acc.set_data(range(1, len(self.val_acc_data) + 1), self.val_acc_data)\n",
    "\n",
    "        self.ax.relim()\n",
    "        self.ax.autoscale_view()\n",
    "        self.canvas_plot.draw()\n",
    "\n",
    "# -----------------------------\n",
    "# 10. Training Function with GUI Integration\n",
    "# -----------------------------\n",
    "\n",
    "def train_deep_model(model, train_loader, val_loader, epochs, lr, device, gui, patience=5):\n",
    "    logger.info(\"Starting the training process.\")\n",
    "    torch.autograd.set_detect_anomaly(True)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=lr)\n",
    "    model.to(device)\n",
    "\n",
    "    # Use GradScaler and autocast only if CUDA is available\n",
    "    use_amp = torch.cuda.is_available()\n",
    "    if use_amp:\n",
    "        scaler = GradScaler()\n",
    "    else:\n",
    "        scaler = None\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    epochs_no_improve = 0\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        logger.info(f\"Starting epoch {epoch}/{epochs}.\")\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            if use_amp:\n",
    "                with autocast():\n",
    "                    outputs = model(inputs)\n",
    "                    targets_flat = targets.view(-1)\n",
    "                    outputs_flat = outputs.view(-1, NUM_CLASSES)\n",
    "                    loss = criterion(outputs_flat, targets_flat)\n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "            else:\n",
    "                outputs = model(inputs)\n",
    "                targets_flat = targets.view(-1)\n",
    "                outputs_flat = outputs.view(-1, NUM_CLASSES)\n",
    "                loss = criterion(outputs_flat, targets_flat)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs_flat.detach(), 1)\n",
    "            correct += (predicted == targets_flat).sum().item()\n",
    "            total += targets_flat.size(0)\n",
    "\n",
    "            if batch_idx % 10 == 0:\n",
    "                logger.info(f\"Epoch [{epoch}/{epochs}], Batch [{batch_idx}/{len(train_loader)}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        epoch_acc = correct / total\n",
    "        logger.info(f\"Epoch [{epoch}/{epochs}] completed. Training Loss: {epoch_loss:.4f}, Training Accuracy: {epoch_acc:.4f}\")\n",
    "\n",
    "        # Validation Phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in val_loader:\n",
    "                inputs = inputs.to(device)\n",
    "                targets = targets.to(device)\n",
    "\n",
    "                if use_amp:\n",
    "                    with autocast():\n",
    "                        outputs = model(inputs)\n",
    "                        targets_flat = targets.view(-1)\n",
    "                        outputs_flat = outputs.view(-1, NUM_CLASSES)\n",
    "                        loss = criterion(outputs_flat, targets_flat)\n",
    "                else:\n",
    "                    outputs = model(inputs)\n",
    "                    targets_flat = targets.view(-1)\n",
    "                    outputs_flat = outputs.view(-1, NUM_CLASSES)\n",
    "                    loss = criterion(outputs_flat, targets_flat)\n",
    "\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                _, predicted = torch.max(outputs_flat.detach(), 1)\n",
    "                val_correct += (predicted == targets_flat).sum().item()\n",
    "                val_total += targets_flat.size(0)\n",
    "\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        val_acc = val_correct / val_total\n",
    "        logger.info(f\"Validation Loss: {avg_val_loss:.4f}, Validation Accuracy: {val_acc:.4f}\")\n",
    "\n",
    "        # Update GUI\n",
    "        gui.queue.put({\n",
    "            'epoch': epoch,\n",
    "            'total_epochs': epochs,\n",
    "            'loss': epoch_loss,\n",
    "            'accuracy': epoch_acc,\n",
    "            'val_loss': avg_val_loss,\n",
    "            'val_accuracy': val_acc\n",
    "        })\n",
    "\n",
    "        # Check for improvement\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            epochs_no_improve = 0\n",
    "            # Save the best model\n",
    "            torch.save(model.state_dict(), \"best_deep_model.pth\")\n",
    "            logger.info(f\"Epoch {epoch}/{epochs} - Validation loss decreased. Saving model.\")\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            logger.info(f\"Epoch {epoch}/{epochs} - No improvement in validation loss for {epochs_no_improve} epochs.\")\n",
    "\n",
    "        # Early Stopping\n",
    "        if epochs_no_improve >= patience:\n",
    "            logger.info(\"Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "    logger.info(\"Training completed.\")\n",
    "\n",
    "# -----------------------------\n",
    "# 11. Evaluation and Prediction Functions\n",
    "# -----------------------------\n",
    "\n",
    "def evaluate_model(model, test_loader, device='cpu'):\n",
    "    \"\"\"\n",
    "    Evaluates the model on the test dataset.\n",
    "    \n",
    "    Args:\n",
    "        model (nn.Module): Trained model.\n",
    "        test_loader (DataLoader): DataLoader for the test dataset.\n",
    "        device (str): Device to run evaluation on.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (average_loss, accuracy)\n",
    "    \"\"\"\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in test_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            outputs = model(inputs)  # Shape: (batch_size, 900, num_classes)\n",
    "            loss = criterion(outputs.view(-1, NUM_CLASSES), targets.view(-1))\n",
    "            total_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "            _, predicted = torch.max(outputs.view(-1, NUM_CLASSES), 1)\n",
    "            correct += (predicted == targets.view(-1)).sum().item()\n",
    "            total += targets.view(-1).size(0)\n",
    "\n",
    "    avg_loss = total_loss / len(test_loader.dataset)\n",
    "    accuracy = correct / total\n",
    "\n",
    "    logger.info(f\"Test Loss: {avg_loss:.4f}, Test Accuracy: {accuracy:.4f}\")\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "def visualize_predictions(model, test_loader, device='cpu', num_samples=5):\n",
    "    \"\"\"\n",
    "    Visualizes a few predictions made by the model.\n",
    "    \n",
    "    Args:\n",
    "        model (nn.Module): Trained model.\n",
    "        test_loader (DataLoader): DataLoader for the test dataset.\n",
    "        device (str): Device to run inference on.\n",
    "        num_samples (int): Number of samples to visualize.\n",
    "    \"\"\"\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    samples_visualized = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in test_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            outputs = model(inputs)  # Shape: (batch_size, 900, num_classes)\n",
    "            _, predicted = torch.max(outputs, 2)  # Shape: (batch_size, 900)\n",
    "\n",
    "            for i in range(inputs.size(0)):\n",
    "                input_grid = inputs[i].cpu().numpy().squeeze()  # Shape: (GRID_SIZE, GRID_SIZE)\n",
    "                predicted_grid = predicted[i].cpu().numpy().reshape(GRID_SIZE, GRID_SIZE)\n",
    "                actual_grid = targets[i].cpu().numpy().reshape(GRID_SIZE, GRID_SIZE)\n",
    "\n",
    "                fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "                # Input Grid\n",
    "                axs[0].imshow(input_grid, cmap='viridis', interpolation='nearest')\n",
    "                axs[0].set_title(\"Input Grid\")\n",
    "                axs[0].axis('off')\n",
    "\n",
    "                # Predicted Grid\n",
    "                axs[1].imshow(predicted_grid, cmap='viridis', interpolation='nearest')\n",
    "                axs[1].set_title(\"Predicted Grid\")\n",
    "                axs[1].axis('off')\n",
    "\n",
    "                # Actual Grid\n",
    "                axs[2].imshow(actual_grid, cmap='viridis', interpolation='nearest')\n",
    "                axs[2].set_title(\"Actual Grid\")\n",
    "                axs[2].axis('off')\n",
    "\n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "\n",
    "                samples_visualized += 1\n",
    "                if samples_visualized >= num_samples:\n",
    "                    return\n",
    "\n",
    "# -----------------------------\n",
    "# 12. Main Workflow with Modifications\n",
    "# -----------------------------\n",
    "\n",
    "def main():\n",
    "    # Define device\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    logger.info(f\"Using device: {device}\")\n",
    "\n",
    "    # Load ARC data\n",
    "    arc_data = load_arc_data()\n",
    "\n",
    "    # Extract and reshape training and evaluation grid pairs\n",
    "    train_grid_pairs = flatten_and_reshape(arc_data.get(\"arc-agi_training-challenges\", {}), grid_size=GRID_SIZE)\n",
    "    eval_grid_pairs = flatten_and_reshape(arc_data.get(\"arc-agi_evaluation-challenges\", {}), grid_size=GRID_SIZE)\n",
    "\n",
    "    logger.info(f\"Number of training grid pairs: {len(train_grid_pairs)}\")\n",
    "    logger.info(f\"Number of evaluation grid pairs: {len(eval_grid_pairs)}\")\n",
    "\n",
    "    # Generate multiple augmented datasets\n",
    "    augmented_pairs = generate_multiple_augmented_datasets(train_grid_pairs, num_augmented_sets=3)\n",
    "\n",
    "    # Combine all datasets\n",
    "    combined_train_pairs = train_grid_pairs + augmented_pairs\n",
    "\n",
    "    # Split into training and validation sets (e.g., 80-20 split)\n",
    "    train_pairs, val_pairs = train_test_split(combined_train_pairs, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Reduce dataset size for testing\n",
    "    train_pairs = train_pairs[:50]  # Use 50 samples for quick testing\n",
    "    val_pairs = val_pairs[:10]      # Use 10 samples for validation\n",
    "\n",
    "    # Create DataLoaders\n",
    "    train_dataset = AugmentedARCDataset(train_pairs, augment=False)  # Already augmented\n",
    "    val_dataset = AugmentedARCDataset(val_pairs, augment=False)\n",
    "    eval_dataset = AugmentedARCDataset(eval_grid_pairs, augment=False)\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, \n",
    "        batch_size=4,  # Reduced batch size for debugging\n",
    "        shuffle=True, \n",
    "        collate_fn=collate_fn,\n",
    "        num_workers=0  # Set to 0 to avoid multiprocessing issues on Windows\n",
    "    )\n",
    "\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset, \n",
    "        batch_size=4, \n",
    "        shuffle=False, \n",
    "        collate_fn=collate_fn,\n",
    "        num_workers=0  # Set to 0 to avoid multiprocessing issues on Windows\n",
    "    )\n",
    "\n",
    "    eval_loader = DataLoader(\n",
    "        eval_dataset, \n",
    "        batch_size=4, \n",
    "        shuffle=False, \n",
    "        collate_fn=collate_fn,\n",
    "        num_workers=0\n",
    "    )\n",
    "\n",
    "    logger.info(f\"Training DataLoader size: {len(train_loader)} batches\")\n",
    "    logger.info(f\"Validation DataLoader size: {len(val_loader)} batches\")\n",
    "    logger.info(f\"Number of training samples: {len(train_dataset)}\")\n",
    "    logger.info(f\"Number of validation samples: {len(val_dataset)}\")\n",
    "    logger.info(f\"Number of evaluation samples: {len(eval_dataset)}\")\n",
    "\n",
    "    # Initialize the model\n",
    "    model = CNNGridMapper(num_classes=NUM_CLASSES, grid_size=GRID_SIZE).to(device)\n",
    "    logger.info(\"Model initialized successfully.\")\n",
    "\n",
    "    # Test model forward and backward pass\n",
    "    try:\n",
    "        model.train()\n",
    "        sample_inputs, sample_targets = next(iter(train_loader))\n",
    "        sample_inputs = sample_inputs.to(device)\n",
    "        sample_targets = sample_targets.to(device)\n",
    "\n",
    "        outputs = model(sample_inputs)\n",
    "        targets_flat = sample_targets.view(-1)\n",
    "        outputs_flat = outputs.view(-1, NUM_CLASSES)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        loss = criterion(outputs_flat, targets_flat)\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        logger.info(\"Single batch forward and backward pass successful.\")\n",
    "    except Exception as e:\n",
    "        logger.exception(\"Model forward or backward pass failed.\")\n",
    "        return\n",
    "\n",
    "    # Initialize the GUI\n",
    "    root = tk.Tk()\n",
    "    total_epochs = 2  # Reduced for quick testing\n",
    "    gui = TrainingGUI(root, total_epochs)\n",
    "\n",
    "    # Define the training thread inside main()\n",
    "    def train_thread():\n",
    "        logger.info(\"Training thread started.\")\n",
    "        try:\n",
    "            train_deep_model(model, train_loader, val_loader, epochs=total_epochs, lr=1e-3,\n",
    "                             device=device, gui=gui, patience=10)\n",
    "            logger.info(\"Training completed successfully.\")\n",
    "            # After training, evaluate the model\n",
    "            evaluate_model(model, val_loader, device=device)\n",
    "            visualize_predictions(model, val_loader, device=device, num_samples=5)\n",
    "            # Evaluate on evaluation set\n",
    "            logger.info(\"Evaluating on evaluation set.\")\n",
    "            evaluate_model(model, eval_loader, device=device)\n",
    "            visualize_predictions(model, eval_loader, device=device, num_samples=5)\n",
    "            logger.info(\"All processes completed successfully.\")\n",
    "        except Exception as e:\n",
    "            logger.exception(\"An error occurred in the training thread.\")\n",
    "\n",
    "    # Run training directly for debugging\n",
    "    train_thread()\n",
    "\n",
    "    root.mainloop()\n",
    "\n",
    "# -----------------------------\n",
    "# 13. Execute the Main Function\n",
    "# -----------------------------\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8f9656-434b-47d4-89e5-50b79d09e669",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================================================\n",
    "# Comprehensive Implementation for ARC Dataset Training with TensorBoard\n",
    "# ===============================================================\n",
    "\n",
    "# -----------------------------\n",
    "# 1. Install Necessary Packages\n",
    "# -----------------------------\n",
    "# Note: Uncomment the following lines if running for the first time.\n",
    "# %pip install torch torchvision tensorboard tqdm matplotlib\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Import Libraries\n",
    "# -----------------------------\n",
    "import math\n",
    "import json\n",
    "import logging\n",
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "import threading\n",
    "import time\n",
    "import subprocess\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from dataclasses import dataclass\n",
    "from torchvision import models\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision.models import ResNet18_Weights\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tqdm.notebook import tqdm  # For progress bars in Jupyter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Configure Logging and Seed\n",
    "# -----------------------------\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_seed()\n",
    "\n",
    "# -----------------------------\n",
    "# 4. Define Constants\n",
    "# -----------------------------\n",
    "\n",
    "GRID_SIZE = 30        # Fixed grid size (adjust as needed)\n",
    "NUM_CLASSES = 11      # 0-10, where 10 represents dead squares\n",
    "\n",
    "# -----------------------------\n",
    "# 5. Define Data Structures and Loading Functions\n",
    "# -----------------------------\n",
    "\n",
    "# Data Class for Grid Pairs\n",
    "@dataclass\n",
    "class GridPair:\n",
    "    task_id: str\n",
    "    input_grid: list\n",
    "    output_grid: list\n",
    "\n",
    "# Load ARC Data\n",
    "def load_arc_data():\n",
    "    file_paths = {\n",
    "        \"arc-agi_training-challenges\": \"arc-agi_training_challenges.json\",\n",
    "        \"arc-agi_evaluation-challenges\": \"arc-agi_evaluation_challenges.json\",\n",
    "        \"arc-agi_training_solutions\": \"arc-agi_training_solutions.json\",\n",
    "        \"arc-agi_evaluation_solutions\": \"arc-agi_evaluation_solutions.json\",\n",
    "    }\n",
    "    arc_data = {}\n",
    "    for key, path in file_paths.items():\n",
    "        try:\n",
    "            with open(path, 'r') as f:\n",
    "                arc_data[key] = json.load(f)\n",
    "                logger.info(f\"Loaded {key} from {path}.\")\n",
    "        except (FileNotFoundError, json.JSONDecodeError) as e:\n",
    "            logger.error(f\"Error loading {path}: {e}\")\n",
    "            arc_data[key] = {}\n",
    "    return arc_data\n",
    "\n",
    "# Reshape to Fixed Square Grid\n",
    "def reshape_to_square_grid(flat_list, grid_size=30):\n",
    "    required_length = grid_size * grid_size\n",
    "    current_length = len(flat_list)\n",
    "    \n",
    "    if current_length > required_length:\n",
    "        # Truncate if the grid is larger than grid_size x grid_size\n",
    "        flat_list = flat_list[:required_length]\n",
    "    else:\n",
    "        # Pad with -1 to reach the required length\n",
    "        flat_list = np.pad(flat_list, (0, required_length - current_length), 'constant', constant_values=-1)\n",
    "    \n",
    "    return flat_list.reshape(grid_size, grid_size).tolist()\n",
    "\n",
    "# Extract and Reshape Grid\n",
    "def extract_and_reshape_grid(grid, grid_size=30):\n",
    "    try:\n",
    "        # Flatten the grid if it's a list of lists\n",
    "        if isinstance(grid, list):\n",
    "            flat_list = [item for sublist in grid for item in sublist]\n",
    "        else:\n",
    "            flat_list = [grid]\n",
    "        return reshape_to_square_grid(flat_list, grid_size)\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error processing grid: {e}\")\n",
    "        return None\n",
    "\n",
    "# Flatten and Reshape Grid Data\n",
    "def flatten_and_reshape(task_data, grid_size=30):\n",
    "    flattened_pairs = []\n",
    "    for task_id, task_content in task_data.items():\n",
    "        logger.info(f\"Parsing task {task_id}...\")\n",
    "        train_pairs = task_content.get('train', [])\n",
    "        for pair in train_pairs:\n",
    "            input_grid = extract_and_reshape_grid(pair.get(\"input\"), grid_size)\n",
    "            output_grid = extract_and_reshape_grid(pair.get(\"output\"), grid_size)\n",
    "            if input_grid and output_grid:\n",
    "                flattened_pairs.append(GridPair(task_id, input_grid, output_grid))\n",
    "            else:\n",
    "                logger.warning(f\"Task ID: {task_id} has invalid input/output grids.\")\n",
    "    logger.info(f\"Total valid grid pairs extracted: {len(flattened_pairs)}\")\n",
    "    return flattened_pairs\n",
    "\n",
    "# -----------------------------\n",
    "# 6. Data Augmentation Functions\n",
    "# -----------------------------\n",
    "\n",
    "def augment_grid(grid, noise_prob=0.2, dead_square_prob=0.1):\n",
    "    \"\"\"Applies augmentation to the grid by adding noise and dead squares.\"\"\"\n",
    "    augmented_grid = np.array(grid).copy()\n",
    "\n",
    "    for i in range(augmented_grid.shape[0]):\n",
    "        for j in range(augmented_grid.shape[1]):\n",
    "            if random.random() < noise_prob:\n",
    "                augmented_grid[i, j] = random.randint(0, NUM_CLASSES - 2)  # Add noise within 0-9\n",
    "            if random.random() < dead_square_prob:\n",
    "                augmented_grid[i, j] = -1  # Dead square\n",
    "    return augmented_grid.tolist()\n",
    "\n",
    "def rotate_grid(grid):\n",
    "    \"\"\"Randomly rotates the grid.\"\"\"\n",
    "    rotations = random.choice([0, 1, 2, 3])\n",
    "    return np.rot90(grid, rotations).tolist()\n",
    "\n",
    "def flip_grid(grid):\n",
    "    \"\"\"Randomly flips the grid.\"\"\"\n",
    "    if random.random() > 0.5:\n",
    "        return np.flipud(grid).tolist()  # Vertical flip\n",
    "    else:\n",
    "        return np.fliplr(grid).tolist()  # Horizontal flip\n",
    "\n",
    "# -----------------------------\n",
    "# 7. Custom Collate Function\n",
    "# -----------------------------\n",
    "\n",
    "def collate_fn(batch):\n",
    "    \"\"\"\n",
    "    Stack input and output grids into batch tensors.\n",
    "    All grids are already padded to GRID_SIZE x GRID_SIZE.\n",
    "    \"\"\"\n",
    "    inputs, outputs = zip(*batch)  # Unzip the batch\n",
    "    inputs = torch.stack(inputs)    # Shape: (batch_size, 1, GRID_SIZE, GRID_SIZE)\n",
    "    outputs = torch.stack(outputs)  # Shape: (batch_size, GRID_SIZE, GRID_SIZE)\n",
    "    return inputs, outputs\n",
    "\n",
    "# -----------------------------\n",
    "# 8. PyTorch Dataset Class\n",
    "# -----------------------------\n",
    "\n",
    "class AugmentedARCDataset(Dataset):\n",
    "    def __init__(self, grid_pairs, augment=True):\n",
    "        self.grid_pairs = grid_pairs\n",
    "        self.augment = augment\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.grid_pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        pair = self.grid_pairs[idx]\n",
    "        input_grid = pair.input_grid\n",
    "        output_grid = pair.output_grid\n",
    "\n",
    "        if self.augment:\n",
    "            input_grid = augment_grid(input_grid)\n",
    "            input_grid = rotate_grid(input_grid)\n",
    "            input_grid = flip_grid(input_grid)\n",
    "\n",
    "        # Convert to tensors\n",
    "        input_tensor = torch.tensor(input_grid, dtype=torch.float32).unsqueeze(0)  # Shape: (1, GRID_SIZE, GRID_SIZE)\n",
    "\n",
    "        # Map -1 to NUM_CLASSES -1 (10)\n",
    "        output_grid_mapped = [\n",
    "            [NUM_CLASSES - 1 if cell == -1 else cell for cell in row]\n",
    "            for row in output_grid\n",
    "        ]\n",
    "        output_tensor = torch.tensor(output_grid_mapped, dtype=torch.long)  # Shape: (GRID_SIZE, GRID_SIZE)\n",
    "\n",
    "        return input_tensor, output_tensor\n",
    "\n",
    "# -----------------------------\n",
    "# 9. Define the Deep Neural Network Model\n",
    "# -----------------------------\n",
    "\n",
    "class CNNGridMapper(nn.Module):\n",
    "    def __init__(self, num_classes=NUM_CLASSES, grid_size=GRID_SIZE):\n",
    "        super(CNNGridMapper, self).__init__()\n",
    "        self.grid_size = grid_size\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        # CNN Backbone: ResNet18 pretrained on ImageNet\n",
    "        self.cnn = models.resnet18(weights=ResNet18_Weights.DEFAULT)\n",
    "        # Modify the first convolutional layer to accept single-channel input\n",
    "        self.cnn.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        # Initialize the new conv1 weights\n",
    "        nn.init.kaiming_normal_(self.cnn.conv1.weight, mode='fan_out', nonlinearity='relu')\n",
    "        # Remove the fully connected layer and average pool\n",
    "        self.cnn = nn.Sequential(*list(self.cnn.children())[:-2])  # Output: (batch_size, 512, H, W)\n",
    "\n",
    "        # Interpolation to match GRID_SIZE\n",
    "        self.interpolate = nn.Upsample(size=(grid_size, grid_size), mode='bilinear', align_corners=False)\n",
    "\n",
    "        # RNN Module: LSTM\n",
    "        # Treat each row as a sequence of cells\n",
    "        self.rnn = nn.LSTM(input_size=512,  # Number of features per cell from CNN\n",
    "                           hidden_size=128,\n",
    "                           num_layers=2,\n",
    "                           batch_first=True,\n",
    "                           bidirectional=True)\n",
    "\n",
    "        # Fully Connected Layers\n",
    "        self.fc = nn.Linear(128 * 2, num_classes)  # *2 for bidirectional\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (batch_size, 1, GRID_SIZE, GRID_SIZE)\n",
    "        batch_size = x.size(0)\n",
    "\n",
    "        # Pass through CNN\n",
    "        features = self.cnn(x)  # Shape: (batch_size, 512, H, W)\n",
    "\n",
    "        # Interpolate to (512, GRID_SIZE, GRID_SIZE)\n",
    "        features = self.interpolate(features)  # Shape: (batch_size, 512, GRID_SIZE, GRID_SIZE)\n",
    "\n",
    "        # Reshape to (batch_size, GRID_SIZE, GRID_SIZE, 512)\n",
    "        features = features.permute(0, 2, 3, 1)  # Shape: (batch_size, GRID_SIZE, GRID_SIZE, 512)\n",
    "\n",
    "        # Reshape to (batch_size * GRID_SIZE, GRID_SIZE, 512) for RNN\n",
    "        features = features.reshape(batch_size * self.grid_size, self.grid_size, 512)  # Shape: (batch_size*30, 30, 512)\n",
    "\n",
    "        # Pass through RNN\n",
    "        rnn_out, _ = self.rnn(features)  # Shape: (batch_size*30, 30, 256)\n",
    "\n",
    "        # Pass through Fully Connected layer\n",
    "        logits = self.fc(rnn_out)  # Shape: (batch_size*30, 30, 11)\n",
    "\n",
    "        # Reshape logits back to (batch_size, GRID_SIZE * GRID_SIZE, num_classes)\n",
    "        logits = logits.reshape(batch_size, self.grid_size, self.grid_size, self.num_classes)  # Shape: (batch_size, 30, 30, 11)\n",
    "        logits = logits.reshape(batch_size, self.grid_size * self.grid_size, self.num_classes)  # Shape: (batch_size, 900, 11)\n",
    "\n",
    "        return logits  # (batch_size, 900, num_classes)\n",
    "\n",
    "# -----------------------------\n",
    "# 10. Training Function with TensorBoard Integration and Progress Bars\n",
    "# -----------------------------\n",
    "\n",
    "def train_deep_model(model, train_loader, val_loader, epochs, lr, device, patience=5):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=lr)\n",
    "    scaler = GradScaler()  # Initialize GradScaler for mixed precision\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    # Initialize TensorBoard writer\n",
    "    writer = SummaryWriter('runs/deep_model')\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    epochs_no_improve = 0\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        logger.info(f\"Starting Epoch {epoch}/{epochs}\")\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        # Initialize tqdm progress bar for training\n",
    "        train_bar = tqdm(train_loader, desc=f\"Epoch {epoch} Training\", leave=False)\n",
    "        for batch_idx, (inputs, targets) in enumerate(train_bar, 1):\n",
    "            inputs = inputs.to(device)    # Shape: (batch_size, 1, GRID_SIZE, GRID_SIZE)\n",
    "            targets = targets.to(device)  # Shape: (batch_size, GRID_SIZE, GRID_SIZE)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            with autocast():  # Enable autocasting for mixed precision\n",
    "                outputs = model(inputs)  # Shape: (batch_size, 900, num_classes)\n",
    "                targets_flat = targets.view(-1)  # Shape: (batch_size * 900)\n",
    "                outputs_flat = outputs.view(-1, NUM_CLASSES)  # Shape: (batch_size * 900, num_classes)\n",
    "                loss = criterion(outputs_flat, targets_flat)\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs_flat, 1)\n",
    "            correct += (predicted == targets_flat).sum().item()\n",
    "            total += targets_flat.size(0)\n",
    "\n",
    "            # Update progress bar with loss\n",
    "            train_bar.set_postfix({'Loss': loss.item()})\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        epoch_acc = correct / total\n",
    "\n",
    "        logger.info(f\"Epoch {epoch}/{epochs} - Train Loss: {epoch_loss:.4f}, Train Acc: {epoch_acc:.4f} - Starting Validation Phase.\")\n",
    "\n",
    "        # Validation Phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "\n",
    "        val_bar = tqdm(val_loader, desc=f\"Epoch {epoch} Validation\", leave=False)\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (inputs, targets) in enumerate(val_bar, 1):\n",
    "                inputs = inputs.to(device)\n",
    "                targets = targets.to(device)\n",
    "\n",
    "                with autocast():  # Enable autocasting for mixed precision\n",
    "                    outputs = model(inputs)\n",
    "                    targets_flat = targets.view(-1)\n",
    "                    outputs_flat = outputs.view(-1, NUM_CLASSES)\n",
    "                    loss = criterion(outputs_flat, targets_flat)\n",
    "                    val_loss += loss.item()\n",
    "\n",
    "                    _, predicted = torch.max(outputs_flat, 1)\n",
    "                    val_correct += (predicted == targets_flat).sum().item()\n",
    "                    val_total += targets_flat.size(0)\n",
    "\n",
    "                # Update validation progress bar with loss\n",
    "                val_bar.set_postfix({'Val Loss': loss.item()})\n",
    "\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        val_acc = val_correct / val_total\n",
    "\n",
    "        logger.info(f\"Epoch {epoch}/{epochs} - Val Loss: {avg_val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "        # Log metrics to TensorBoard\n",
    "        writer.add_scalar('Loss/Train', epoch_loss, epoch)\n",
    "        writer.add_scalar('Loss/Validation', avg_val_loss, epoch)\n",
    "        writer.add_scalar('Accuracy/Train', epoch_acc, epoch)\n",
    "        writer.add_scalar('Accuracy/Validation', val_acc, epoch)\n",
    "\n",
    "        # Check for improvement\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            epochs_no_improve = 0\n",
    "            # Save the best model\n",
    "            torch.save(model.state_dict(), \"best_deep_model.pth\")\n",
    "            logger.info(\"Validation loss decreased. Saving model.\")\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            logger.info(f\"No improvement in validation loss for {epochs_no_improve} epochs.\")\n",
    "\n",
    "        # Early Stopping\n",
    "        if epochs_no_improve >= patience:\n",
    "            logger.info(\"Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "    writer.close()\n",
    "    logger.info(\"Training completed.\")\n",
    "\n",
    "# -----------------------------\n",
    "# 11. Evaluation and Prediction Functions\n",
    "# -----------------------------\n",
    "\n",
    "def evaluate_model(model, test_loader, device='cpu'):\n",
    "    \"\"\"\n",
    "    Evaluates the model on the test dataset.\n",
    "    \n",
    "    Args:\n",
    "        model (nn.Module): Trained model.\n",
    "        test_loader (DataLoader): DataLoader for the test dataset.\n",
    "        device (str): Device to run evaluation on.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (average_loss, accuracy)\n",
    "    \"\"\"\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in tqdm(test_loader, desc=\"Evaluating\", leave=False):\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            outputs = model(inputs)  # Shape: (batch_size, 900, num_classes)\n",
    "            loss = criterion(outputs.view(-1, NUM_CLASSES), targets.view(-1))\n",
    "            total_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "            _, predicted = torch.max(outputs.view(-1, NUM_CLASSES), 1)\n",
    "            correct += (predicted == targets.view(-1)).sum().item()\n",
    "            total += targets.view(-1).size(0)\n",
    "\n",
    "    avg_loss = total_loss / len(test_loader.dataset)\n",
    "    accuracy = correct / total\n",
    "\n",
    "    logger.info(f\"Test Loss: {avg_loss:.4f}, Test Accuracy: {accuracy:.4f}\")\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "def visualize_predictions(model, test_loader, device='cpu', num_samples=5):\n",
    "    \"\"\"\n",
    "    Visualizes a few predictions made by the model.\n",
    "    \n",
    "    Args:\n",
    "        model (nn.Module): Trained model.\n",
    "        test_loader (DataLoader): DataLoader for the test dataset.\n",
    "        device (str): Device to run inference on.\n",
    "        num_samples (int): Number of samples to visualize.\n",
    "    \"\"\"\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    samples_visualized = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in test_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            outputs = model(inputs)  # Shape: (batch_size, 900, num_classes)\n",
    "            _, predicted = torch.max(outputs, 2)  # Shape: (batch_size, 900)\n",
    "\n",
    "            for i in range(inputs.size(0)):\n",
    "                input_grid = inputs[i].cpu().numpy().squeeze()  # Shape: (GRID_SIZE, GRID_SIZE)\n",
    "                predicted_grid = predicted[i].cpu().numpy().reshape(GRID_SIZE, GRID_SIZE)\n",
    "                actual_grid = targets[i].cpu().numpy().reshape(GRID_SIZE, GRID_SIZE)\n",
    "\n",
    "                fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "                # Input Grid\n",
    "                axs[0].imshow(input_grid, cmap='viridis', interpolation='nearest')\n",
    "                axs[0].set_title(\"Input Grid\")\n",
    "                axs[0].axis('off')\n",
    "\n",
    "                # Predicted Grid\n",
    "                axs[1].imshow(predicted_grid, cmap='viridis', interpolation='nearest')\n",
    "                axs[1].set_title(\"Predicted Grid\")\n",
    "                axs[1].axis('off')\n",
    "\n",
    "                # Actual Grid\n",
    "                axs[2].imshow(actual_grid, cmap='viridis', interpolation='nearest')\n",
    "                axs[2].set_title(\"Actual Grid\")\n",
    "                axs[2].axis('off')\n",
    "\n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "\n",
    "                samples_visualized += 1\n",
    "                if samples_visualized >= num_samples:\n",
    "                    return\n",
    "\n",
    "# -----------------------------\n",
    "# 12. TensorBoard Launch Function\n",
    "# -----------------------------\n",
    "\n",
    "def launch_tensorboard(log_dir='runs/deep_model'):\n",
    "    \"\"\"\n",
    "    Launches TensorBoard in a separate thread.\n",
    "    \n",
    "    Args:\n",
    "        log_dir (str): Directory where TensorBoard logs are stored.\n",
    "    \"\"\"\n",
    "    def run_tensorboard():\n",
    "        subprocess.run([\"tensorboard\", \"--logdir\", log_dir, \"--port\", \"6006\"])\n",
    "    \n",
    "    thread = threading.Thread(target=run_tensorboard, daemon=True)\n",
    "    thread.start()\n",
    "    time.sleep(5)  # Wait for TensorBoard to start\n",
    "    logger.info(\"TensorBoard launched at http://localhost:6006\")\n",
    "\n",
    "# -----------------------------\n",
    "# 13. Main Workflow\n",
    "# -----------------------------\n",
    "\n",
    "def main():\n",
    "    # Define device\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    logger.info(f\"Using device: {device}\")\n",
    "\n",
    "    # Load ARC data\n",
    "    arc_data = load_arc_data()\n",
    "\n",
    "    # Extract and reshape training and evaluation grid pairs\n",
    "    train_grid_pairs = flatten_and_reshape(arc_data.get(\"arc-agi_training-challenges\", {}), grid_size=GRID_SIZE)\n",
    "    eval_grid_pairs = flatten_and_reshape(arc_data.get(\"arc-agi_evaluation-challenges\", {}), grid_size=GRID_SIZE)\n",
    "\n",
    "    logger.info(f\"Number of training grid pairs: {len(train_grid_pairs)}\")\n",
    "    logger.info(f\"Number of evaluation grid pairs: {len(eval_grid_pairs)}\")\n",
    "\n",
    "    # Split into training and validation sets (e.g., 80-20 split)\n",
    "    train_pairs, val_pairs = train_test_split(train_grid_pairs, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Create DataLoaders\n",
    "    train_dataset = AugmentedARCDataset(train_pairs, augment=True)\n",
    "    val_dataset = AugmentedARCDataset(val_pairs, augment=False)\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, \n",
    "        batch_size=32, \n",
    "        shuffle=True, \n",
    "        collate_fn=collate_fn,\n",
    "        num_workers=0  # Set to 0 to avoid multiprocessing issues on Windows\n",
    "    )\n",
    "\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset, \n",
    "        batch_size=32, \n",
    "        shuffle=False, \n",
    "        collate_fn=collate_fn,\n",
    "        num_workers=0  # Set to 0 to avoid multiprocessing issues on Windows\n",
    "    )\n",
    "\n",
    "    logger.info(f\"Training DataLoader size: {len(train_loader)} batches\")\n",
    "    logger.info(f\"Validation DataLoader size: {len(val_loader)} batches\")\n",
    "\n",
    "    # Initialize the model\n",
    "    model = CNNGridMapper(num_classes=NUM_CLASSES, grid_size=GRID_SIZE).to(device)\n",
    "    logger.info(\"Model initialized successfully.\")\n",
    "\n",
    "    # Launch TensorBoard in a separate thread\n",
    "    launch_tensorboard(log_dir='runs/deep_model')\n",
    "\n",
    "    # Train the model\n",
    "    train_deep_model(model, train_loader, val_loader, epochs=20, lr=1e-3, device=device, patience=5)\n",
    "\n",
    "    # Evaluate the model\n",
    "    evaluate_model(model, val_loader, device=device)\n",
    "\n",
    "    # Visualize Predictions\n",
    "    visualize_predictions(model, val_loader, device=device, num_samples=5)\n",
    "\n",
    "    logger.info(\"All processes completed successfully.\")\n",
    "\n",
    "# -----------------------------\n",
    "# 14. Execute the Main Function\n",
    "# -----------------------------\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34afd7b-8e4d-4fc3-9474-f90966d74ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import json\n",
    "import logging\n",
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from dataclasses import dataclass\n",
    "from torchvision import models\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# -----------------------------\n",
    "# 1. Configure Logging and Set Random Seeds\n",
    "# -----------------------------\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_seed()\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Define Constants and Variables\n",
    "# -----------------------------\n",
    "GRID_SIZE = 30\n",
    "NUM_CLASSES = 11\n",
    "EPOCHS = 20\n",
    "LEARNING_RATE = 1e-3\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Define Data Classes and Functions\n",
    "# -----------------------------\n",
    "@dataclass\n",
    "class GridPair:\n",
    "    task_id: str\n",
    "    input_grid: list\n",
    "    output_grid: list\n",
    "\n",
    "def load_arc_data():\n",
    "    file_paths = {\n",
    "        \"arc-agi_training-challenges\": \"arc-agi_training_challenges.json\",\n",
    "        \"arc-agi_evaluation-challenges\": \"arc-agi_evaluation_challenges.json\",\n",
    "    }\n",
    "    arc_data = {}\n",
    "    for key, path in file_paths.items():\n",
    "        try:\n",
    "            with open(path, 'r') as f:\n",
    "                arc_data[key] = json.load(f)\n",
    "                logger.info(f\"Loaded {key} from {path}.\")\n",
    "        except (FileNotFoundError, json.JSONDecodeError) as e:\n",
    "            logger.error(f\"Error loading {path}: {e}\")\n",
    "            arc_data[key] = {}\n",
    "    return arc_data\n",
    "\n",
    "def reshape_to_square_grid(flat_list):\n",
    "    size = GRID_SIZE\n",
    "    padded_list = np.pad(flat_list, (0, size * size - len(flat_list)), constant_values=-1)\n",
    "    return padded_list.reshape(size, size).tolist()\n",
    "\n",
    "class AugmentedARCDataset(Dataset):\n",
    "    def __init__(self, grid_pairs, augment=True):\n",
    "        self.grid_pairs = grid_pairs\n",
    "        self.augment = augment\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.grid_pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        pair = self.grid_pairs[idx]\n",
    "        input_tensor = torch.tensor(pair.input_grid, dtype=torch.float32).unsqueeze(0)\n",
    "        output_tensor = torch.tensor(pair.output_grid, dtype=torch.long)\n",
    "        return input_tensor, output_tensor\n",
    "\n",
    "def collate_fn(batch):\n",
    "    inputs, outputs = zip(*batch)\n",
    "    inputs = torch.stack(inputs)\n",
    "    outputs = torch.stack(outputs)\n",
    "    return inputs, outputs\n",
    "\n",
    "# -----------------------------\n",
    "# 4. Define Model\n",
    "# -----------------------------\n",
    "class CNNGridMapper(nn.Module):\n",
    "    def __init__(self, num_classes=NUM_CLASSES):\n",
    "        super(CNNGridMapper, self).__init__()\n",
    "        self.cnn = models.resnet18(weights=None)\n",
    "        self.cnn.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.cnn(x)\n",
    "        x = x.view(x.size(0), -1)  # Flatten the output\n",
    "        return self.fc(x)\n",
    "\n",
    "# -----------------------------\n",
    "# 5. Training and Evaluation Functions\n",
    "# -----------------------------\n",
    "def train_model(model, train_loader, val_loader, epochs, device):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    model.to(device)\n",
    "\n",
    "    train_losses, val_losses = [], []\n",
    "    train_accuracies, val_accuracies = [], []\n",
    "\n",
    "    plt.ion()  # Enable interactive mode for live plotting\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(8, 10))\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss, correct, total = 0.0, 0, 0\n",
    "\n",
    "        for inputs, targets in train_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs.view(-1, NUM_CLASSES), targets.view(-1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct += (predicted == targets).sum().item()\n",
    "            total += targets.size(0)\n",
    "\n",
    "        train_loss = running_loss / len(train_loader)\n",
    "        train_acc = correct / total\n",
    "        val_loss, val_acc = evaluate_model(model, val_loader, device)\n",
    "\n",
    "        train_losses.append(train_loss)\n",
    "        train_accuracies.append(train_acc)\n",
    "        val_losses.append(val_loss)\n",
    "        val_accuracies.append(val_acc)\n",
    "\n",
    "        logger.info(f\"Epoch {epoch + 1}/{epochs} - \"\n",
    "                    f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f} - \"\n",
    "                    f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "        # Update plots\n",
    "        ax1.clear()\n",
    "        ax2.clear()\n",
    "        ax1.plot(train_losses, label='Train Loss')\n",
    "        ax1.plot(val_losses, label='Val Loss')\n",
    "        ax1.legend()\n",
    "        ax2.plot(train_accuracies, label='Train Acc')\n",
    "        ax2.plot(val_accuracies, label='Val Acc')\n",
    "        ax2.legend()\n",
    "        plt.pause(0.1)\n",
    "\n",
    "    plt.ioff()  # Disable interactive mode\n",
    "    plt.show()\n",
    "\n",
    "def evaluate_model(model, val_loader, device):\n",
    "    model.eval()\n",
    "    total_loss, correct, total = 0.0, 0, 0\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in val_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs.view(-1, NUM_CLASSES), targets.view(-1))\n",
    "            total_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct += (predicted == targets).sum().item()\n",
    "            total += targets.size(0)\n",
    "\n",
    "    return total_loss / len(val_loader), correct / total\n",
    "\n",
    "# -----------------------------\n",
    "# 6. Main Workflow\n",
    "# -----------------------------\n",
    "def main():\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    train_pairs = [GridPair(\"task\", np.random.randint(0, 10, (30, 30)).tolist(),\n",
    "                            np.random.randint(0, 10, (30, 30)).tolist()) for _ in range(100)]\n",
    "\n",
    "    train_loader = DataLoader(AugmentedARCDataset(train_pairs), batch_size=4, shuffle=True, collate_fn=collate_fn)\n",
    "    val_loader = DataLoader(AugmentedARCDataset(train_pairs), batch_size=4, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "    model = CNNGridMapper().to(device)\n",
    "    train_model(model, train_loader, val_loader, EPOCHS, device)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36d6115-d28c-468c-b7ff-65fd97ef5fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# models/cnn_grid_mapper.py\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class CNNGridMapper(nn.Module):\n",
    "    def __init__(self, num_classes=11):\n",
    "        \"\"\"\n",
    "        Initializes the CNN model.\n",
    "\n",
    "        Args:\n",
    "            num_classes (int, optional): Number of classes per grid cell. Defaults to 11.\n",
    "        \"\"\"\n",
    "        super(CNNGridMapper, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1),  # Input channels=1\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),  # 10x10 -> 5x5\n",
    "            nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)  # 5x5 -> 2x2\n",
    "        )\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(32, 16, kernel_size=2, stride=2),  # 2x2 -> 4x4\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(16, num_classes, kernel_size=3, stride=1, padding=1),  # 4x4 -> 4x4\n",
    "            # Optionally, add another upsampling layer to reach 9x9\n",
    "            nn.Upsample(size=(9, 9), mode='bilinear', align_corners=True)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Reshape input to (batch_size, 1, 10, 10)\n",
    "        x = x.view(-1, 1, 10, 10)\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        # Flatten output to (batch_size, 81)\n",
    "        x = x.view(-1, 81)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a95bbfb-f252-48fa-9ce4-b2653a49887d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import logging\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99668d4a-e3e7-4d71-9f8b-d97f2d64f08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_grid_pairs(challenges, solutions):\n",
    "    \"\"\"\n",
    "    Extracts pairs of input and output grids from two datasets: challenges and solutions.\n",
    "\n",
    "    Args:\n",
    "        challenges (list of dict): A list of dictionaries containing input grids.\n",
    "        solutions (list of dict): A list of dictionaries containing output grids.\n",
    "\n",
    "    Returns:\n",
    "        list of tuple: A list of (input_grid, output_grid) pairs.\n",
    "    \"\"\"\n",
    "    if len(challenges) != len(solutions):\n",
    "        raise ValueError(\"The number of challenges and solutions must be equal.\")\n",
    "\n",
    "    grid_pairs = []\n",
    "\n",
    "    for challenge, solution in zip(challenges, solutions):\n",
    "        try:\n",
    "            # Ensure each dictionary contains 'input' and 'output' keys\n",
    "            input_grid = challenge.get('input')\n",
    "            output_grid = solution.get('output')\n",
    "\n",
    "            if input_grid is not None and output_grid is not None:\n",
    "                grid_pairs.append((input_grid, output_grid))\n",
    "            else:\n",
    "                print(f\"Invalid grid pair: {challenge}, {solution}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error extracting grid pair: {e}\")\n",
    "\n",
    "    return grid_pairs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7732657-814b-492c-ae7a-75302ac07167",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_arc_model(model_type='mlp', num_epochs=50, learning_rate=0.001, device='cpu'):\n",
    "    \"\"\"\n",
    "    Trains the specified model type on the ARC dataset.\n",
    "\n",
    "    Args:\n",
    "        model_type (str, optional): Type of model ('mlp' or 'cnn'). Defaults to 'mlp'.\n",
    "        num_epochs (int, optional): Number of training epochs. Defaults to 50.\n",
    "        learning_rate (float, optional): Learning rate for the optimizer. Defaults to 0.001.\n",
    "        device (str, optional): Device to train on ('cpu' or 'cuda'). Defaults to 'cpu'.\n",
    "\n",
    "    Returns:\n",
    "        nn.Module: Trained model.\n",
    "    \"\"\"\n",
    "    # Load data\n",
    "    arc_data = load_arc_data()\n",
    "    unique_id = \"007bbfb7\"  # Replace with your actual unique ID if different\n",
    "\n",
    "    train_challenges = arc_data.get(\"arc-agi_training-challenges\", [])\n",
    "    train_solutions = arc_data.get(\"arc-agi_training-solutions\", [])\n",
    "    eval_challenges = arc_data.get(\"arc-agi_evaluation-challenges\", [])\n",
    "    eval_solutions = arc_data.get(\"arc-agi_evaluation-solutions\", [])\n",
    "\n",
    "    logger.info(f\"Number of training challenges: {len(train_challenges)}\")\n",
    "    logger.info(f\"Number of training solutions: {len(train_solutions)}\")\n",
    "    logger.info(f\"Number of evaluation challenges: {len(eval_challenges)}\")\n",
    "    logger.info(f\"Number of evaluation solutions: {len(eval_solutions)}\")\n",
    "\n",
    "    # Extract grid pairs\n",
    "    train_grid_pairs = extract_grid_pairs(train_challenges, train_solutions)\n",
    "    eval_grid_pairs = extract_grid_pairs(eval_challenges, eval_solutions)\n",
    "    logger.info(f\"Number of training grid pairs: {len(train_grid_pairs)}\")\n",
    "    logger.info(f\"Number of evaluation grid pairs: {len(eval_grid_pairs)}\")\n",
    "\n",
    "    # Create DataLoaders\n",
    "    batch_size = 32\n",
    "    train_loader, test_loader = create_data_loaders(\n",
    "        train_grid_pairs,\n",
    "        eval_grid_pairs,\n",
    "        batch_size=batch_size,\n",
    "        flatten=True,\n",
    "        max_size=10,\n",
    "        padding_value=-1\n",
    "    )\n",
    "\n",
    "    logger.info(f\"Training DataLoader size: {len(train_loader)} batches\")\n",
    "    logger.info(f\"Testing DataLoader size: {len(test_loader)} batches\")\n",
    "\n",
    "    # Initialize the model\n",
    "    if model_type.lower() == 'mlp':\n",
    "        input_size = 10 * 10  # 100\n",
    "        output_size = 9 * 9  # 81\n",
    "        model = MLPGridMapper(input_size=input_size, hidden_sizes=[256, 128], output_size=output_size)\n",
    "    elif model_type.lower() == 'cnn':\n",
    "        model = CNNGridMapper(num_classes=11)  # Adjust num_classes as per your dataset\n",
    "    else:\n",
    "        logger.error(\"Invalid model type specified. Choose 'mlp' or 'cnn'.\")\n",
    "        return None\n",
    "\n",
    "    # Define the loss function and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Train the model\n",
    "    model.to(device)\n",
    "    logger.info(f\"Starting training on {device}...\")\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for batch in train_loader:\n",
    "            inputs = batch['input_grid'].to(device)\n",
    "            targets = batch['output_grid'].to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "            # Calculate accuracy\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            _, actual = torch.max(targets, 1)\n",
    "            total += targets.size(0)\n",
    "            correct += (predicted == actual).sum().item()\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        epoch_acc = correct / total\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in test_loader:\n",
    "                inputs = batch['input_grid'].to(device)\n",
    "                targets = batch['output_grid'].to(device)\n",
    "\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                _, actual = torch.max(targets, 1)\n",
    "                val_total += targets.size(0)\n",
    "                val_correct += (predicted == actual).sum().item()\n",
    "\n",
    "        avg_val_loss = val_loss / len(test_loader.dataset)\n",
    "        val_acc = val_correct / val_total\n",
    "\n",
    "        logger.info(f\"Epoch {epoch}/{num_epochs} - \"\n",
    "                    f\"Train Loss: {epoch_loss:.4f}, Train Acc: {epoch_acc:.4f} - \"\n",
    "                    f\"Val Loss: {avg_val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "    logger.info(\"Training complete.\")\n",
    "\n",
    "    # Save the trained model\n",
    "    model_filename = f\"{model_type}_grid_mapper.pth\"\n",
    "    torch.save(model.state_dict(), model_filename)\n",
    "    logger.info(f\"Model saved to {model_filename}\")\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb9b1b2-7326-4cb2-931a-ccb50bb1c736",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MLPGridMapper(nn.Module):\n",
    "    \"\"\"\n",
    "    A Multi-Layer Perceptron (MLP) model to map input grids to output grids.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_size=100, hidden_sizes=[256, 128], output_size=81):\n",
    "        super(MLPGridMapper, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_sizes[0])\n",
    "        self.fc2 = nn.Linear(hidden_sizes[0], hidden_sizes[1])\n",
    "        self.fc3 = nn.Linear(hidden_sizes[1], output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return self.fc3(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7bfa07a-5e7c-425b-ade6-33eb56f98b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model, loss function, and optimizer\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = MLPGridMapper(input_size=100, hidden_sizes=[256, 128], output_size=81).to(device)\n",
    "criterion = nn.MSELoss()  # Example loss function\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Example data (random) - replace with actual grid data\n",
    "X_train = torch.randn(100, 100).to(device)  # 100 samples, each with 100 features\n",
    "y_train = torch.randn(100, 81).to(device)   # 100 samples, each with 81 outputs\n",
    "\n",
    "# Training loop\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    output = model(X_train)\n",
    "    loss = criterion(output, y_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    print(f\"Epoch {epoch + 1}/{epochs}, Loss: {loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59ba9aa-0711-4370-b566-4a8163d0e43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model's state dictionary\n",
    "torch.save(model.state_dict(), 'mlp_grid_mapper.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736cf9b7-61c4-40ff-bb4c-71d9c8b6ecb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model again\n",
    "model = MLPGridMapper(input_size=100, hidden_sizes=[256, 128], output_size=81).to(device)\n",
    "\n",
    "# Load the model with weights_only=True\n",
    "model.load_state_dict(\n",
    "    torch.load('mlp_grid_mapper.pth', map_location=device, weights_only=True)\n",
    ")\n",
    "\n",
    "print(\"Model loaded successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2060ed4-4421-4e2e-b9ef-50da74c75e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Example test data (random data)\n",
    "X_test = torch.randn(20, 100)  # 20 samples, each with 100 features\n",
    "y_test = torch.randint(0, 81, (20, 81))  # 20 samples, each with 81 possible outputs\n",
    "\n",
    "# Create a TensorDataset and DataLoader for the test data\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "test_loader = DataLoader(test_dataset, batch_size=4, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440c8e11-973e-4e4c-8deb-b7d0d1192485",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader, device='cpu'):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in test_loader:\n",
    "            inputs = inputs.to(device)\n",
    "\n",
    "            # Convert targets to class indices if they are one-hot encoded\n",
    "            if targets.dtype != torch.long:\n",
    "                targets = torch.argmax(targets, dim=1)\n",
    "\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            total_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += targets.size(0)\n",
    "            correct += (predicted == targets).sum().item()\n",
    "\n",
    "    avg_loss = total_loss / len(test_loader.dataset)\n",
    "    accuracy = correct / total\n",
    "\n",
    "    print(f\"Test Loss: {avg_loss:.4f}, Test Accuracy: {accuracy:.4f}\")\n",
    "    return avg_loss, accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc15810-5cbb-4ee4-9d58-7fc232f93750",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualize_predictions(model, test_loader, device='cpu', num_samples=5):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    samples_visualized = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in test_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)  # Predicted class indices\n",
    "\n",
    "            for i in range(inputs.size(0)):\n",
    "                input_grid = inputs[i].cpu().numpy().reshape(10, 10)  # Input grid\n",
    "\n",
    "                # Use torch.argmax() to get the class index from targets\n",
    "                predicted_class = predicted[i].item()\n",
    "                actual_class = torch.argmax(targets[i]).item()\n",
    "\n",
    "                fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "                # Input Grid\n",
    "                axs[0].imshow(input_grid, cmap='viridis', interpolation='nearest')\n",
    "                axs[0].set_title(\"Input Grid (10x10)\")\n",
    "                axs[0].axis('off')\n",
    "\n",
    "                # Predicted and Actual Class Labels\n",
    "                axs[1].text(0.5, 0.5, f\"Predicted: {predicted_class}\\nActual: {actual_class}\",\n",
    "                            fontsize=18, ha='center', va='center')\n",
    "                axs[1].set_title(\"Class Prediction\")\n",
    "                axs[1].axis('off')\n",
    "\n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "\n",
    "                samples_visualized += 1\n",
    "                if samples_visualized >= num_samples:\n",
    "                    return\n",
    "\n",
    "# Visualize predictions\n",
    "visualize_predictions(model, test_loader, device=device, num_samples=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1ba210-96e1-4d32-9100-c6e7835972ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data/generate_and_visualize.py\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "def visualize_batch(batch):\n",
    "    \"\"\"\n",
    "    Visualizes a batch of images.\n",
    "\n",
    "    Args:\n",
    "        batch (dict): Batch containing color_image, grayscale_image, numeric_image, and grid.\n",
    "    \"\"\"\n",
    "    color_images = batch['color_image']\n",
    "    grayscale_images = batch['grayscale_image']\n",
    "    numeric_images = batch['numeric_image']\n",
    "    grids = batch['grid']\n",
    "\n",
    "    batch_size = color_images.size(0)\n",
    "    fig, axs = plt.subplots(batch_size, 3, figsize=(12, 4 * batch_size))\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        # Color Image\n",
    "        axs[i, 0].imshow(color_images[i].permute(1, 2, 0))\n",
    "        axs[i, 0].set_title(f\"Color Image\\nGrid:\\n{grids[i].numpy()}\")\n",
    "        axs[i, 0].axis('off')\n",
    "\n",
    "        # Grayscale Image\n",
    "        axs[i, 1].imshow(grayscale_images[i].squeeze(), cmap='gray')\n",
    "        axs[i, 1].set_title(\"Grayscale Image\")\n",
    "        axs[i, 1].axis('off')\n",
    "\n",
    "        # Numeric Image\n",
    "        axs[i, 2].imshow(numeric_images[i].permute(1, 2, 0))\n",
    "        axs[i, 2].set_title(\"Numeric Image\")\n",
    "        axs[i, 2].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def main():\n",
    "    train_loader, eval_loader = get_data_loaders(batch_size=4, grid_size=10, num_classes=11, augment=True)\n",
    "\n",
    "    # Get a batch of training data\n",
    "    batch = next(iter(train_loader))\n",
    "\n",
    "    # Visualize the batch\n",
    "    visualize_batch(batch)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04dcce3e-0e37-425e-a8b1-c9f03fcfb705",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data/data_conversion.py (continued)\n",
    "\n",
    "import pickle\n",
    "\n",
    "def save_datasets(train_grids, eval_grids, filepath='data/grids.pkl'):\n",
    "    \"\"\"\n",
    "    Saves the training and evaluation grids to a pickle file.\n",
    "\n",
    "    Args:\n",
    "        train_grids (list of np.ndarray): Training grids.\n",
    "        eval_grids (list of np.ndarray): Evaluation grids.\n",
    "        filepath (str, optional): Path to save the pickle file. Defaults to 'data/grids.pkl'.\n",
    "    \"\"\"\n",
    "    with open(filepath, 'wb') as f:\n",
    "        pickle.dump({'train_grids': train_grids, 'eval_grids': eval_grids}, f)\n",
    "    logger.info(f\"Saved grids to {filepath}.\")\n",
    "\n",
    "\n",
    "def load_datasets(filepath='data/grids.pkl'):\n",
    "    \"\"\"\n",
    "    Loads the training and evaluation grids from a pickle file.\n",
    "\n",
    "    Args:\n",
    "        filepath (str, optional): Path to the pickle file. Defaults to 'data/grids.pkl'.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (train_grids, eval_grids)\n",
    "    \"\"\"\n",
    "    if not os.path.exists(filepath):\n",
    "        logger.error(f\"File {filepath} does not exist.\")\n",
    "        return None, None\n",
    "\n",
    "    with open(filepath, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    logger.info(f\"Loaded grids from {filepath}.\")\n",
    "    return data['train_grids'], data['eval_grids']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d518c9-9d0a-43ec-b1cf-87834e72dbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training/trainer.py\n",
    "\n",
    "# ==========================\n",
    "# 1. Standard Library Imports\n",
    "# ==========================\n",
    "import logging\n",
    "\n",
    "# ==========================\n",
    "# 2. Third-Party Library Imports\n",
    "# ==========================\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "\n",
    "# ==========================\n",
    "# 3. Local Application/Module Imports\n",
    "# ==========================\n",
    "\n",
    "def train_regular_model(\n",
    "    model, train_loader, eval_loader, num_epochs, initial_lr, gui, model_num, \n",
    "    total_models, device, tuner, shared_layer=None, redis_manager=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Trains a single model over a specified number of epochs.\n",
    "    \"\"\"\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=initial_lr, weight_decay=1e-4)\n",
    "    scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3, verbose=True)\n",
    "    criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "    scaler = GradScaler() if torch.cuda.is_available() else None\n",
    "\n",
    "    best_val_loss, best_val_accuracy = float('inf'), 0.0\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        model.train()\n",
    "\n",
    "        total_loss, correct_predictions, total_samples = 0, 0, 0\n",
    "\n",
    "        for batch_idx, (inputs, labels) in enumerate(train_loader):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            if shared_layer:\n",
    "                inputs = shared_layer(inputs)\n",
    "\n",
    "            try:\n",
    "                with autocast(enabled=torch.cuda.is_available()):\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, labels) / 4\n",
    "\n",
    "                scaler.scale(loss).backward() if scaler else loss.backward()\n",
    "\n",
    "                if (batch_idx + 1) % 4 == 0:\n",
    "                    if scaler:\n",
    "                        scaler.step(optimizer)\n",
    "                        scaler.update()\n",
    "                    else:\n",
    "                        optimizer.step()\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                total_loss += loss.item() * 4\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                correct_predictions += (predicted == labels).sum().item()\n",
    "                total_samples += labels.size(0)\n",
    "\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Error in batch {batch_idx}: {e}\")\n",
    "                continue\n",
    "\n",
    "        avg_train_loss = total_loss / len(train_loader)\n",
    "        train_accuracy = correct_predictions / total_samples\n",
    "\n",
    "        val_loss, val_accuracy = evaluate_model(model, eval_loader, criterion, device)\n",
    "\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        # Use Hyperparameter Tuner to adjust learning rate\n",
    "        if tuner:\n",
    "            tuner.adjust_learning_rate(optimizer, val_loss)\n",
    "            if tuner.early_stopping():\n",
    "                logging.info(\"Early stopping triggered by HyperparameterTuner.\")\n",
    "                break\n",
    "\n",
    "        # Update Redis with current metrics\n",
    "        if redis_manager:\n",
    "            current_metrics = {\n",
    "                'model_num': model_num,\n",
    "                'total_models': total_models,\n",
    "                'epoch': epoch,\n",
    "                'total_epochs': num_epochs,\n",
    "                'loss': avg_train_loss,\n",
    "                'accuracy': train_accuracy,\n",
    "                'val_loss': val_loss,\n",
    "                'val_accuracy': val_accuracy,\n",
    "                'lr': optimizer.param_groups[0]['lr']\n",
    "            }\n",
    "            redis_manager.set_value('current_metrics', current_metrics)\n",
    "\n",
    "        gui.queue.put({\n",
    "            'type': 'epoch',\n",
    "            'model_num': model_num,\n",
    "            'total_models': total_models,\n",
    "            'epoch': epoch,\n",
    "            'total_epochs': num_epochs,\n",
    "            'loss': avg_train_loss,\n",
    "            'accuracy': train_accuracy,\n",
    "            'val_loss': val_loss,\n",
    "            'val_accuracy': val_accuracy,\n",
    "            'lr': optimizer.param_groups[0]['lr']\n",
    "        })\n",
    "\n",
    "    return model, None\n",
    "\n",
    "def evaluate_model(model, eval_loader, criterion, device):\n",
    "    \"\"\"\n",
    "    Evaluates the model on the evaluation dataset.\n",
    "    \n",
    "    Args:\n",
    "        model (nn.Module): The trained model.\n",
    "        eval_loader (DataLoader): DataLoader for evaluation data.\n",
    "        criterion (nn.Module): Loss function.\n",
    "        device (torch.device): Device to perform computation on.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (average_loss, accuracy)\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    total_loss, correct_predictions, total_samples = 0, 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in eval_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct_predictions += (predicted == labels).sum().item()\n",
    "            total_samples += labels.size(0)\n",
    "\n",
    "    avg_loss = total_loss / len(eval_loader)\n",
    "    accuracy = correct_predictions / total_samples\n",
    "\n",
    "    return avg_loss, accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9f9dff-29a6-445c-a924-b1ec899f82bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training/trainer.py (excerpt)\n",
    "\n",
    "from data.data_conversion import get_data_loaders_variable_sizes\n",
    "from models import MLPMagician, CNNMagician  # Import necessary models\n",
    "from torch import nn, optim\n",
    "\n",
    "def main_training():\n",
    "    # Parameters\n",
    "    batch_size = 32\n",
    "    grid_sizes = [3, 5, 10]\n",
    "    num_classes = 11\n",
    "    augment = True\n",
    "    num_models = 6\n",
    "    num_epochs = 50\n",
    "    initial_lr = 0.001\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Create data loaders\n",
    "    train_loader, eval_loader = get_data_loaders_variable_sizes(\n",
    "        batch_size=batch_size,\n",
    "        grid_sizes=grid_sizes,\n",
    "        num_classes=num_classes,\n",
    "        augment=augment\n",
    "    )\n",
    "\n",
    "    # Initialize models, optimizers, loss functions, etc.\n",
    "    models = []\n",
    "    for i in range(num_models):\n",
    "        model = MLPMagician(input_size=grid_sizes[-1]**2, hidden_sizes=[256, 128, 64], dropout_rate=0.5)\n",
    "        model.to(device)\n",
    "        models.append(model)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizers = [optim.AdamW(model.parameters(), lr=initial_lr, weight_decay=1e-4) for model in models]\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        for model, optimizer in zip(models, optimizers):\n",
    "            model.train()\n",
    "            running_loss = 0.0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "\n",
    "            for batch in train_loader:\n",
    "                inputs = batch['color_image'].to(device)\n",
    "                targets = batch['grid'].to(device).view(-1)  # Flatten targets\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += targets.size(0)\n",
    "                correct += (predicted == targets).sum().item()\n",
    "\n",
    "            epoch_loss = running_loss / len(train_loader.dataset)\n",
    "            epoch_acc = correct / total\n",
    "            logger.info(f\"Model {model.__class__.__name__} - Epoch {epoch}/{num_epochs} - Loss: {epoch_loss:.4f} - Accuracy: {epoch_acc:.4f}\")\n",
    "\n",
    "        # Evaluation at the end of each epoch\n",
    "        for model in models:\n",
    "            model.eval()\n",
    "            val_loss = 0.0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for batch in eval_loader:\n",
    "                    inputs = batch['color_image'].to(device)\n",
    "                    targets = batch['grid'].to(device).view(-1)\n",
    "\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, targets)\n",
    "                    val_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "                    _, predicted = torch.max(outputs.data, 1)\n",
    "                    total += targets.size(0)\n",
    "                    correct += (predicted == targets).sum().item()\n",
    "\n",
    "            avg_val_loss = val_loss / len(eval_loader.dataset)\n",
    "            val_accuracy = correct / total\n",
    "            logger.info(f\"Model {model.__class__.__name__} - Validation Loss: {avg_val_loss:.4f} - Validation Accuracy: {val_accuracy:.4f}\")\n",
    "\n",
    "    logger.info(\"Training completed.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main_training()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0bcb53-fa0a-4da1-993e-bb724de0be34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# models/mlp_magician.py\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import logging\n",
    "\n",
    "class MLPMagician(nn.Module):\n",
    "    def __init__(self, input_size, hidden_sizes, dropout_rate=0.5, num_classes=10):\n",
    "        \"\"\"\n",
    "        Initializes the MLPMagician model.\n",
    "\n",
    "        Args:\n",
    "            input_size (int): Number of input features.\n",
    "            hidden_sizes (list): List containing the number of neurons in each hidden layer.\n",
    "            dropout_rate (float): Dropout rate for regularization.\n",
    "            num_classes (int): Number of output classes.\n",
    "        \"\"\"\n",
    "        super(MLPMagician, self).__init__()\n",
    "        layers = []\n",
    "        prev_size = input_size\n",
    "        for idx, hidden_size in enumerate(hidden_sizes):\n",
    "            layers.append(nn.Linear(prev_size, hidden_size))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.Dropout(dropout_rate))\n",
    "            prev_size = hidden_size\n",
    "        layers.append(nn.Linear(prev_size, num_classes))\n",
    "        self.network = nn.Sequential(*layers)\n",
    "        \n",
    "        # Initialize weights\n",
    "        initialize_weights(self)\n",
    "        logging.info(\"Initialized MLPMagician model with layers: {}\".format(self.network))\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass of the model.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor of shape (batch_size, input_size).\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Output predictions of shape (batch_size, num_classes).\n",
    "        \"\"\"\n",
    "        return self.network(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59810f1e-3399-46fd-9ca0-1e5df112230e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data/test_data_conversion.py\n",
    "\n",
    "import unittest\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "class TestDataConversion(unittest.TestCase):\n",
    "    def setUp(self):\n",
    "        self.grid = np.array([\n",
    "            [0, 1, 2],\n",
    "            [3, 4, 5],\n",
    "            [6, 7, 8]\n",
    "        ])\n",
    "        self.color_map = {\n",
    "            0: [0, 0, 0],\n",
    "            1: [255, 0, 0],\n",
    "            2: [0, 255, 0],\n",
    "            3: [0, 0, 255],\n",
    "            4: [255, 255, 0],\n",
    "            5: [255, 165, 0],\n",
    "            6: [128, 0, 128],\n",
    "            7: [0, 255, 255],\n",
    "            8: [255, 192, 203],\n",
    "        }\n",
    "\n",
    "    def test_grid_to_image(self):\n",
    "        img = grid_to_image(self.grid, self.color_map)\n",
    "        self.assertIsInstance(img, Image.Image)\n",
    "        self.assertEqual(img.size, (3, 3))\n",
    "        pixels = img.load()\n",
    "        self.assertEqual(pixels[0, 0], (0, 0, 0))          # Black\n",
    "        self.assertEqual(pixels[1, 0], (255, 0, 0))        # Red\n",
    "        self.assertEqual(pixels[2, 0], (0, 255, 0))        # Green\n",
    "\n",
    "    def test_grid_to_grayscale(self):\n",
    "        img = grid_to_grayscale(self.grid)\n",
    "        self.assertIsInstance(img, Image.Image)\n",
    "        self.assertEqual(img.mode, 'L')                     # Grayscale\n",
    "        self.assertEqual(img.size, (3, 3))\n",
    "        pixels = img.load()\n",
    "        self.assertEqual(pixels[0, 0], 0)                   # Minimum value normalized to 0\n",
    "        self.assertEqual(pixels[1, 1], 127)                 # Mid value\n",
    "\n",
    "    def test_grid_to_numeric_image(self):\n",
    "        img = grid_to_numeric_image(self.grid)\n",
    "        self.assertIsInstance(img, Image.Image)\n",
    "        self.assertEqual(img.mode, 'RGB')\n",
    "        self.assertEqual(img.size, (150, 150))               # 3x3 grid with cell_size=50\n",
    "        pixels = img.load()\n",
    "        self.assertEqual(pixels[25, 25], (255, 0, 0))        # Number 1 in red cell\n",
    "        self.assertEqual(pixels[75, 75], (255, 255, 0))      # Number 4 in yellow cell\n",
    "\n",
    "    def test_augment_image(self):\n",
    "        img = grid_to_image(self.grid, self.color_map)\n",
    "        augmented_img, dead_squares = augment_image(img, self.grid, perturb_prob=0.0, dead_square_prob=1.0, noise_prob=0.0)\n",
    "        self.assertEqual(len(dead_squares), 1)               # Only one dead square expected\n",
    "        self.assertIsInstance(augmented_img, Image.Image)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    unittest.main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae5062f-51cd-4bf1-9c73-06b5697a28cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data/data_conversion.py (continued)\n",
    "\n",
    "def generate_grids_variable_sizes(num_grids_per_size, grid_sizes, num_classes):\n",
    "    \"\"\"\n",
    "    Generates grids of multiple sizes.\n",
    "\n",
    "    Args:\n",
    "        num_grids_per_size (int): Number of grids per size.\n",
    "        grid_sizes (list of int): List of grid sizes (e.g., [3, 5, 10]).\n",
    "        num_classes (int): Number of classes/colors.\n",
    "\n",
    "    Returns:\n",
    "        list of np.ndarray: Generated grids.\n",
    "    \"\"\"\n",
    "    grids = []\n",
    "    for size in grid_sizes:\n",
    "        grids.extend(generate_grids(num_grids=num_grids_per_size, grid_size=size, num_classes=num_classes))\n",
    "    logger.info(f\"Generated {len(grids)} grids of varying sizes: {grid_sizes}.\")\n",
    "    return grids\n",
    "\n",
    "\n",
    "def get_data_loaders_variable_sizes(batch_size=32, grid_sizes=[3, 5, 10], num_classes=11, augment=True):\n",
    "    \"\"\"\n",
    "    Creates DataLoader instances for training and evaluation with variable grid sizes.\n",
    "\n",
    "    Args:\n",
    "        batch_size (int, optional): Number of samples per batch. Defaults to 32.\n",
    "        grid_sizes (list of int, optional): List of grid sizes. Defaults to [3, 5, 10].\n",
    "        num_classes (int, optional): Number of classes/colors. Defaults to 11.\n",
    "        augment (bool, optional): Whether to apply data augmentation. Defaults to True.\n",
    "\n",
    "    Returns:\n",
    "        DataLoader: Training DataLoader.\n",
    "        DataLoader: Evaluation DataLoader.\n",
    "    \"\"\"\n",
    "    # Generate grids for training and evaluation\n",
    "    train_grids = generate_grids_variable_sizes(num_grids_per_size=1000, grid_sizes=grid_sizes, num_classes=num_classes)\n",
    "    eval_grids = generate_grids_variable_sizes(num_grids_per_size=200, grid_sizes=grid_sizes, num_classes=num_classes)\n",
    "\n",
    "    # Define transformations\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((256, 256)),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "\n",
    "    # Create datasets\n",
    "    train_dataset = GridDataset(train_grids, transform=transform, augmentation=augment)\n",
    "    eval_dataset = GridDataset(eval_grids, transform=transform, augmentation=False)\n",
    "\n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "    eval_loader = DataLoader(eval_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "    logger.info(\"Created training and evaluation DataLoaders with variable grid sizes.\")\n",
    "    return train_loader, eval_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b86de8-5763-43d0-9476-7bbdfb7cb1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# models/cnn_magician.py\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from utils.weight_initialization import initialize_weights\n",
    "import logging\n",
    "\n",
    "class CNNMagician(nn.Module):\n",
    "    def __init__(self, dropout_rate=0.5, num_classes=10):\n",
    "        \"\"\"\n",
    "        Initializes the CNNMagician model.\n",
    "\n",
    "        Args:\n",
    "            dropout_rate (float): Dropout rate for regularization.\n",
    "            num_classes (int): Number of output classes.\n",
    "        \"\"\"\n",
    "        super(CNNMagician, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)  # Assuming grayscale input\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.fc1 = nn.Linear(128 * 3 * 3, 128)  # Adjust based on input size\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        \n",
    "        # Initialize weights\n",
    "        initialize_weights(self)\n",
    "        logging.info(\"Initialized CNNMagician model with layers.\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass of the model.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor of shape (batch_size, 1, 28, 28).\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Output predictions of shape (batch_size, num_classes).\n",
    "        \"\"\"\n",
    "        x = self.pool(F.relu(self.bn1(self.conv1(x))))  # [32, H/2, W/2]\n",
    "        x = self.pool(F.relu(self.bn2(self.conv2(x))))  # [64, H/4, W/4]\n",
    "        x = self.pool(F.relu(self.bn3(self.conv3(x))))  # [128, H/8, W/8]\n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        return self.fc2(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72f429b-6e98-4f3a-a892-6512dac0b3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# models/resnet_magician.py\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import logging\n",
    "\n",
    "class ResNetBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        \"\"\"\n",
    "        Initializes a single ResNet block.\n",
    "\n",
    "        Args:\n",
    "            in_channels (int): Number of input channels.\n",
    "            out_channels (int): Number of output channels.\n",
    "            stride (int): Stride for the convolution.\n",
    "        \"\"\"\n",
    "        super(ResNetBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "        self.downsample = None\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.downsample = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass of the ResNet block.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Output tensor after residual connection.\n",
    "        \"\"\"\n",
    "        identity = x\n",
    "        out = self.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        if self.downsample:\n",
    "            identity = self.downsample(x)\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "class ResNetMagician(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        \"\"\"\n",
    "        Initializes the ResNetMagician model.\n",
    "\n",
    "        Args:\n",
    "            num_classes (int): Number of output classes.\n",
    "        \"\"\"\n",
    "        super(ResNetMagician, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3)  # Assuming grayscale input\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        \n",
    "        # Define ResNet layers\n",
    "        self.layer1 = self._make_layer(64, 64, blocks=2, stride=1)\n",
    "        self.layer2 = self._make_layer(64, 128, blocks=2, stride=2)\n",
    "        self.layer3 = self._make_layer(128, 256, blocks=2, stride=2)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(256, num_classes)\n",
    "        \n",
    "        # Initialize weights\n",
    "        initialize_weights(self)\n",
    "        logging.info(\"Initialized ResNetMagician model with layers.\")\n",
    "\n",
    "    def _make_layer(self, in_channels, out_channels, blocks, stride):\n",
    "        \"\"\"\n",
    "        Creates a ResNet layer composed of multiple ResNet blocks.\n",
    "\n",
    "        Args:\n",
    "            in_channels (int): Number of input channels.\n",
    "            out_channels (int): Number of output channels.\n",
    "            blocks (int): Number of ResNet blocks.\n",
    "            stride (int): Stride for the first block.\n",
    "\n",
    "        Returns:\n",
    "            nn.Sequential: Sequential container of ResNet blocks.\n",
    "        \"\"\"\n",
    "        layers = []\n",
    "        layers.append(ResNetBlock(in_channels, out_channels, stride))\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(ResNetBlock(out_channels, out_channels))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass of the ResNetMagician model.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor of shape (batch_size, 1, 224, 224).\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Output predictions of shape (batch_size, num_classes).\n",
    "        \"\"\"\n",
    "        x = self.relu(self.bn1(self.conv1(x)))  # [64, H/2, W/2]\n",
    "        x = self.maxpool(x)  # [64, H/4, W/4]\n",
    "        \n",
    "        x = self.layer1(x)  # [64, H/4, W/4]\n",
    "        x = self.layer2(x)  # [128, H/8, W/8]\n",
    "        x = self.layer3(x)  # [256, H/16, W/16]\n",
    "        \n",
    "        x = self.avgpool(x)  # [256, 1, 1]\n",
    "        x = torch.flatten(x, 1)  # [256]\n",
    "        x = self.fc(x)  # [num_classes]\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a91c10e-6114-4ebf-ab29-3d7c5e38deab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# models/vision_transformer_magician.py\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.models import vit_b_16\n",
    "import logging\n",
    "\n",
    "class VisionTransformerMagician(nn.Module):\n",
    "    def __init__(self, num_classes=10, pretrained=True):\n",
    "        \"\"\"\n",
    "        Initializes the VisionTransformerMagician model.\n",
    "\n",
    "        Args:\n",
    "            num_classes (int): Number of output classes.\n",
    "            pretrained (bool): Whether to use a pre-trained ViT model.\n",
    "        \"\"\"\n",
    "        super(VisionTransformerMagician, self).__init__()\n",
    "        self.vit = vit_b_16(pretrained=pretrained)\n",
    "        # Replace the classification head\n",
    "        self.vit.heads = nn.Linear(self.vit.heads.in_features, num_classes)\n",
    "        \n",
    "        # Initialize weights of the new head\n",
    "        initialize_weights(self.vit.heads)\n",
    "        logging.info(\"Initialized VisionTransformerMagician model with ViT backbone.\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass of the VisionTransformerMagician model.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor of shape (batch_size, 3, 224, 224).\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Output predictions of shape (batch_size, num_classes).\n",
    "        \"\"\"\n",
    "        return self.vit(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a359d1-f4bb-45f1-87d1-ea438b3b13a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# models/dnn_magician.py\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import logging\n",
    "\n",
    "class DNNMagician(nn.Module):\n",
    "    def __init__(self, input_size, hidden_sizes, dropout_rate=0.5, num_classes=10):\n",
    "        \"\"\"\n",
    "        Initializes the DNNMagician model.\n",
    "\n",
    "        Args:\n",
    "            input_size (int): Number of input features.\n",
    "            hidden_sizes (list): List containing the number of neurons in each hidden layer.\n",
    "            dropout_rate (float): Dropout rate for regularization.\n",
    "            num_classes (int): Number of output classes.\n",
    "        \"\"\"\n",
    "        super(DNNMagician, self).__init__()\n",
    "        layers = []\n",
    "        prev_size = input_size\n",
    "        for idx, hidden_size in enumerate(hidden_sizes):\n",
    "            layers.append(nn.Linear(prev_size, hidden_size))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.Dropout(dropout_rate))\n",
    "            prev_size = hidden_size\n",
    "        layers.append(nn.Linear(prev_size, num_classes))\n",
    "        self.network = nn.Sequential(*layers)\n",
    "        \n",
    "        # Initialize weights\n",
    "        initialize_weights(self)\n",
    "        logging.info(\"Initialized DNNMagician model with layers: {}\".format(self.network))\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass of the model.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor of shape (batch_size, input_size).\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Output predictions of shape (batch_size, num_classes).\n",
    "        \"\"\"\n",
    "        return self.network(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f959310c-9353-4207-9438-2b143ed4eacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# models/rnn_magician.py\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import logging\n",
    "\n",
    "class RNNMagician(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size, dropout_rate=0.3):\n",
    "        \"\"\"\n",
    "        Initializes the RNNMagician model.\n",
    "\n",
    "        Args:\n",
    "            input_size (int): Number of input features per time step.\n",
    "            hidden_size (int): Number of features in the hidden state.\n",
    "            num_layers (int): Number of recurrent layers.\n",
    "            output_size (int): Number of output classes.\n",
    "            dropout_rate (float): Dropout rate for regularization.\n",
    "        \"\"\"\n",
    "        super(RNNMagician, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, dropout=dropout_rate)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "        # Initialize weights\n",
    "        initialize_weights(self)\n",
    "        logging.info(\"Initialized RNNMagician model with LSTM layers.\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass of the RNNMagician model.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor of shape (batch_size, sequence_length, input_size).\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Output predictions of shape (batch_size, output_size).\n",
    "        \"\"\"\n",
    "        out, _ = self.lstm(x)  # out: (batch_size, sequence_length, hidden_size)\n",
    "        out = out[:, -1, :]    # Take the last time step\n",
    "        out = self.fc(out)     # (batch_size, output_size)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466ff08d-c912-4a55-a219-868d398cc2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils/logging_setup.py\n",
    "\n",
    "import logging\n",
    "import os\n",
    "\n",
    "def initialize_logging(log_file='logs/training.log', log_level=logging.INFO):\n",
    "    \"\"\"\n",
    "    Initializes the logging configuration.\n",
    "\n",
    "    Args:\n",
    "        log_file (str): Path to the log file.\n",
    "        log_level (int): Logging level (e.g., logging.INFO, logging.DEBUG).\n",
    "    \"\"\"\n",
    "    # Create logs directory if it doesn't exist\n",
    "    os.makedirs(os.path.dirname(log_file), exist_ok=True)\n",
    "    \n",
    "    # Define logging format\n",
    "    log_format = '%(asctime)s [%(levelname)s] %(message)s'\n",
    "    \n",
    "    # Configure logging\n",
    "    logging.basicConfig(\n",
    "        level=log_level,\n",
    "        format=log_format,\n",
    "        handlers=[\n",
    "            logging.FileHandler(log_file),\n",
    "            logging.StreamHandler()\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    logging.info(\"Logging is initialized.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232ac365-8bb6-4de4-bea4-1fc6090093ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils/redis_manager.py\n",
    "\n",
    "import redis\n",
    "import json\n",
    "import logging\n",
    "\n",
    "class RedisManager:\n",
    "    \"\"\"\n",
    "    Manages connections and interactions with Redis for shared memory.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, host='localhost', port=6379, db=0):\n",
    "        \"\"\"\n",
    "        Initializes the RedisManager by establishing a connection to the Redis server.\n",
    "\n",
    "        Args:\n",
    "            host (str): Redis server hostname.\n",
    "            port (int): Redis server port.\n",
    "            db (int): Redis database index.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.redis = redis.Redis(host=host, port=port, db=db)\n",
    "            # Test the connection\n",
    "            self.redis.ping()\n",
    "            logging.info(f\"Connected to Redis at {host}:{port}, DB: {db}\")\n",
    "        except redis.exceptions.ConnectionError as e:\n",
    "            logging.error(f\"Redis connection error: {e}\")\n",
    "            raise e\n",
    "\n",
    "    def set_value(self, key, value):\n",
    "        \"\"\"\n",
    "        Sets a value in Redis after serializing it to JSON.\n",
    "\n",
    "        Args:\n",
    "            key (str): The key under which the value is stored.\n",
    "            value (any): The value to store (must be JSON serializable).\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.redis.set(key, json.dumps(value))\n",
    "            logging.debug(f\"Set key '{key}' in Redis.\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error setting key '{key}' in Redis: {e}\")\n",
    "\n",
    "    def get_value(self, key):\n",
    "        \"\"\"\n",
    "        Retrieves a value from Redis and deserializes it from JSON.\n",
    "\n",
    "        Args:\n",
    "            key (str): The key to retrieve.\n",
    "\n",
    "        Returns:\n",
    "            any: The deserialized value, or None if the key does not exist.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            value = self.redis.get(key)\n",
    "            if value:\n",
    "                logging.debug(f\"Retrieved key '{key}' from Redis.\")\n",
    "                return json.loads(value)\n",
    "            else:\n",
    "                logging.debug(f\"Key '{key}' not found in Redis.\")\n",
    "                return None\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error retrieving key '{key}' from Redis: {e}\")\n",
    "            return None\n",
    "\n",
    "    def delete_key(self, key):\n",
    "        \"\"\"\n",
    "        Deletes a key from Redis.\n",
    "\n",
    "        Args:\n",
    "            key (str): The key to delete.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.redis.delete(key)\n",
    "            logging.debug(f\"Deleted key '{key}' from Redis.\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error deleting key '{key}' from Redis: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b0fb45-71d8-4321-9b3e-8abe7fb45eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils/plot_utils.py\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg\n",
    "import logging\n",
    "\n",
    "def plot_training_metrics(gui, loss_data, val_loss_data, acc_data, val_acc_data):\n",
    "    \"\"\"\n",
    "    Plots training and validation metrics in the GUI.\n",
    "\n",
    "    Args:\n",
    "        gui (TrainingGUI): Instance of the TrainingGUI.\n",
    "        loss_data (list): List of training loss values.\n",
    "        val_loss_data (list): List of validation loss values.\n",
    "        acc_data (list): List of training accuracy values.\n",
    "        val_acc_data (list): List of validation accuracy values.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        gui.ax.clear()\n",
    "        gui.ax.plot(range(1, len(loss_data)+1), loss_data, label='Training Loss', color='blue')\n",
    "        gui.ax.plot(range(1, len(val_loss_data)+1), val_loss_data, label='Validation Loss', color='orange')\n",
    "        gui.ax.plot(range(1, len(acc_data)+1), acc_data, label='Training Accuracy', color='green')\n",
    "        gui.ax.plot(range(1, len(val_acc_data)+1), val_acc_data, label='Validation Accuracy', color='red')\n",
    "        gui.ax.set_xlabel('Epochs')\n",
    "        gui.ax.set_ylabel('Metrics')\n",
    "        gui.ax.legend()\n",
    "        gui.ax.grid(True)\n",
    "        gui.canvas.draw()\n",
    "        logging.info(\"Updated training metrics plot.\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error plotting training metrics: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426975e7-af4b-4173-a28d-e0efb78b0c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils/weight_initialization.py\n",
    "\n",
    "import torch.nn as nn\n",
    "import logging\n",
    "\n",
    "def initialize_weights(model):\n",
    "    \"\"\"\n",
    "    Initializes weights of the model using Kaiming initialization for Conv layers\n",
    "    and Xavier initialization for Linear layers. BatchNorm layers are initialized\n",
    "    with constant weights and biases.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): The model to initialize.\n",
    "    \"\"\"\n",
    "    for m in model.modules():\n",
    "        if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n",
    "            nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            if m.bias is not None:\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            logging.debug(f\"Initialized Conv layer: {m}\")\n",
    "        elif isinstance(m, nn.Linear):\n",
    "            nn.init.xavier_normal_(m.weight)\n",
    "            if m.bias is not None:\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            logging.debug(f\"Initialized Linear layer: {m}\")\n",
    "        elif isinstance(m, (nn.BatchNorm1d, nn.BatchNorm2d)):\n",
    "            nn.init.constant_(m.weight, 1)\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "            logging.debug(f\"Initialized BatchNorm layer: {m}\")\n",
    "        elif isinstance(m, nn.LSTM):\n",
    "            for name, param in m.named_parameters():\n",
    "                if 'weight' in name:\n",
    "                    nn.init.xavier_normal_(param.data)\n",
    "                elif 'bias' in name:\n",
    "                    nn.init.constant_(param.data, 0)\n",
    "            logging.debug(f\"Initialized LSTM layer: {m}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559b24b9-42ab-40b4-a23d-a2dc0c76dc62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils/hyperparameter_tuner.py\n",
    "\n",
    "import logging\n",
    "\n",
    "class HyperparameterTuner:\n",
    "    \"\"\"\n",
    "    Adjusts hyperparameters like learning rate based on training progress.\n",
    "    Implements a simple strategy; can be expanded with reinforcement learning.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, initial_lr, factor=0.5, patience=3, min_lr=1e-6):\n",
    "        \"\"\"\n",
    "        Initializes the HyperparameterTuner.\n",
    "\n",
    "        Args:\n",
    "            initial_lr (float): Initial learning rate.\n",
    "            factor (float): Factor by which to reduce the learning rate.\n",
    "            patience (int): Number of epochs to wait before reducing LR.\n",
    "            min_lr (float): Minimum learning rate.\n",
    "        \"\"\"\n",
    "        self.initial_lr = initial_lr\n",
    "        self.factor = factor\n",
    "        self.patience = patience\n",
    "        self.min_lr = min_lr\n",
    "        self.best_loss = float('inf')\n",
    "        self.counter = 0\n",
    "        logging.info(\"Initialized HyperparameterTuner.\")\n",
    "\n",
    "    def adjust_learning_rate(self, optimizer, current_loss):\n",
    "        \"\"\"\n",
    "        Adjusts the learning rate based on current loss.\n",
    "\n",
    "        Args:\n",
    "            optimizer (torch.optim.Optimizer): Optimizer whose LR is to be adjusted.\n",
    "            current_loss (float): Current validation loss.\n",
    "        \"\"\"\n",
    "        if current_loss < self.best_loss:\n",
    "            self.best_loss = current_loss\n",
    "            self.counter = 0\n",
    "            logging.debug(\"Validation loss improved; resetting patience counter.\")\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            logging.debug(f\"No improvement in validation loss. Counter: {self.counter}/{self.patience}\")\n",
    "            if self.counter >= self.patience:\n",
    "                for param_group in optimizer.param_groups:\n",
    "                    new_lr = max(param_group['lr'] * self.factor, self.min_lr)\n",
    "                    if param_group['lr'] > self.min_lr:\n",
    "                        param_group['lr'] = new_lr\n",
    "                        logging.info(f\"Reducing learning rate to {new_lr}.\")\n",
    "                self.counter = 0  # Reset counter after adjusting\n",
    "\n",
    "    def early_stopping(self):\n",
    "        \"\"\"\n",
    "        Determines whether to perform early stopping.\n",
    "\n",
    "        Returns:\n",
    "            bool: True if early stopping criteria met, False otherwise.\n",
    "        \"\"\"\n",
    "        # Placeholder for actual early stopping logic\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b351e9ab-e843-4e1d-9d14-428e4b960250",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils/hyperparameter_helper.py\n",
    "\n",
    "import random\n",
    "import logging\n",
    "\n",
    "def randomize_params():\n",
    "    \"\"\"\n",
    "    Randomizes hyperparameters for model training.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (num_models, num_epochs, initial_lr, other_params)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        num_models = random.randint(5, 15)  # Example range\n",
    "        num_epochs = random.randint(50, 200)\n",
    "        initial_lr = random.choice([0.1, 0.01, 0.001, 0.0001])\n",
    "        other_params = {}  # Add other hyperparameters as needed\n",
    "        logging.info(f\"Randomized hyperparameters: num_models={num_models}, num_epochs={num_epochs}, initial_lr={initial_lr}\")\n",
    "        return num_models, num_epochs, initial_lr, other_params\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error randomizing parameters: {e}\")\n",
    "        return 10, 100, 0.001, {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f95c06a-3896-4c21-a825-33b13b04d85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gui/training_gui.py\n",
    "\n",
    "import tkinter as tk\n",
    "from tkinter import ttk, messagebox\n",
    "import queue\n",
    "from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "\n",
    "\n",
    "class TrainingGUI:\n",
    "    \"\"\"\n",
    "    A Tkinter-based GUI that displays real-time training progress, including model metrics,\n",
    "    learning rate adjustments, ensemble accuracy, and allows querying the LLM for explanations.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, root, total_models, total_epochs, redis_manager, llm):\n",
    "        \"\"\"\n",
    "        Initializes the TrainingGUI.\n",
    "\n",
    "        Args:\n",
    "            root (tk.Tk): The root Tkinter window.\n",
    "            total_models (int): Total number of models to train.\n",
    "            total_epochs (int): Total number of epochs per model.\n",
    "            redis_manager (RedisManager): Instance for interacting with Redis.\n",
    "            llm (StrategyLLM): Instance of the language model for generating explanations.\n",
    "        \"\"\"\n",
    "        self.root = root\n",
    "        self.queue = queue.Queue()\n",
    "        self.redis_manager = redis_manager\n",
    "        self.llm = llm\n",
    "        self.root.title(\"Model Training Progress Tracker\")\n",
    "\n",
    "        # Initialize GUI Components\n",
    "        self._init_labels(total_models, total_epochs)\n",
    "        self._init_progress_bar()\n",
    "        self._init_plots()\n",
    "        self._init_ensemble_accuracy()\n",
    "        self._init_query_section()\n",
    "\n",
    "        # Start real-time queue processing\n",
    "        self.root.after(100, self.process_queue)\n",
    "\n",
    "    def _init_labels(self, total_models, total_epochs):\n",
    "        \"\"\"Initialize the labels to display real-time metrics.\"\"\"\n",
    "        self.model_label = tk.Label(self.root, text=f\"Training Model: 0/{total_models}\", font=(\"Helvetica\", 14))\n",
    "        self.model_label.pack(pady=5)\n",
    "\n",
    "        self.epoch_label = tk.Label(self.root, text=f\"Epoch: 0/{total_epochs}\", font=(\"Helvetica\", 14))\n",
    "        self.epoch_label.pack(pady=5)\n",
    "\n",
    "        self.loss_label = tk.Label(self.root, text=\"Loss: 0.0000\", font=(\"Helvetica\", 12))\n",
    "        self.loss_label.pack(pady=2)\n",
    "\n",
    "        self.accuracy_label = tk.Label(self.root, text=\"Accuracy: 0.0000\", font=(\"Helvetica\", 12))\n",
    "        self.accuracy_label.pack(pady=2)\n",
    "\n",
    "        self.val_loss_label = tk.Label(self.root, text=\"Validation Loss: 0.0000\", font=(\"Helvetica\", 12))\n",
    "        self.val_loss_label.pack(pady=2)\n",
    "\n",
    "        self.val_accuracy_label = tk.Label(self.root, text=\"Validation Accuracy: 0.0000\", font=(\"Helvetica\", 12))\n",
    "        self.val_accuracy_label.pack(pady=2)\n",
    "\n",
    "        self.lr_label = tk.Label(self.root, text=\"Learning Rate: 0.000000\", font=(\"Helvetica\", 12))\n",
    "        self.lr_label.pack(pady=2)\n",
    "\n",
    "    def _init_progress_bar(self):\n",
    "        \"\"\"Initialize the progress bar.\"\"\"\n",
    "        self.progress_bar = ttk.Progressbar(self.root, orient=\"horizontal\", length=400, mode=\"determinate\")\n",
    "        self.progress_bar.pack(pady=10)\n",
    "\n",
    "    def _init_plots(self):\n",
    "        \"\"\"Initialize the real-time plots.\"\"\"\n",
    "        self.fig, self.ax = plt.subplots(figsize=(6, 4))\n",
    "        self.line_loss, = self.ax.plot([], [], label='Training Loss', color='blue')\n",
    "        self.line_val_loss, = self.ax.plot([], [], label='Validation Loss', color='orange')\n",
    "        self.line_acc, = self.ax.plot([], [], label='Training Accuracy', color='green')\n",
    "        self.line_val_acc, = self.ax.plot([], [], label='Validation Accuracy', color='red')\n",
    "\n",
    "        self.ax.set_xlabel('Epochs')\n",
    "        self.ax.set_ylabel('Metrics')\n",
    "        self.ax.legend()\n",
    "        self.ax.grid(True)\n",
    "\n",
    "        self.canvas = FigureCanvasTkAgg(self.fig, master=self.root)\n",
    "        self.canvas.draw()\n",
    "        self.canvas.get_tk_widget().pack()\n",
    "\n",
    "        # Data storage for plotting\n",
    "        self.loss_data = []\n",
    "        self.val_loss_data = []\n",
    "        self.acc_data = []\n",
    "        self.val_acc_data = []\n",
    "\n",
    "    def _init_ensemble_accuracy(self):\n",
    "        \"\"\"Initialize the ensemble accuracy display.\"\"\"\n",
    "        self.ensemble_label = tk.Label(self.root, text=\"Ensemble Accuracy: N/A\", font=(\"Helvetica\", 14))\n",
    "        self.ensemble_label.pack(pady=5)\n",
    "\n",
    "    def _init_query_section(self):\n",
    "        \"\"\"Initialize the section for querying the LLM for explanations.\"\"\"\n",
    "        self.query_frame = tk.Frame(self.root)\n",
    "        self.query_frame.pack(pady=10)\n",
    "\n",
    "        self.query_label = tk.Label(self.query_frame, text=\"LLM Query:\", font=(\"Helvetica\", 12))\n",
    "        self.query_label.pack(side=tk.LEFT, padx=5)\n",
    "\n",
    "        self.query_entry = tk.Entry(self.query_frame, width=50)\n",
    "        self.query_entry.pack(side=tk.LEFT, padx=5)\n",
    "\n",
    "        self.query_button = tk.Button(self.query_frame, text=\"Ask\", command=self.handle_query)\n",
    "        self.query_button.pack(side=tk.LEFT, padx=5)\n",
    "\n",
    "        self.response_text = tk.Text(self.root, height=10, width=80, state='disabled')\n",
    "        self.response_text.pack(pady=5)\n",
    "\n",
    "    def process_queue(self):\n",
    "        \"\"\"Process the queue for thread-safe GUI updates.\"\"\"\n",
    "        while not self.queue.empty():\n",
    "            message = self.queue.get()\n",
    "            if isinstance(message, dict):\n",
    "                self._handle_message(message)\n",
    "        self.root.after(100, self.process_queue)  # Schedule next update\n",
    "\n",
    "    def _handle_message(self, message):\n",
    "        \"\"\"Handle incoming messages from the queue.\"\"\"\n",
    "        msg_type = message.get('type')\n",
    "        if msg_type == 'epoch':\n",
    "            self.update_epoch(message)\n",
    "        elif msg_type == 'ensemble_accuracy':\n",
    "            self.update_ensemble_accuracy(message.get('accuracy'))\n",
    "        elif msg_type == 'training_completed':\n",
    "            self.model_label.config(text=\"Training Completed\")\n",
    "            messagebox.showinfo(\"Training Completed\", \"All models have been trained successfully!\")\n",
    "\n",
    "    def update_epoch(self, data):\n",
    "        \"\"\"Update the GUI with epoch metrics.\"\"\"\n",
    "        self._update_labels(data)\n",
    "        self._update_progress_bar(data['epoch'], data['total_epochs'])\n",
    "        self._update_plots(data)\n",
    "\n",
    "    def update_ensemble_accuracy(self, accuracy):\n",
    "        \"\"\"Update the ensemble accuracy label.\"\"\"\n",
    "        self.ensemble_label.config(text=f\"Ensemble Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "    def _update_labels(self, data):\n",
    "        \"\"\"Update the labels with new data.\"\"\"\n",
    "        self.model_label.config(text=f\"Training Model: {data['model_num']}/{data['total_models']}\")\n",
    "        self.epoch_label.config(text=f\"Epoch: {data['epoch']}/{data['total_epochs']}\")\n",
    "        self.loss_label.config(text=f\"Loss: {data['loss']:.4f}\")\n",
    "        self.accuracy_label.config(text=f\"Accuracy: {data['accuracy']:.4f}\")\n",
    "        self.val_loss_label.config(text=f\"Validation Loss: {data['val_loss']:.4f}\")\n",
    "        self.val_accuracy_label.config(text=f\"Validation Accuracy: {data['val_accuracy']:.4f}\")\n",
    "        self.lr_label.config(text=f\"Learning Rate: {data['lr']:.6f}\")\n",
    "\n",
    "    def _update_progress_bar(self, epoch, total_epochs):\n",
    "        \"\"\"Update the progress bar.\"\"\"\n",
    "        self.progress_bar[\"value\"] = (epoch / total_epochs) * 100\n",
    "        self.root.update_idletasks()\n",
    "\n",
    "    def _update_plots(self, data):\n",
    "        \"\"\"Update the real-time plots with new metrics.\"\"\"\n",
    "        self.loss_data.append(data['loss'])\n",
    "        self.val_loss_data.append(data['val_loss'])\n",
    "        self.acc_data.append(data['accuracy'])\n",
    "        self.val_acc_data.append(data['val_accuracy'])\n",
    "\n",
    "        self.ax.clear()\n",
    "        self.ax.plot(range(1, len(self.loss_data)+1), self.loss_data, label='Training Loss', color='blue')\n",
    "        self.ax.plot(range(1, len(self.val_loss_data)+1), self.val_loss_data, label='Validation Loss', color='orange')\n",
    "        self.ax.plot(range(1, len(self.acc_data)+1), self.acc_data, label='Training Accuracy', color='green')\n",
    "        self.ax.plot(range(1, len(self.val_acc_data)+1), self.val_acc_data, label='Validation Accuracy', color='red')\n",
    "        self.ax.set_xlabel('Epochs')\n",
    "        self.ax.set_ylabel('Metrics')\n",
    "        self.ax.legend()\n",
    "        self.ax.grid(True)\n",
    "        self.canvas.draw()\n",
    "\n",
    "    def handle_query(self):\n",
    "        \"\"\"Handle user queries to the LLM.\"\"\"\n",
    "        query = self.query_entry.get()\n",
    "        if not query:\n",
    "            messagebox.showwarning(\"Input Needed\", \"Please enter a query.\")\n",
    "            return\n",
    "\n",
    "        # Retrieve current metrics from Redis\n",
    "        current_metrics = self.redis_manager.get_value('current_metrics')\n",
    "        if not current_metrics:\n",
    "            messagebox.showwarning(\"No Data\", \"No current metrics available for explanation.\")\n",
    "            return\n",
    "\n",
    "        # Generate explanation using LLM\n",
    "        explanation = self.llm.explain_prediction(\n",
    "            model_num=current_metrics.get('model_num', 0),\n",
    "            epoch=current_metrics.get('epoch', 0),\n",
    "            input_data=None,       # Optionally, pass actual input data if available\n",
    "            prediction=None,      # Optionally, pass actual prediction if available\n",
    "            actual_label=None     # Optionally, pass actual label if available\n",
    "        )\n",
    "\n",
    "        # Display the explanation\n",
    "        response = f\"Query: {query}\\nExplanation: {explanation}\\n\"\n",
    "        self.response_text.config(state='normal')\n",
    "        self.response_text.insert(tk.END, response + \"\\n\")\n",
    "        self.response_text.config(state='disabled')\n",
    "        self.query_entry.delete(0, tk.END)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d98d04-aa25-4ec5-b8e1-577144026e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training/trainer.py\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import DataLoader\n",
    "import logging\n",
    "from queue import Queue\n",
    "import threading\n",
    "import time\n",
    "import joblib\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Ensure all models are imported in models/__init__.py for easy access\n",
    "\n",
    "class Trainer:\n",
    "    \"\"\"\n",
    "    Manages the training process for multiple models, interacts with the GUI,\n",
    "    handles hyperparameter tuning, evaluates models, and creates an ensemble.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 train_loader: DataLoader, \n",
    "                 eval_loader: DataLoader, \n",
    "                 total_models: int, \n",
    "                 total_epochs: int, \n",
    "                 initial_lr: float, \n",
    "                 device: torch.device,\n",
    "                 redis_manager: RedisManager,\n",
    "                 llm: StrategyLLM,\n",
    "                 gui: TrainingGUI):\n",
    "        \"\"\"\n",
    "        Initializes the Trainer with necessary components.\n",
    "\n",
    "        Args:\n",
    "            train_loader (DataLoader): DataLoader for training data.\n",
    "            eval_loader (DataLoader): DataLoader for evaluation data.\n",
    "            total_models (int): Total number of models to train.\n",
    "            total_epochs (int): Number of epochs per model.\n",
    "            initial_lr (float): Initial learning rate.\n",
    "            device (torch.device): Device to perform training on.\n",
    "            redis_manager (RedisManager): Instance for interacting with Redis.\n",
    "            llm (StrategyLLM): Instance of the language model for explanations.\n",
    "            gui (TrainingGUI): Instance of the GUI for updates.\n",
    "        \"\"\"\n",
    "        self.train_loader = train_loader\n",
    "        self.eval_loader = eval_loader\n",
    "        self.total_models = total_models\n",
    "        self.total_epochs = total_epochs\n",
    "        self.initial_lr = initial_lr\n",
    "        self.device = device\n",
    "        self.redis_manager = redis_manager\n",
    "        self.llm = llm\n",
    "        self.gui = gui\n",
    "        self.models = []\n",
    "        self.ensemble_model = None\n",
    "        self.scaler = None\n",
    "        self.tuner = HyperparameterTuner(initial_lr=initial_lr)\n",
    "        self.lock = threading.Lock()  # To manage access to shared resources\n",
    "\n",
    "    def get_model(self, model_num: int):\n",
    "        \"\"\"\n",
    "        Dynamically initializes a model based on the model number.\n",
    "\n",
    "        Args:\n",
    "            model_num (int): The current model number.\n",
    "\n",
    "        Returns:\n",
    "            nn.Module: An instance of the selected model.\n",
    "        \"\"\"\n",
    "        # Example strategy: cycle through different model architectures\n",
    "        architectures = [\n",
    "            MLPMagician,\n",
    "            CNNMagician,\n",
    "            ResNetMagician,\n",
    "            VisionTransformerMagician,\n",
    "            DNNMagician,\n",
    "            RNNMagician\n",
    "        ]\n",
    "        architecture = architectures[model_num % len(architectures)]\n",
    "        \n",
    "        if architecture == MLPMagician:\n",
    "            model = MLPMagician(input_size=784, hidden_sizes=[256, 128, 64], dropout_rate=0.5)\n",
    "        elif architecture == CNNMagician:\n",
    "            model = CNNMagician(dropout_rate=0.5, num_classes=10)\n",
    "        elif architecture == ResNetMagician:\n",
    "            model = ResNetMagician(num_classes=10)\n",
    "        elif architecture == VisionTransformerMagician:\n",
    "            model = VisionTransformerMagician(num_classes=10, pretrained=True)\n",
    "        elif architecture == DNNMagician:\n",
    "            model = DNNMagician(input_size=784, hidden_sizes=[512, 256, 128], dropout_rate=0.5)\n",
    "        elif architecture == RNNMagician:\n",
    "            model = RNNMagician(input_size=10, hidden_size=50, num_layers=2, output_size=10, dropout_rate=0.3)\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported architecture: {architecture}\")\n",
    "        \n",
    "        model.to(self.device)\n",
    "        logging.info(f\"Initialized {architecture.__name__} for Model {model_num}.\")\n",
    "        return model\n",
    "\n",
    "    def train(self):\n",
    "        \"\"\"\n",
    "        Starts the training process in a separate thread to keep the GUI responsive.\n",
    "        \"\"\"\n",
    "        training_thread = threading.Thread(target=self._training_loop, daemon=True)\n",
    "        training_thread.start()\n",
    "\n",
    "    def _training_loop(self):\n",
    "        \"\"\"\n",
    "        The main training loop that iterates over the number of models and epochs.\n",
    "        \"\"\"\n",
    "        for model_num in range(1, self.total_models + 1):\n",
    "            try:\n",
    "                model = self.get_model(model_num)\n",
    "                self.models.append(model)\n",
    "                optimizer = optim.AdamW(model.parameters(), lr=self.initial_lr, weight_decay=1e-4)\n",
    "                scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3, verbose=True)\n",
    "                criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "                scaler = torch.cuda.amp.GradScaler() if self.device.type == 'cuda' else None\n",
    "\n",
    "                best_val_loss = float('inf')\n",
    "                best_val_accuracy = 0.0\n",
    "\n",
    "                for epoch in range(1, self.total_epochs + 1):\n",
    "                    model.train()\n",
    "                    running_loss = 0.0\n",
    "                    correct = 0\n",
    "                    total = 0\n",
    "\n",
    "                    for batch_idx, (inputs, labels) in enumerate(self.train_loader):\n",
    "                        inputs, labels = inputs.to(self.device), labels.to(self.device)\n",
    "                        \n",
    "                        optimizer.zero_grad()\n",
    "                        \n",
    "                        with torch.cuda.amp.autocast(enabled=self.device.type == 'cuda'):\n",
    "                            outputs = model(inputs)\n",
    "                            loss = criterion(outputs, labels)\n",
    "                        \n",
    "                        if scaler:\n",
    "                            scaler.scale(loss).backward()\n",
    "                            scaler.step(optimizer)\n",
    "                            scaler.update()\n",
    "                        else:\n",
    "                            loss.backward()\n",
    "                            optimizer.step()\n",
    "                        \n",
    "                        running_loss += loss.item() * inputs.size(0)\n",
    "                        _, predicted = torch.max(outputs.data, 1)\n",
    "                        total += labels.size(0)\n",
    "                        correct += (predicted == labels).sum().item()\n",
    "                    \n",
    "                    epoch_loss = running_loss / len(self.train_loader.dataset)\n",
    "                    epoch_acc = correct / total\n",
    "\n",
    "                    val_loss, val_acc = self.evaluate(model, criterion)\n",
    "\n",
    "                    scheduler.step(val_loss)\n",
    "                    self.tuner.adjust_learning_rate(optimizer, val_loss)\n",
    "\n",
    "                    # Update Redis with current metrics\n",
    "                    current_metrics = {\n",
    "                        'model_num': model_num,\n",
    "                        'epoch': epoch,\n",
    "                        'total_models': self.total_models,\n",
    "                        'total_epochs': self.total_epochs,\n",
    "                        'loss': epoch_loss,\n",
    "                        'accuracy': epoch_acc,\n",
    "                        'val_loss': val_loss,\n",
    "                        'val_accuracy': val_acc,\n",
    "                        'lr': optimizer.param_groups[0]['lr']\n",
    "                    }\n",
    "                    self.redis_manager.set_value('current_metrics', current_metrics)\n",
    "\n",
    "                    # Send update to GUI\n",
    "                    self.gui.queue.put({\n",
    "                        'type': 'epoch',\n",
    "                        'model_num': model_num,\n",
    "                        'total_models': self.total_models,\n",
    "                        'epoch': epoch,\n",
    "                        'total_epochs': self.total_epochs,\n",
    "                        'loss': epoch_loss,\n",
    "                        'accuracy': epoch_acc,\n",
    "                        'val_loss': val_loss,\n",
    "                        'val_accuracy': val_acc,\n",
    "                        'lr': optimizer.param_groups[0]['lr']\n",
    "                    })\n",
    "\n",
    "                    logging.info(f\"Model {model_num}, Epoch {epoch}/{self.total_epochs} - \"\n",
    "                                 f\"Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.4f}, \"\n",
    "                                 f\"Val Loss: {val_loss:.4f}, Val Accuracy: {val_acc:.4f}, \"\n",
    "                                 f\"LR: {optimizer.param_groups[0]['lr']:.6f}\")\n",
    "\n",
    "                # Save model checkpoint\n",
    "                checkpoint_path = f'models/model_{model_num}.pth'\n",
    "                torch.save(model.state_dict(), checkpoint_path)\n",
    "                logging.info(f\"Saved Model {model_num} at '{checkpoint_path}'.\")\n",
    "\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Error training Model {model_num}: {e}\")\n",
    "                continue\n",
    "\n",
    "        # After training all models, create an ensemble\n",
    "        self.create_ensemble()\n",
    "\n",
    "        # Notify GUI that training is completed\n",
    "        self.gui.queue.put({'type': 'training_completed'})\n",
    "\n",
    "    def evaluate(self, model: nn.Module, criterion: nn.Module):\n",
    "        \"\"\"\n",
    "        Evaluates the model on the validation dataset.\n",
    "\n",
    "        Args:\n",
    "            model (nn.Module): The trained model.\n",
    "            criterion (nn.Module): The loss function.\n",
    "\n",
    "        Returns:\n",
    "            tuple: (validation_loss, validation_accuracy)\n",
    "        \"\"\"\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in self.eval_loader:\n",
    "                inputs, labels = inputs.to(self.device), labels.to(self.device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        avg_val_loss = val_loss / len(self.eval_loader.dataset)\n",
    "        val_accuracy = correct / total\n",
    "\n",
    "        logging.info(f\"Validation - Loss: {avg_val_loss:.4f}, Accuracy: {val_accuracy:.4f}\")\n",
    "\n",
    "        return avg_val_loss, val_accuracy\n",
    "\n",
    "    def create_ensemble(self):\n",
    "        \"\"\"\n",
    "        Creates an ensemble model using a Random Forest classifier based on the trained models' outputs.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Collect features and labels from training data\n",
    "            all_features = []\n",
    "            all_labels = []\n",
    "            for model in self.models:\n",
    "                model.eval()\n",
    "                features = []\n",
    "                labels = []\n",
    "                with torch.no_grad():\n",
    "                    for inputs, lbls in self.train_loader:\n",
    "                        inputs = inputs.to(self.device)\n",
    "                        outputs = model(inputs)\n",
    "                        features.append(outputs.cpu().numpy())\n",
    "                        labels.append(lbls.numpy())\n",
    "                all_features.append(np.vstack(features))\n",
    "                all_labels.append(np.hstack(labels))\n",
    "            \n",
    "            # Concatenate features from all models\n",
    "            combined_features = np.hstack(all_features)\n",
    "            combined_labels = all_labels[0]  # Assuming all models have the same labels\n",
    "\n",
    "            # Scale features\n",
    "            scaler = StandardScaler()\n",
    "            scaled_features = scaler.fit_transform(combined_features)\n",
    "\n",
    "            # Train Random Forest ensemble\n",
    "            rf = RandomForestClassifier(n_estimators=300, max_depth=12, random_state=42, n_jobs=-1)\n",
    "            rf.fit(scaled_features, combined_labels)\n",
    "            self.ensemble_model = rf\n",
    "            self.scaler = scaler\n",
    "\n",
    "            # Save ensemble model\n",
    "            ensemble_path = 'ensemble_random_forest.pkl'\n",
    "            joblib.dump((rf, scaler), ensemble_path)\n",
    "            logging.info(f\"Saved ensemble model at '{ensemble_path}'.\")\n",
    "\n",
    "            # Evaluate ensemble on validation data\n",
    "            val_loss, val_accuracy = self.evaluate_ensemble()\n",
    "            self.gui.queue.put({'type': 'ensemble_accuracy', 'accuracy': val_accuracy})\n",
    "\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error creating ensemble: {e}\")\n",
    "\n",
    "    def evaluate_ensemble(self):\n",
    "        \"\"\"\n",
    "        Evaluates the ensemble model on the validation dataset.\n",
    "\n",
    "        Returns:\n",
    "            tuple: (validation_loss, validation_accuracy)\n",
    "        \"\"\"\n",
    "        if not self.ensemble_model or not self.scaler:\n",
    "            logging.error(\"Ensemble model or scaler not found.\")\n",
    "            return float('inf'), 0.0\n",
    "\n",
    "        all_features = []\n",
    "        all_labels = []\n",
    "        for model in self.models:\n",
    "            model.eval()\n",
    "            features = []\n",
    "            labels = []\n",
    "            with torch.no_grad():\n",
    "                for inputs, lbls in self.eval_loader:\n",
    "                    inputs = inputs.to(self.device)\n",
    "                    outputs = model(inputs)\n",
    "                    features.append(outputs.cpu().numpy())\n",
    "                    labels.append(lbls.numpy())\n",
    "            all_features.append(np.vstack(features))\n",
    "            all_labels.append(np.hstack(labels))\n",
    "        \n",
    "        # Concatenate features from all models\n",
    "        combined_features = np.hstack(all_features)\n",
    "        combined_labels = all_labels[0]  # Assuming all models have the same labels\n",
    "\n",
    "        # Scale features\n",
    "        scaled_features = self.scaler.transform(combined_features)\n",
    "\n",
    "        # Predict with Random Forest\n",
    "        predictions = self.ensemble_model.predict(scaled_features)\n",
    "        prediction_probs = self.ensemble_model.predict_proba(scaled_features)\n",
    "\n",
    "        # Calculate metrics\n",
    "        accuracy = accuracy_score(combined_labels, predictions)\n",
    "        loss = log_loss(combined_labels, prediction_probs)\n",
    "\n",
    "        logging.info(f\"Ensemble Validation - Loss: {loss:.4f}, Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "        return loss, accuracy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99658f43-b76a-4ad0-8459-562f1fa18625",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa64048-7f54-44c3-be45-7e91a9d20a0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc50195-64a5-4b1f-a242-0d19ad1c09f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97390b85-1d9c-4fbb-877c-939041c53a0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0cf8ba-2c92-464e-86a0-2209204239da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae0d674-53b0-43b1-a901-19947b7f6fbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfea14bd-9fc2-471d-b757-6ae0c68784b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381cc436-36ed-49d7-a9c7-088923cdb43b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ee0ebb-df77-47ee-ba4d-7e852d8c3d86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b8b113-59e3-431b-a1d1-32335c7a6aa2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ac47e2-d7bb-4ad1-b7fd-0590a7d250ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b3d482-e576-4a00-997a-340209d39021",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils/__init__.py\n",
    "\n",
    "from .logging_setup import initialize_logging\n",
    "from .redis_manager import RedisManager\n",
    "from .plot_utils import plot_training_metrics\n",
    "from .weight_initialization import initialize_weights\n",
    "from .hyperparameter_tuner import HyperparameterTuner\n",
    "from .hyperparameter_helper import randomize_params\n",
    "\n",
    "__all__ = [\n",
    "    'initialize_logging',\n",
    "    'RedisManager',\n",
    "    'plot_training_metrics',\n",
    "    'initialize_weights',\n",
    "    'HyperparameterTuner',\n",
    "    'randomize_params'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09c32c6-74aa-49c8-8e04-e65ca46befca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# models/__init__.py\n",
    "\n",
    "from .mlp_magician import MLPMagician\n",
    "from .cnn_magician import CNNMagician\n",
    "from .resnet_magician import ResNetMagician\n",
    "from .vision_transformer_magician import VisionTransformerMagician\n",
    "from .dnn_magician import DNNMagician\n",
    "from .rnn_magician import RNNMagician\n",
    "\n",
    "__all__ = [\n",
    "    'MLPMagician',\n",
    "    'CNNMagician',\n",
    "    'ResNetMagician',\n",
    "    'VisionTransformerMagician',\n",
    "    'DNNMagician',\n",
    "    'RNNMagician'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d86660-756b-4afc-b396-9d11efe8099d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main.py\n",
    "\n",
    "import tkinter as tk\n",
    "from utils.logging_setup import initialize_logging\n",
    "from utils.redis_manager import RedisManager\n",
    "from utils.strategy_llm import StrategyLLM\n",
    "from gui.training_gui import TrainingGUI\n",
    "from data.data_loader import load_arc_data, prepare_training_data, prepare_evaluation_data\n",
    "from training.trainer import Trainer\n",
    "from utils.hyperparameter_helper import randomize_params\n",
    "import torch\n",
    "\n",
    "def main():\n",
    "    # Initialize logging\n",
    "    initialize_logging()\n",
    "\n",
    "    # Initialize Redis Manager\n",
    "    redis_manager = RedisManager(host='localhost', port=6379, db=0)\n",
    "\n",
    "    # Initialize Strategy LLM\n",
    "    llm = StrategyLLM(model_name='gpt2')  # Adjust model name as needed\n",
    "\n",
    "    # Load ARC data\n",
    "    arc_data = load_arc_data()\n",
    "    if arc_data is None:\n",
    "        print(\"Failed to load ARC data.\")\n",
    "        return\n",
    "\n",
    "    # Prepare data loaders\n",
    "    train_loader = prepare_training_data(\n",
    "        arc_data=arc_data, \n",
    "        batch_size=32, \n",
    "        shuffle=True, \n",
    "        augment=True, \n",
    "        seed_manager=None  # Initialize SeedManager if needed\n",
    "    )\n",
    "    eval_loader = prepare_evaluation_data(\n",
    "        arc_data=arc_data, \n",
    "        batch_size=32, \n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    # Randomize hyperparameters\n",
    "    num_models, num_epochs, initial_lr, _ = randomize_params()\n",
    "\n",
    "    # Determine device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    # Initialize GUI\n",
    "    root = tk.Tk()\n",
    "    gui = TrainingGUI(\n",
    "        root=root, \n",
    "        total_models=num_models, \n",
    "        total_epochs=num_epochs, \n",
    "        redis_manager=redis_manager, \n",
    "        llm=llm\n",
    "    )\n",
    "\n",
    "    # Initialize Trainer\n",
    "    trainer = Trainer(\n",
    "        train_loader=train_loader,\n",
    "        eval_loader=eval_loader,\n",
    "        total_models=num_models,\n",
    "        total_epochs=num_epochs,\n",
    "        initial_lr=initial_lr,\n",
    "        device=device,\n",
    "        redis_manager=redis_manager,\n",
    "        llm=llm,\n",
    "        gui=gui\n",
    "    )\n",
    "\n",
    "    # Start training\n",
    "    trainer.train()\n",
    "\n",
    "    # Start the Tkinter main loop\n",
    "    root.mainloop()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a645f15-66f0-4ffa-a7f0-d593ea3cd1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class CNNGridExtractor(nn.Module):\n",
    "    \"\"\"Extract spatial features from grid patterns using CNN.\"\"\"\n",
    "    def __init__(self):\n",
    "        super(CNNGridExtractor, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc = nn.Linear(64 * 15 * 15, 256)  # Adjust for 30x30 grid\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.pool(self.conv1(x)))\n",
    "        x = F.relu(self.pool(self.conv2(x)))\n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "        features = F.relu(self.fc(x))\n",
    "        return features\n",
    "\n",
    "class RNNLearner(nn.Module):\n",
    "    \"\"\"Learns temporal dependencies across iterations.\"\"\"\n",
    "    def __init__(self, input_size=256, hidden_size=128, num_layers=2):\n",
    "        super(RNNLearner, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, 64)\n",
    "\n",
    "    def forward(self, x, hidden_state):\n",
    "        out, hidden_state = self.lstm(x, hidden_state)\n",
    "        output = self.fc(out[:, -1, :])  # Use last hidden state output\n",
    "        return output, hidden_state\n",
    "\n",
    "class HybridGridNetwork(nn.Module):\n",
    "    \"\"\"Combines CNN and RNN to learn grid-based patterns.\"\"\"\n",
    "    def __init__(self):\n",
    "        super(HybridGridNetwork, self).__init__()\n",
    "        self.cnn = CNNGridExtractor()\n",
    "        self.rnn = RNNLearner()\n",
    "        self.fc = nn.Linear(64, 10)  # Example output layer (10 classes)\n",
    "\n",
    "    def forward(self, x, hidden_state):\n",
    "        features = self.cnn(x)\n",
    "        features = features.unsqueeze(1)  # Add batch dimension for LSTM\n",
    "        rnn_output, hidden_state = self.rnn(features, hidden_state)\n",
    "        output = self.fc(rnn_output)\n",
    "        return output, hidden_state\n",
    "\n",
    "def initialize_hidden(batch_size, hidden_size=128, num_layers=2):\n",
    "    \"\"\"Initialize LSTM hidden state.\"\"\"\n",
    "    return (\n",
    "        torch.zeros(num_layers, batch_size, hidden_size).to(device),\n",
    "        torch.zeros(num_layers, batch_size, hidden_size).to(device)\n",
    "    )\n",
    "\n",
    "def preprocess_grid(grid):\n",
    "    \"\"\"Convert grid to tensor and normalize it.\"\"\"\n",
    "    grid_tensor = torch.tensor(grid, dtype=torch.float32).unsqueeze(0)  # Add channel dimension\n",
    "    return grid_tensor / 10.0  # Normalize values\n",
    "\n",
    "def compute_reward(predicted, target):\n",
    "    \"\"\"Compute reward based on MSE difference.\"\"\"\n",
    "    return 1.0 - F.mse_loss(predicted, target).item()\n",
    "\n",
    "def train_hybrid_model(\n",
    "    model, train_loader, eval_loader, num_epochs, optimizer, criterion, device\n",
    "):\n",
    "    \"\"\"Train the hybrid model using reinforcement learning and SGD.\"\"\"\n",
    "    hidden_state = initialize_hidden(train_loader.batch_size)\n",
    "    rewards = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss, total_reward = 0, 0\n",
    "\n",
    "        for inputs, targets in train_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs, hidden_state = model(inputs, hidden_state)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            reward = compute_reward(outputs, targets)\n",
    "            total_reward += reward\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        val_loss, val_accuracy = evaluate_model(model, eval_loader, criterion, device)\n",
    "        print(f\"Epoch {epoch+1}, Loss: {total_loss:.4f}, Reward: {total_reward:.4f}, Val Acc: {val_accuracy:.4f}\")\n",
    "\n",
    "    return model\n",
    "\n",
    "def evaluate_model(model, eval_loader, criterion, device):\n",
    "    \"\"\"Evaluate the model on validation data.\"\"\"\n",
    "    model.eval()\n",
    "    total_loss, correct_predictions, total_samples = 0, 0, 0\n",
    "    hidden_state = initialize_hidden(eval_loader.batch_size)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in eval_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs, _ = model(inputs, hidden_state)\n",
    "            loss = criterion(outputs, targets)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct_predictions += (predicted == targets).sum().item()\n",
    "            total_samples += targets.size(0)\n",
    "\n",
    "    avg_loss = total_loss / len(eval_loader)\n",
    "    accuracy = correct_predictions / total_samples\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "# Example usage\n",
    "grid_data = np.random.randint(0, 10, (100, 30, 30))  # Generate random grid data\n",
    "grid_labels = np.random.randint(0, 10, (100,))  # Random labels\n",
    "\n",
    "# Prepare DataLoader\n",
    "grids = torch.stack([preprocess_grid(grid) for grid in grid_data])\n",
    "labels = torch.tensor(grid_labels)\n",
    "dataset = TensorDataset(grids, labels)\n",
    "train_loader = DataLoader(dataset, batch_size=8, shuffle=True)\n",
    "eval_loader = DataLoader(dataset, batch_size=8)\n",
    "\n",
    "model = HybridGridNetwork().to(device)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-3)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Train the model\n",
    "train_hybrid_model(model, train_loader, eval_loader, num_epochs=500, optimizer=optimizer, criterion=criterion, device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdacfb24-5a2d-48db-af6f-62c2b38237a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "\n",
    "class CNNExtractor(nn.Module):\n",
    "    \"\"\"Extract visual features from image data using CNN.\"\"\"\n",
    "    def __init__(self):\n",
    "        super(CNNExtractor, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc = nn.Linear(128 * 15 * 15, 512)  # Assuming 30x30 input size\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.pool(self.conv1(x)))\n",
    "        x = F.relu(self.pool(self.conv2(x)))\n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "        features = F.relu(self.fc(x))\n",
    "        return features\n",
    "\n",
    "class RNNLearner(nn.Module):\n",
    "    \"\"\"Learns long-term dependencies from extracted features.\"\"\"\n",
    "    def __init__(self, input_size=512, hidden_size=256, num_layers=2):\n",
    "        super(RNNLearner, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, 128)  # Output for reinforcement learning\n",
    "\n",
    "    def forward(self, x, hidden_state):\n",
    "        out, hidden_state = self.lstm(x, hidden_state)\n",
    "        output = self.fc(out[:, -1, :])  # Use the last hidden state\n",
    "        return output, hidden_state\n",
    "\n",
    "class HybridNetwork(nn.Module):\n",
    "    \"\"\"Combines CNN and RNN for visual data learning.\"\"\"\n",
    "    def __init__(self):\n",
    "        super(HybridNetwork, self).__init__()\n",
    "        self.cnn = CNNExtractor()\n",
    "        self.rnn = RNNLearner()\n",
    "        self.fc = nn.Linear(128, 10)  # Example output layer (10 classes)\n",
    "\n",
    "    def forward(self, x, hidden_state):\n",
    "        features = self.cnn(x)\n",
    "        features = features.unsqueeze(1)  # Add batch dimension for LSTM\n",
    "        rnn_output, hidden_state = self.rnn(features, hidden_state)\n",
    "        output = self.fc(rnn_output)\n",
    "        return output, hidden_state\n",
    "\n",
    "def initialize_hidden(batch_size, hidden_size=256, num_layers=2):\n",
    "    \"\"\"Initialize LSTM hidden state.\"\"\"\n",
    "    return (\n",
    "        torch.zeros(num_layers, batch_size, hidden_size).to(device),\n",
    "        torch.zeros(num_layers, batch_size, hidden_size).to(device)\n",
    "    )\n",
    "\n",
    "def compute_reward(predicted, target):\n",
    "    \"\"\"Compute reward based on accuracy.\"\"\"\n",
    "    return 1.0 - F.mse_loss(predicted, target).item()  # Reward is inverse of MSE\n",
    "\n",
    "def train_hybrid_model(\n",
    "    model, train_loader, eval_loader, num_epochs, optimizer, criterion, device\n",
    "):\n",
    "    \"\"\"Train the hybrid model using reinforcement learning and SGD.\"\"\"\n",
    "    hidden_state = initialize_hidden(train_loader.batch_size)\n",
    "    rewards = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss, total_reward = 0, 0\n",
    "\n",
    "        for inputs, targets in train_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            outputs, hidden_state = model(inputs, hidden_state)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Compute reward and update long-term memory\n",
    "            reward = compute_reward(outputs, targets)\n",
    "            total_reward += reward\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        # Evaluate on validation set\n",
    "        val_loss, val_accuracy = evaluate_model(model, eval_loader, criterion, device)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {total_loss}, Reward: {total_reward}, Val Acc: {val_accuracy}\")\n",
    "\n",
    "    return model\n",
    "\n",
    "def evaluate_model(model, eval_loader, criterion, device):\n",
    "    \"\"\"Evaluate model on validation set.\"\"\"\n",
    "    model.eval()\n",
    "    total_loss, correct_predictions, total_samples = 0, 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        hidden_state = initialize_hidden(eval_loader.batch_size)\n",
    "        for inputs, targets in eval_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs, _ = model(inputs, hidden_state)\n",
    "            loss = criterion(outputs, targets)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct_predictions += (predicted == targets).sum().item()\n",
    "            total_samples += targets.size(0)\n",
    "\n",
    "    accuracy = correct_predictions / total_samples\n",
    "    avg_loss = total_loss / len(eval_loader)\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "# Usage example:\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = HybridNetwork().to(device)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-3)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Train and evaluate the model\n",
    "num_epochs = 500\n",
    "train_hybrid_model(model, train_loader, eval_loader, num_epochs, optimizer, criterion, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899e3340-5f67-43f4-b220-88902cdf81e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data/data_conversion.py\n",
    "\n",
    "import os\n",
    "import random\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import logging\n",
    "\n",
    "# Configure logging for the data_conversion module\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "def grid_to_image(grid, color_map):\n",
    "    \"\"\"\n",
    "    Converts a numerical grid into a colored image based on the provided color map.\n",
    "\n",
    "    Args:\n",
    "        grid (np.ndarray): 2D array representing the grid values.\n",
    "        color_map (dict): Dictionary mapping grid values to RGB colors.\n",
    "\n",
    "    Returns:\n",
    "        PIL.Image: Colored image representation of the grid.\n",
    "    \"\"\"\n",
    "    height, width = grid.shape\n",
    "    img_array = np.zeros((height, width, 3), dtype=np.uint8)\n",
    "\n",
    "    for i in range(height):\n",
    "        for j in range(width):\n",
    "            img_array[i, j] = color_map.get(grid[i, j], [255, 255, 255])  # Default to white\n",
    "\n",
    "    return Image.fromarray(img_array)\n",
    "\n",
    "\n",
    "def grid_to_grayscale(grid):\n",
    "    \"\"\"\n",
    "    Converts a numerical grid into a grayscale image.\n",
    "\n",
    "    Args:\n",
    "        grid (np.ndarray): 2D array representing the grid values.\n",
    "\n",
    "    Returns:\n",
    "        PIL.Image: Grayscale image representation of the grid.\n",
    "    \"\"\"\n",
    "    height, width = grid.shape\n",
    "    # Normalize grid values to 0-255\n",
    "    normalized_grid = (grid - grid.min()) / (grid.max() - grid.min()) * 255\n",
    "    grayscale_array = normalized_grid.astype(np.uint8)\n",
    "    return Image.fromarray(grayscale_array, mode='L')\n",
    "\n",
    "\n",
    "def grid_to_numeric_image(grid, font_path=None, font_size=12):\n",
    "    \"\"\"\n",
    "    Converts a numerical grid into an image with numbers overlaid on a blank background.\n",
    "\n",
    "    Args:\n",
    "        grid (np.ndarray): 2D array representing the grid values.\n",
    "        font_path (str, optional): Path to a .ttf font file. Defaults to None.\n",
    "        font_size (int, optional): Font size for the numbers. Defaults to 12.\n",
    "\n",
    "    Returns:\n",
    "        PIL.Image: Image with numbers overlaid on the grid.\n",
    "    \"\"\"\n",
    "    height, width = grid.shape\n",
    "    cell_size = 50  # Pixels\n",
    "    img_width = width * cell_size\n",
    "    img_height = height * cell_size\n",
    "\n",
    "    image = Image.new('RGB', (img_width, img_height), color='white')\n",
    "    draw = ImageDraw.Draw(image)\n",
    "\n",
    "    # Load a font\n",
    "    if font_path and os.path.exists(font_path):\n",
    "        font = ImageFont.truetype(font_path, font_size)\n",
    "    else:\n",
    "        font = ImageFont.load_default()\n",
    "\n",
    "    for i in range(height):\n",
    "        for j in range(width):\n",
    "            top_left = (j * cell_size, i * cell_size)\n",
    "            bottom_right = ((j + 1) * cell_size, (i + 1) * cell_size)\n",
    "            draw.rectangle([top_left, bottom_right], outline='black', fill='white')\n",
    "\n",
    "            # Overlay the number\n",
    "            number = str(grid[i, j])\n",
    "            text_width, text_height = draw.textsize(number, font=font)\n",
    "            text_x = top_left[0] + (cell_size - text_width) / 2\n",
    "            text_y = top_left[1] + (cell_size - text_height) / 2\n",
    "            draw.text((text_x, text_y), number, fill='black', font=font)\n",
    "\n",
    "    return image\n",
    "\n",
    "\n",
    "# data/data_conversion.py (continued)\n",
    "\n",
    "def augment_image_with_transforms(image, grid, perturb_prob=0.1, dead_square_prob=0.05, noise_prob=0.05):\n",
    "    \"\"\"\n",
    "    Applies random perturbations, dead squares, noise, and additional transformations to the image.\n",
    "\n",
    "    Args:\n",
    "        image (PIL.Image): The original image to augment.\n",
    "        grid (np.ndarray): The original grid data.\n",
    "        perturb_prob (float): Probability of perturbing a cell.\n",
    "        dead_square_prob (float): Probability of marking a cell as dead.\n",
    "        noise_prob (float): Probability of adding noise to a cell.\n",
    "\n",
    "    Returns:\n",
    "        PIL.Image: Augmented image.\n",
    "        list: List of dead squares as (i, j) tuples.\n",
    "    \"\"\"\n",
    "    augmented_grid = grid.copy()\n",
    "    height, width = grid.shape\n",
    "    dead_squares = []\n",
    "\n",
    "    for i in range(height):\n",
    "        for j in range(width):\n",
    "            rand_val = random.random()\n",
    "            if rand_val < perturb_prob:\n",
    "                # Introduce random perturbation\n",
    "                original_value = augmented_grid[i, j]\n",
    "                augmented_grid[i, j] = random.randint(0, augmented_grid.max())\n",
    "                logger.debug(f\"Perturbed cell ({i}, {j}) from {original_value} to {augmented_grid[i, j]}\")\n",
    "\n",
    "            if rand_val < dead_square_prob:\n",
    "                # Mark square as dead\n",
    "                dead_squares.append((i, j))\n",
    "                logger.debug(f\"Marked cell ({i}, {j}) as dead.\")\n",
    "\n",
    "            if rand_val < noise_prob:\n",
    "                # Add random noise by altering the pixel color slightly\n",
    "                pixels = image.load()\n",
    "                current_color = pixels[j, i]\n",
    "                noise = np.random.randint(-30, 31, size=3)\n",
    "                noisy_color = np.clip(np.array(current_color) + noise, 0, 255)\n",
    "                pixels[j, i] = tuple(noisy_color)\n",
    "                logger.debug(f\"Added noise to cell ({i}, {j}): {current_color} -> {pixels[j, i]}\")\n",
    "\n",
    "    # Apply additional transformations\n",
    "    transform = transforms.Compose([\n",
    "        transforms.RandomRotation(15),          # Rotate image by ±15 degrees\n",
    "        transforms.RandomHorizontalFlip(p=0.5), # Flip image horizontally with 50% probability\n",
    "        transforms.RandomVerticalFlip(p=0.5),   # Flip image vertically with 50% probability\n",
    "    ])\n",
    "    augmented_image = grid_to_image(augmented_grid, color_map={\n",
    "        0: [0, 0, 0],        # Black\n",
    "        1: [255, 0, 0],      # Red\n",
    "        2: [0, 255, 0],      # Green\n",
    "        3: [0, 0, 255],      # Blue\n",
    "        4: [255, 255, 0],    # Yellow\n",
    "        5: [255, 165, 0],    # Orange\n",
    "        6: [128, 0, 128],    # Purple\n",
    "        7: [0, 255, 255],    # Cyan\n",
    "        8: [255, 192, 203],  # Pink\n",
    "        9: [128, 128, 128],  # Gray\n",
    "        10: [255, 255, 255], # White\n",
    "        # Add more mappings as needed\n",
    "    })\n",
    "    augmented_image = transform(augmented_image)\n",
    "\n",
    "    return augmented_image, dead_squares\n",
    "\n",
    "\n",
    "class GridDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Custom Dataset for handling grid-based image data.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, grids, transform=None, augmentation=True):\n",
    "        \"\"\"\n",
    "        Initializes the GridDataset.\n",
    "\n",
    "        Args:\n",
    "            grids (list of np.ndarray): List of 2D grid arrays.\n",
    "            transform (callable, optional): Transformations to apply to images. Defaults to None.\n",
    "            augmentation (bool, optional): Whether to apply data augmentation. Defaults to True.\n",
    "        \"\"\"\n",
    "        self.grids = grids\n",
    "        self.transform = transform\n",
    "        self.augmentation = augmentation\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.grids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        grid = self.grids[idx]\n",
    "        # Generate images\n",
    "        color_image = grid_to_image(grid, color_map={\n",
    "            0: [0, 0, 0],        # Black\n",
    "            1: [255, 0, 0],      # Red\n",
    "            2: [0, 255, 0],      # Green\n",
    "            3: [0, 0, 255],      # Blue\n",
    "            4: [255, 255, 0],    # Yellow\n",
    "            5: [255, 165, 0],    # Orange\n",
    "            6: [128, 0, 128],    # Purple\n",
    "            7: [0, 255, 255],    # Cyan\n",
    "            8: [255, 192, 203],  # Pink\n",
    "            9: [128, 128, 128],  # Gray\n",
    "            10: [255, 255, 255], # White\n",
    "            # Add more mappings as needed\n",
    "        })\n",
    "        grayscale_image = grid_to_grayscale(grid)\n",
    "        numeric_image = grid_to_numeric_image(grid)\n",
    "    \n",
    "        # Apply augmentation\n",
    "        if self.augmentation:\n",
    "            color_image_aug, dead_squares = augment_image_with_transforms(color_image, grid)\n",
    "            grayscale_image_aug, _ = augment_image_with_transforms(grayscale_image.convert('RGB'), grid)\n",
    "            numeric_image_aug, _ = augment_image_with_transforms(numeric_image, grid)\n",
    "        else:\n",
    "            color_image_aug = color_image\n",
    "            grayscale_image_aug = grayscale_image\n",
    "            numeric_image_aug = numeric_image\n",
    "    \n",
    "        # Apply transformations\n",
    "        if self.transform:\n",
    "            color_image_aug = self.transform(color_image_aug)\n",
    "            grayscale_image_aug = self.transform(grayscale_image_aug)\n",
    "            numeric_image_aug = self.transform(numeric_image_aug)\n",
    "    \n",
    "        return {\n",
    "            'color_image': color_image_aug,\n",
    "            'grayscale_image': grayscale_image_aug,\n",
    "            'numeric_image': numeric_image_aug,\n",
    "            'grid': torch.tensor(grid, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "\n",
    "def generate_grids(num_grids, grid_size, num_classes):\n",
    "    \"\"\"\n",
    "    Generates random grids for training.\n",
    "\n",
    "    Args:\n",
    "        num_grids (int): Number of grids to generate.\n",
    "        grid_size (int): Size of each grid (grid_size x grid_size).\n",
    "        num_classes (int): Number of classes/colors.\n",
    "\n",
    "    Returns:\n",
    "        list of np.ndarray: Generated grids.\n",
    "    \"\"\"\n",
    "    grids = []\n",
    "    for _ in range(num_grids):\n",
    "        grid = np.random.randint(0, num_classes, size=(grid_size, grid_size))\n",
    "        grids.append(grid)\n",
    "    logger.info(f\"Generated {num_grids} grids of size {grid_size}x{grid_size}.\")\n",
    "    return grids\n",
    "\n",
    "\n",
    "def get_data_loaders(batch_size=32, grid_size=10, num_classes=11, augment=True):\n",
    "    \"\"\"\n",
    "    Creates DataLoader instances for training and evaluation.\n",
    "\n",
    "    Args:\n",
    "        batch_size (int, optional): Number of samples per batch. Defaults to 32.\n",
    "        grid_size (int, optional): Size of each grid. Defaults to 10.\n",
    "        num_classes (int, optional): Number of classes/colors. Defaults to 11.\n",
    "        augment (bool, optional): Whether to apply data augmentation. Defaults to True.\n",
    "\n",
    "    Returns:\n",
    "        DataLoader: Training DataLoader.\n",
    "        DataLoader: Evaluation DataLoader.\n",
    "    \"\"\"\n",
    "    # Generate grids\n",
    "    train_grids = generate_grids(num_grids=1000, grid_size=grid_size, num_classes=num_classes)\n",
    "    eval_grids = generate_grids(num_grids=200, grid_size=grid_size, num_classes=num_classes)\n",
    "\n",
    "    # Define transformations\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((256, 256)),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "\n",
    "    # Create datasets\n",
    "    train_dataset = GridDataset(train_grids, transform=transform, augmentation=augment)\n",
    "    eval_dataset = GridDataset(eval_grids, transform=transform, augmentation=False)\n",
    "\n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "    eval_loader = DataLoader(eval_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "    logger.info(\"Created training and evaluation DataLoaders.\")\n",
    "    return train_loader, eval_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da8eab9-b4c9-45ae-91a3-ca5d5f088333",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
